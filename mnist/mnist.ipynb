{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "\n",
    "In this section, an MNistDataLoader() class is defined with some basic functions to read the binary data from the dataset and load them as lists of data instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Path to dataset files: C:\\Users\\mnguyen6\\.cache\\kagglehub\\datasets\\hojjatk\\mnist-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path import join\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "# Download latest version\n",
    "dataset_path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_path)\n",
    "\n",
    "\n",
    "# MNIST Data Loader Class\n",
    "\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "    \n",
    "    # Function to read the labels and load\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return np.array(images), np.array(labels)\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 15 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set file paths based on added MNIST Datasets\n",
    "base_path = 'data'\n",
    "training_images_filepath = join(base_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(base_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(base_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(base_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "# Helper function to show a list of images with their relating titles\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images)/cols)\n",
    "    plt.figure(figsize=(cols*4,rows*4))\n",
    "    \n",
    "    for index, x in enumerate(zip(images, title_texts)):        \n",
    "        image = x[0]        \n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index+1)        \n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if (title_text != ''):\n",
    "            plt.title(title_text, fontsize = 15);        \n",
    "\n",
    "\n",
    "# Load MINST dataset\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_trainval, y_trainval), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "\n",
    "# Show some random training and test images \n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_trainval[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_trainval[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 samples in the training dataset, each of size (28, 28) \n",
      "There are 10000 samples in the testing dataset \n",
      "The training label set has dimension of (60000,)\n"
     ]
    }
   ],
   "source": [
    "x_trainval_dim = x_trainval.shape\n",
    "y_trainval_dim = y_trainval.shape\n",
    "\n",
    "x_test_dim = x_test.shape\n",
    "y_test_dim = y_test.shape\n",
    "\n",
    "print(f\"There are {x_trainval_dim[0]} samples in the training dataset, each of size {x_trainval_dim[1],x_trainval_dim[2]} \\n\"\n",
    "      f\"There are {x_test_dim[0]} samples in the testing dataset \")\n",
    "\n",
    "print(f\"The training label set has dimension of {y_trainval_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = len(np.unique(y_trainval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the train-validation data split\n",
      "There are 48000 samples in the training dataset, each of size (28, 28). \n",
      "There are 12000 samples in the validation dataset.\n",
      "There are 10000 samples in the testing dataset.\n",
      "The training label set has dimension of (48000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_trainval,\n",
    "                                                  y_trainval,\n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=12)\n",
    "\n",
    "x_train_dim = np.shape(x_train)\n",
    "y_train_dim = np.shape(y_train)\n",
    "\n",
    "x_val_dim = np.shape(x_val)\n",
    "y_val_dim = np.shape(y_val)\n",
    "\n",
    "print(\"After the train-validation data split\")\n",
    "\n",
    "print(f\"There are {x_train_dim[0]} samples in the training dataset, each of size {x_train_dim[1:]}. \\n\"\n",
    "      f\"There are {x_val_dim[0]} samples in the validation dataset.\\n\"\n",
    "      f\"There are {x_test_dim[0]} samples in the testing dataset.\")\n",
    "\n",
    "print(f\"The training label set has dimension of {y_train_dim}\")\n",
    "\n",
    "# The input shape to the NN is the number of pixels in an MNIST image (28x28=784 input)\n",
    "INPUT_SHAPE = x_train_dim[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator\n",
    "\n",
    "I found that when training or evaluating a model on a GPU with limited RAM (such as 8GB RAM cards like the T1000 or RTX4060), the code often fails since TensorFlow tries to load the full arrays into the GPU memory (even when loading in batches). This code block is an attempt to solve this problem by using a generator to generate data from the training sets to the model in batches. These generators are used directly in model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# These generator objects will generate BATCH_SIZE samples at a time from the specified nparray\n",
    "train_gen = DataGenerator(x_train,y_train,BATCH_SIZE)\n",
    "val_gen = DataGenerator(x_val,y_val,BATCH_SIZE)\n",
    "test_gen = DataGenerator(x_test,y_test,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Fully-Connected ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model Construction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf                                 # General machine learning functionalities                    \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "def build_ann_model(layer_widths, \n",
    "                    input_shape, \n",
    "                    activation='relu', \n",
    "                    loss='sparse_categorical_crossentropy', \n",
    "                    metrics='accuracy', \n",
    "                    learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Creates a Keras Sequential model based on the specified architecture.\n",
    "\n",
    "    Args:\n",
    "        layer_widths (list): A list where each element is the number of nodes in a layer.\n",
    "        input_shape (tuple): Shape of the input data (e.g., (num_features,)).\n",
    "        activation (str): Activation function to use in the hidden layers.\n",
    "        learning_rate (float): Learning rate for the optimizer.\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): A compiled Keras Sequential model.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Add additional hidden layers based on layer_widths\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    for i,width in enumerate(layer_widths):\n",
    "        model.add(layers.Dense(width, activation=activation))\n",
    "        model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Add the output layer with width = number of class and softmax activation\n",
    "    model.add(layers.Dense(NUM_CLASS, activation='softmax', name = \"Output_layer\"))\n",
    "\n",
    "    # Compile the model with the provided or default learning rate, loss functions, and metrics\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                  loss=loss, \n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_SHAPE+(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,034\n",
      "Trainable params: 52,842\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LAYER_WIDTHS = [64,32]\n",
    "LAYER_DEPTH = len(LAYER_WIDTHS)\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCH = 50\n",
    "ACTIVATION = 'relu'\n",
    "LOSS = 'sparse_categorical_crossentropy'\n",
    "METRICS = 'accuracy'\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = build_ann_model(layer_widths=LAYER_WIDTHS,\n",
    "                        input_shape=INPUT_SHAPE+(1,),\n",
    "                        activation=ACTIVATION,\n",
    "                        loss=LOSS,\n",
    "                        metrics=METRICS,\n",
    "                        learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Experimentation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.2082 - val_accuracy: 0.9624\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.1935 - val_accuracy: 0.9661\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 6.0166e-04 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9662\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 4.1806e-04 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9658\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 3.5412e-04 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.9662\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.2075 - val_accuracy: 0.9639\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.2084 - val_accuracy: 0.9637\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 5.9160e-04 - accuracy: 1.0000 - val_loss: 0.2003 - val_accuracy: 0.9656\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 3.0761e-04 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9653\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.4352e-04 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9652\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.2324 - val_accuracy: 0.9610\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2096 - val_accuracy: 0.9644\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 4.9290e-04 - accuracy: 1.0000 - val_loss: 0.2090 - val_accuracy: 0.9660\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.6427e-04 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 0.9652\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.2190 - val_accuracy: 0.9645\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 9.9406e-04 - accuracy: 0.9999 - val_loss: 0.2146 - val_accuracy: 0.9655\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 3.7969e-04 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9663\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.0821e-04 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9660\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.6551e-04 - accuracy: 1.0000 - val_loss: 0.2166 - val_accuracy: 0.9662\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 6.6578e-04 - accuracy: 0.9998 - val_loss: 0.2836 - val_accuracy: 0.9570\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.2237 - val_accuracy: 0.9644\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 5.4064e-04 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9657\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.1210e-04 - accuracy: 1.0000 - val_loss: 0.2173 - val_accuracy: 0.9657\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.5079e-04 - accuracy: 1.0000 - val_loss: 0.2169 - val_accuracy: 0.9657\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.1942e-04 - accuracy: 1.0000 - val_loss: 0.2204 - val_accuracy: 0.9657\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.2583 - val_accuracy: 0.9605\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.2363 - val_accuracy: 0.9634\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 4.5230e-04 - accuracy: 1.0000 - val_loss: 0.2253 - val_accuracy: 0.9653\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.5977e-04 - accuracy: 1.0000 - val_loss: 0.2233 - val_accuracy: 0.9651\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.1817e-04 - accuracy: 1.0000 - val_loss: 0.2257 - val_accuracy: 0.9647\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 9.3255e-05 - accuracy: 1.0000 - val_loss: 0.2275 - val_accuracy: 0.9646\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 8.1203e-05 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9652\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.2384 - val_accuracy: 0.9634\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 9.2697e-04 - accuracy: 0.9999 - val_loss: 0.2352 - val_accuracy: 0.9649\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.0951e-04 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 0.9653\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.1308e-04 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9652\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 8.7016e-05 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9654\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 6.8953e-05 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9667\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.2217e-04 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.9501\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.2351 - val_accuracy: 0.9640\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 7.3209e-04 - accuracy: 0.9999 - val_loss: 0.2354 - val_accuracy: 0.9646\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.8932e-04 - accuracy: 1.0000 - val_loss: 0.2334 - val_accuracy: 0.9655\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9654\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 7.1243e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9658\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 5.5707e-05 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9663\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 4.6442e-05 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9655\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.2552 - val_accuracy: 0.9643\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.2509 - val_accuracy: 0.9648\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 2.6401e-04 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9663\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 9.1148e-05 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 0.9668\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "train_start = time()\n",
    "history = model.fit(train_gen,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    validation_data=val_gen,\n",
    "                    epochs = EPOCH)\n",
    "train_end = time()\n",
    "\n",
    "TRAIN_TIME = train_end - train_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model directory\n",
    "This section create the directory that corresponds to the time of the current run and store the training parameters, training performance, evaluation, and testing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                               # For saving models and training results\n",
    "from datetime import datetime                           # For creating the directory of each training run\n",
    "import json                                             # For storing training parameters during each run\n",
    "\n",
    "# Generate a timestamped directory for the training run\n",
    "timestamp = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "BASE_DIR = os.getcwd()\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR,f\"ann_model_results/{timestamp}_{LAYER_DEPTH}_{LEARNING_RATE}_{EPOCH}\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_122303_2_0.0001_50\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_122303_2_0.0001_50\\params_results.json\n"
     ]
    }
   ],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Save the model in H5DF format\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR,\"model.h5\")\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"Model saved as {MODEL_PATH}\")\n",
    "\n",
    "# Save the model structure\n",
    "model_path = os.path.join(OUTPUT_DIR, \"model_summary.json\")\n",
    "with open(model_path, 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        model.summary()\n",
    "\n",
    "# Save the training parameters\n",
    "training_params = {\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCH,\n",
    "    \"structure\": str(LAYER_WIDTHS),\n",
    "    \"loss\": LOSS,\n",
    "    \"metrics\": METRICS,\n",
    "    \"activation\": 'relu'\n",
    "}\n",
    "\n",
    "# Store the final training results\n",
    "training_results = {}\n",
    "for i in history.history.keys():\n",
    "    training_results[i] = history.history[i][-1]\n",
    "training_results['train_time'] = TRAIN_TIME\n",
    "# Save the training parameters and training results in the directory\n",
    "params_path = os.path.join(OUTPUT_DIR, \"params_results.json\")\n",
    "with open(params_path, \"w\") as f:\n",
    "    json.dump({\"parameters\": training_params, \"results\": training_results}, f, indent=4)\n",
    "print(f\"Training parameters and results saved at {params_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I defined a helper function that plots the training history and stores in the directory defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history, training_params=None, save_dir=None):\n",
    "    # Determine whether history is keras history or a dictionary to appropriately extract the history data\n",
    "    if isinstance(history, keras.callbacks.History):\n",
    "        history_data = history.history        # Extract the history dictionary\n",
    "    else:\n",
    "        history_data = history                # Assume it's already a dictionary\n",
    "\n",
    "    metric_list = list(history_data.keys())     # Extract the list of history keys\n",
    "    half_length = len(metric_list) // 2         # The index where the validation metrics start\n",
    "\n",
    "    metric2txt_dict = {'accuracy': 'Accuracy',\n",
    "                       'loss': 'Sparse Caregorical Crossentropy Loss'}\n",
    "\n",
    "    fig = plt.figure(figsize=(half_length * 5,5))\n",
    "\n",
    "    for index, metric in enumerate(metric_list[:half_length]):\n",
    "        metric_train = metric\n",
    "        metric_val = metric_list[index+half_length]\n",
    "\n",
    "        ax = fig.add_subplot(1,half_length,index+1)\n",
    "        ylim_acc = [0, max(max(history_data[metric_train]),max(history_data[metric_val]))]\n",
    "        ax.plot(history_data[metric_train], label = metric_train)\n",
    "        ax.plot(history_data[metric_val], label = metric_val)\n",
    "        ax.set_ylim(ylim_acc)\n",
    "        # plt.ylabel(metric_train)\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.legend(loc='best')\n",
    "        ax.set_title(f'{metric2txt_dict[metric_train]}')\n",
    "\n",
    "        ax.grid(which='major', color='black', linestyle='--', linewidth=0.5)\n",
    "        ax.minorticks_on()  # Turn on the minor ticks\n",
    "        ax.grid(which='minor', color='gray', linestyle=':', linewidth=0.5)\n",
    "        \n",
    "    if training_params:\n",
    "        fig.suptitle(f\"{training_params['structure']} model, lr={training_params['learning_rate']}, \"\n",
    "                    f\"{training_params['epochs']} epochs, {training_params['activation']} activation\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plots if a directory is provided\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "        plot_path = os.path.join(save_dir, \"performance_plot.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        print(f\"Performance plot saved at {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_122303_2_0.0001_50\\performance_plot.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_performance(history,training_params=training_params,save_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_WIDTHS = [[64,32],[32,16],[64,32,16],[32,16,8]]               # Architectures to be experimented with\n",
    "LAYER_DEPTH = [len(i) for i in LAYER_WIDTHS]                        # Depth of each architecture\n",
    "LEARNING_RATE = [0.001, 0.0005, 0.0001]\n",
    "EPOCH = [10,25,50]\n",
    "ACTIVATION = ['relu','sigmoid']\n",
    "LOSS = 'sparse_categorical_crossentropy'\n",
    "METRICS = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3455 - accuracy: 0.9004 - val_loss: 0.1597 - val_accuracy: 0.9517\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1575 - accuracy: 0.9524 - val_loss: 0.1264 - val_accuracy: 0.9605\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1160 - accuracy: 0.9649 - val_loss: 0.1257 - val_accuracy: 0.9597\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0900 - accuracy: 0.9725 - val_loss: 0.1088 - val_accuracy: 0.9661\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0747 - accuracy: 0.9769 - val_loss: 0.1075 - val_accuracy: 0.9671\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0602 - accuracy: 0.9817 - val_loss: 0.1182 - val_accuracy: 0.9639\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0518 - accuracy: 0.9834 - val_loss: 0.1020 - val_accuracy: 0.9693\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.1000 - val_accuracy: 0.9707\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.1086 - val_accuracy: 0.9707\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 0.1098 - val_accuracy: 0.9703\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131736_[64, 32]_0.001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131736_[64, 32]_0.001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131736_[64, 32]_0.001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.7085 - accuracy: 0.7779 - val_loss: 0.4785 - val_accuracy: 0.8503\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5116 - accuracy: 0.8417 - val_loss: 0.5249 - val_accuracy: 0.8425\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4917 - accuracy: 0.8453 - val_loss: 0.4423 - val_accuracy: 0.8645\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4583 - accuracy: 0.8577 - val_loss: 0.4238 - val_accuracy: 0.8656\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4139 - accuracy: 0.8712 - val_loss: 0.4034 - val_accuracy: 0.8770\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3927 - accuracy: 0.8802 - val_loss: 0.3298 - val_accuracy: 0.9000\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3762 - accuracy: 0.8825 - val_loss: 0.3586 - val_accuracy: 0.8905\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3840 - accuracy: 0.8785 - val_loss: 0.3221 - val_accuracy: 0.9021\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3503 - accuracy: 0.8909 - val_loss: 0.3025 - val_accuracy: 0.9044\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3408 - accuracy: 0.8962 - val_loss: 0.3043 - val_accuracy: 0.9069\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131819_[64, 32]_0.001_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131819_[64, 32]_0.001_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131819_[64, 32]_0.001_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3317 - accuracy: 0.9022 - val_loss: 0.1618 - val_accuracy: 0.9507\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1516 - accuracy: 0.9538 - val_loss: 0.1222 - val_accuracy: 0.9628\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1148 - accuracy: 0.9645 - val_loss: 0.1145 - val_accuracy: 0.9641\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0925 - accuracy: 0.9706 - val_loss: 0.1041 - val_accuracy: 0.9691\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 0.1004 - val_accuracy: 0.9705\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.1023 - val_accuracy: 0.9712\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0500 - accuracy: 0.9847 - val_loss: 0.1053 - val_accuracy: 0.9688\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0419 - accuracy: 0.9869 - val_loss: 0.1143 - val_accuracy: 0.9681\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0383 - accuracy: 0.9880 - val_loss: 0.1095 - val_accuracy: 0.9693\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.1101 - val_accuracy: 0.9699\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0270 - accuracy: 0.9914 - val_loss: 0.1129 - val_accuracy: 0.9720\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.1176 - val_accuracy: 0.9707\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.1174 - val_accuracy: 0.9719\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.1123 - val_accuracy: 0.9726\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.1290 - val_accuracy: 0.9714\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.1227 - val_accuracy: 0.9749\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.1390 - val_accuracy: 0.9711\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.1262 - val_accuracy: 0.9731\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.1368 - val_accuracy: 0.9703\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0135 - accuracy: 0.9957 - val_loss: 0.1376 - val_accuracy: 0.9718\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.1418 - val_accuracy: 0.9722\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.1447 - val_accuracy: 0.9705\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.1410 - val_accuracy: 0.9713\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1423 - val_accuracy: 0.9721\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.1588 - val_accuracy: 0.9712\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131900_[64, 32]_0.001_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131900_[64, 32]_0.001_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_131900_[64, 32]_0.001_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7012 - accuracy: 0.7783 - val_loss: 0.4841 - val_accuracy: 0.8475\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5020 - accuracy: 0.8419 - val_loss: 0.4932 - val_accuracy: 0.8440\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4580 - accuracy: 0.8599 - val_loss: 0.4142 - val_accuracy: 0.8718\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4282 - accuracy: 0.8658 - val_loss: 0.4002 - val_accuracy: 0.8748\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4327 - accuracy: 0.8644 - val_loss: 0.4059 - val_accuracy: 0.8741\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3993 - accuracy: 0.8754 - val_loss: 0.3454 - val_accuracy: 0.8926\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3787 - accuracy: 0.8814 - val_loss: 0.3718 - val_accuracy: 0.8837\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3538 - accuracy: 0.8931 - val_loss: 0.3453 - val_accuracy: 0.8984\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3421 - accuracy: 0.8956 - val_loss: 0.2879 - val_accuracy: 0.9128\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3345 - accuracy: 0.8982 - val_loss: 0.3064 - val_accuracy: 0.9070\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3153 - accuracy: 0.9035 - val_loss: 0.2855 - val_accuracy: 0.9141\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3241 - accuracy: 0.9003 - val_loss: 0.2890 - val_accuracy: 0.9136\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3170 - accuracy: 0.9027 - val_loss: 0.2694 - val_accuracy: 0.9201\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2979 - accuracy: 0.9107 - val_loss: 0.2569 - val_accuracy: 0.9230\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2896 - accuracy: 0.9111 - val_loss: 0.2729 - val_accuracy: 0.9187\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2842 - accuracy: 0.9125 - val_loss: 0.2581 - val_accuracy: 0.9216\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2821 - accuracy: 0.9132 - val_loss: 0.2599 - val_accuracy: 0.9205\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2914 - accuracy: 0.9097 - val_loss: 0.2623 - val_accuracy: 0.9200\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2839 - accuracy: 0.9139 - val_loss: 0.2717 - val_accuracy: 0.9199\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3045 - accuracy: 0.9068 - val_loss: 0.2827 - val_accuracy: 0.9136\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2929 - accuracy: 0.9091 - val_loss: 0.2667 - val_accuracy: 0.9178\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3044 - accuracy: 0.9060 - val_loss: 0.2545 - val_accuracy: 0.9236\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2750 - accuracy: 0.9167 - val_loss: 0.2383 - val_accuracy: 0.9300\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2510 - accuracy: 0.9248 - val_loss: 0.2441 - val_accuracy: 0.9294\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2574 - accuracy: 0.9207 - val_loss: 0.2337 - val_accuracy: 0.9303\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132040_[64, 32]_0.001_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132040_[64, 32]_0.001_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132040_[64, 32]_0.001_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3414 - accuracy: 0.9013 - val_loss: 0.1708 - val_accuracy: 0.9486\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1584 - accuracy: 0.9526 - val_loss: 0.1458 - val_accuracy: 0.9587\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1182 - accuracy: 0.9645 - val_loss: 0.1248 - val_accuracy: 0.9640\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0953 - accuracy: 0.9705 - val_loss: 0.1280 - val_accuracy: 0.9668\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0775 - accuracy: 0.9758 - val_loss: 0.1181 - val_accuracy: 0.9682\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0662 - accuracy: 0.9790 - val_loss: 0.1179 - val_accuracy: 0.9697\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0559 - accuracy: 0.9826 - val_loss: 0.1339 - val_accuracy: 0.9674\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0471 - accuracy: 0.9845 - val_loss: 0.1325 - val_accuracy: 0.9666\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 0.1178 - val_accuracy: 0.9675\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0376 - accuracy: 0.9878 - val_loss: 0.1178 - val_accuracy: 0.9680\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.1304 - val_accuracy: 0.9678\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.1167 - val_accuracy: 0.9696\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.1363 - val_accuracy: 0.9670\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.1306 - val_accuracy: 0.9692\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.1443 - val_accuracy: 0.9658\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.1449 - val_accuracy: 0.9667\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.1543 - val_accuracy: 0.9690\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.1372 - val_accuracy: 0.9712\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.1491 - val_accuracy: 0.9671\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.1528 - val_accuracy: 0.9684\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.1695 - val_accuracy: 0.9675\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.1504 - val_accuracy: 0.9688\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.1596 - val_accuracy: 0.9682\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.1692 - val_accuracy: 0.9686\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1809 - val_accuracy: 0.9660\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.1741 - val_accuracy: 0.9667\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.1546 - val_accuracy: 0.9698\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1596 - val_accuracy: 0.9705\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1608 - val_accuracy: 0.9706\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.1584 - val_accuracy: 0.9711\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1681 - val_accuracy: 0.9706\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.1748 - val_accuracy: 0.9691\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1802 - val_accuracy: 0.9698\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.1701 - val_accuracy: 0.9699\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.1781 - val_accuracy: 0.9708\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1685 - val_accuracy: 0.9730\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.1735 - val_accuracy: 0.9722\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.2194 - val_accuracy: 0.9660\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1826 - val_accuracy: 0.9697\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1711 - val_accuracy: 0.9716\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.1805 - val_accuracy: 0.9693\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.1837 - val_accuracy: 0.9718\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1916 - val_accuracy: 0.9702\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.1907 - val_accuracy: 0.9702\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.1863 - val_accuracy: 0.9706\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1924 - val_accuracy: 0.9693\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1840 - val_accuracy: 0.9694\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.1920 - val_accuracy: 0.9697\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.2076 - val_accuracy: 0.9697\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1886 - val_accuracy: 0.9707\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132228_[64, 32]_0.001_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132228_[64, 32]_0.001_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132228_[64, 32]_0.001_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6786 - accuracy: 0.7854 - val_loss: 0.5727 - val_accuracy: 0.8227\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5115 - accuracy: 0.8372 - val_loss: 0.4662 - val_accuracy: 0.8581\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4614 - accuracy: 0.8565 - val_loss: 0.4055 - val_accuracy: 0.8762\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4497 - accuracy: 0.8611 - val_loss: 0.4101 - val_accuracy: 0.8753\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4275 - accuracy: 0.8670 - val_loss: 0.3715 - val_accuracy: 0.8857\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4159 - accuracy: 0.8747 - val_loss: 0.3865 - val_accuracy: 0.8823\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3875 - accuracy: 0.8858 - val_loss: 0.3381 - val_accuracy: 0.9004\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3673 - accuracy: 0.8877 - val_loss: 0.3589 - val_accuracy: 0.8858\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3716 - accuracy: 0.8852 - val_loss: 0.3425 - val_accuracy: 0.9003\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3624 - accuracy: 0.8904 - val_loss: 0.3157 - val_accuracy: 0.9081\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3278 - accuracy: 0.9005 - val_loss: 0.3168 - val_accuracy: 0.9035\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3421 - accuracy: 0.8949 - val_loss: 0.3008 - val_accuracy: 0.9105\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3314 - accuracy: 0.8986 - val_loss: 0.2970 - val_accuracy: 0.9103\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3186 - accuracy: 0.9015 - val_loss: 0.3204 - val_accuracy: 0.9004\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3240 - accuracy: 0.8985 - val_loss: 0.2811 - val_accuracy: 0.9133\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3242 - accuracy: 0.9011 - val_loss: 0.3107 - val_accuracy: 0.9043\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3228 - accuracy: 0.8994 - val_loss: 0.3104 - val_accuracy: 0.9058\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3049 - accuracy: 0.9070 - val_loss: 0.2859 - val_accuracy: 0.9127\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2995 - accuracy: 0.9074 - val_loss: 0.2946 - val_accuracy: 0.9121\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3067 - accuracy: 0.9054 - val_loss: 0.2743 - val_accuracy: 0.9163\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2985 - accuracy: 0.9080 - val_loss: 0.2716 - val_accuracy: 0.9164\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3094 - accuracy: 0.9056 - val_loss: 0.3135 - val_accuracy: 0.9050\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3077 - accuracy: 0.9062 - val_loss: 0.2756 - val_accuracy: 0.9197\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3013 - accuracy: 0.9080 - val_loss: 0.2801 - val_accuracy: 0.9154\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2886 - accuracy: 0.9117 - val_loss: 0.2672 - val_accuracy: 0.9185\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2747 - accuracy: 0.9153 - val_loss: 0.2425 - val_accuracy: 0.9257\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2686 - accuracy: 0.9180 - val_loss: 0.2463 - val_accuracy: 0.9268\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2846 - accuracy: 0.9121 - val_loss: 0.2606 - val_accuracy: 0.9200\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2794 - accuracy: 0.9139 - val_loss: 0.2566 - val_accuracy: 0.9243\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2631 - accuracy: 0.9201 - val_loss: 0.2454 - val_accuracy: 0.9285\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2646 - accuracy: 0.9182 - val_loss: 0.2459 - val_accuracy: 0.9238\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2701 - accuracy: 0.9162 - val_loss: 0.2510 - val_accuracy: 0.9227\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2689 - accuracy: 0.9172 - val_loss: 0.2431 - val_accuracy: 0.9264\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2559 - accuracy: 0.9216 - val_loss: 0.2364 - val_accuracy: 0.9292\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2543 - accuracy: 0.9213 - val_loss: 0.2248 - val_accuracy: 0.9334\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2576 - accuracy: 0.9204 - val_loss: 0.2579 - val_accuracy: 0.9227\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2710 - accuracy: 0.9162 - val_loss: 0.2536 - val_accuracy: 0.9247\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2527 - accuracy: 0.9228 - val_loss: 0.2377 - val_accuracy: 0.9310\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2477 - accuracy: 0.9257 - val_loss: 0.2284 - val_accuracy: 0.9347\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2356 - accuracy: 0.9303 - val_loss: 0.2201 - val_accuracy: 0.9366\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2332 - accuracy: 0.9287 - val_loss: 0.2209 - val_accuracy: 0.9357\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2379 - accuracy: 0.9268 - val_loss: 0.2370 - val_accuracy: 0.9304\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2554 - accuracy: 0.9204 - val_loss: 0.2337 - val_accuracy: 0.9273\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2456 - accuracy: 0.9259 - val_loss: 0.2336 - val_accuracy: 0.9317\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2356 - accuracy: 0.9281 - val_loss: 0.2326 - val_accuracy: 0.9308\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2321 - accuracy: 0.9295 - val_loss: 0.2169 - val_accuracy: 0.9355\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2309 - accuracy: 0.9288 - val_loss: 0.2249 - val_accuracy: 0.9340\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2374 - accuracy: 0.9271 - val_loss: 0.2234 - val_accuracy: 0.9343\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2285 - accuracy: 0.9294 - val_loss: 0.2189 - val_accuracy: 0.9373\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2217 - accuracy: 0.9320 - val_loss: 0.2172 - val_accuracy: 0.9362\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132553_[64, 32]_0.001_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132553_[64, 32]_0.001_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132553_[64, 32]_0.001_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4165 - accuracy: 0.8829 - val_loss: 0.1861 - val_accuracy: 0.9440\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1854 - accuracy: 0.9472 - val_loss: 0.1460 - val_accuracy: 0.9558\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1346 - accuracy: 0.9592 - val_loss: 0.1345 - val_accuracy: 0.9597\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1043 - accuracy: 0.9685 - val_loss: 0.1158 - val_accuracy: 0.9653\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0818 - accuracy: 0.9751 - val_loss: 0.1114 - val_accuracy: 0.9663\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0690 - accuracy: 0.9787 - val_loss: 0.1013 - val_accuracy: 0.9683\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0554 - accuracy: 0.9827 - val_loss: 0.1006 - val_accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0464 - accuracy: 0.9861 - val_loss: 0.1067 - val_accuracy: 0.9681\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0382 - accuracy: 0.9887 - val_loss: 0.1096 - val_accuracy: 0.9677\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 0.1104 - val_accuracy: 0.9689\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132934_[64, 32]_0.0005_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132934_[64, 32]_0.0005_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_132934_[64, 32]_0.0005_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.7201 - accuracy: 0.7763 - val_loss: 0.4701 - val_accuracy: 0.8522\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4423 - accuracy: 0.8640 - val_loss: 0.3869 - val_accuracy: 0.8793\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3974 - accuracy: 0.8769 - val_loss: 0.3836 - val_accuracy: 0.8816\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3652 - accuracy: 0.8892 - val_loss: 0.3500 - val_accuracy: 0.8946\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3502 - accuracy: 0.8936 - val_loss: 0.3228 - val_accuracy: 0.9003\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3312 - accuracy: 0.8999 - val_loss: 0.2783 - val_accuracy: 0.9179\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3186 - accuracy: 0.9035 - val_loss: 0.2998 - val_accuracy: 0.9050\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3234 - accuracy: 0.9024 - val_loss: 0.3001 - val_accuracy: 0.9098\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3045 - accuracy: 0.9080 - val_loss: 0.2875 - val_accuracy: 0.9140\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2927 - accuracy: 0.9100 - val_loss: 0.2680 - val_accuracy: 0.9197\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133018_[64, 32]_0.0005_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133018_[64, 32]_0.0005_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133018_[64, 32]_0.0005_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4460 - accuracy: 0.8758 - val_loss: 0.1851 - val_accuracy: 0.9463\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1816 - accuracy: 0.9466 - val_loss: 0.1316 - val_accuracy: 0.9597\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1280 - accuracy: 0.9625 - val_loss: 0.1101 - val_accuracy: 0.9653\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0967 - accuracy: 0.9709 - val_loss: 0.1073 - val_accuracy: 0.9664\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0775 - accuracy: 0.9768 - val_loss: 0.1001 - val_accuracy: 0.9705\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0639 - accuracy: 0.9809 - val_loss: 0.0980 - val_accuracy: 0.9721\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0502 - accuracy: 0.9855 - val_loss: 0.1004 - val_accuracy: 0.9709\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0421 - accuracy: 0.9877 - val_loss: 0.0993 - val_accuracy: 0.9709\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0342 - accuracy: 0.9901 - val_loss: 0.1081 - val_accuracy: 0.9711\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0284 - accuracy: 0.9917 - val_loss: 0.1069 - val_accuracy: 0.9707\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 0.1039 - val_accuracy: 0.9724\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0213 - accuracy: 0.9939 - val_loss: 0.1112 - val_accuracy: 0.9705\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0172 - accuracy: 0.9954 - val_loss: 0.1159 - val_accuracy: 0.9722\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.1157 - val_accuracy: 0.9722\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.1203 - val_accuracy: 0.9718\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.1230 - val_accuracy: 0.9718\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.1280 - val_accuracy: 0.9717\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.1402 - val_accuracy: 0.9677\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.1239 - val_accuracy: 0.9729\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0092 - accuracy: 0.9974 - val_loss: 0.1283 - val_accuracy: 0.9727\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0071 - accuracy: 0.9981 - val_loss: 0.1381 - val_accuracy: 0.9716\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0084 - accuracy: 0.9975 - val_loss: 0.1388 - val_accuracy: 0.9721\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1278 - val_accuracy: 0.9730\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.1249 - val_accuracy: 0.9753\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.1666 - val_accuracy: 0.9664\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133102_[64, 32]_0.0005_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133102_[64, 32]_0.0005_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133102_[64, 32]_0.0005_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7495 - accuracy: 0.7673 - val_loss: 0.4310 - val_accuracy: 0.8692\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4349 - accuracy: 0.8637 - val_loss: 0.3722 - val_accuracy: 0.8852\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3759 - accuracy: 0.8834 - val_loss: 0.3383 - val_accuracy: 0.8943\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3555 - accuracy: 0.8903 - val_loss: 0.3230 - val_accuracy: 0.9007\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3304 - accuracy: 0.8972 - val_loss: 0.3113 - val_accuracy: 0.9038\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3297 - accuracy: 0.8977 - val_loss: 0.3047 - val_accuracy: 0.9086\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3150 - accuracy: 0.9018 - val_loss: 0.2978 - val_accuracy: 0.9093\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2946 - accuracy: 0.9089 - val_loss: 0.2820 - val_accuracy: 0.9173\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2929 - accuracy: 0.9118 - val_loss: 0.2755 - val_accuracy: 0.9146\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2882 - accuracy: 0.9117 - val_loss: 0.2512 - val_accuracy: 0.9228\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2640 - accuracy: 0.9204 - val_loss: 0.2354 - val_accuracy: 0.9282\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2659 - accuracy: 0.9192 - val_loss: 0.2285 - val_accuracy: 0.9332\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2559 - accuracy: 0.9217 - val_loss: 0.2373 - val_accuracy: 0.9268\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2507 - accuracy: 0.9238 - val_loss: 0.2342 - val_accuracy: 0.9307\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2501 - accuracy: 0.9244 - val_loss: 0.2183 - val_accuracy: 0.9332\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2438 - accuracy: 0.9260 - val_loss: 0.2279 - val_accuracy: 0.9306\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2461 - accuracy: 0.9257 - val_loss: 0.2245 - val_accuracy: 0.9304\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2352 - accuracy: 0.9287 - val_loss: 0.2216 - val_accuracy: 0.9324\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2239 - accuracy: 0.9315 - val_loss: 0.2080 - val_accuracy: 0.9384\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2172 - accuracy: 0.9332 - val_loss: 0.2002 - val_accuracy: 0.9381\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2310 - accuracy: 0.9290 - val_loss: 0.2144 - val_accuracy: 0.9337\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2223 - accuracy: 0.9316 - val_loss: 0.2024 - val_accuracy: 0.9402\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2204 - accuracy: 0.9329 - val_loss: 0.2108 - val_accuracy: 0.9352\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2222 - accuracy: 0.9320 - val_loss: 0.2028 - val_accuracy: 0.9387\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2103 - accuracy: 0.9368 - val_loss: 0.2008 - val_accuracy: 0.9406\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133257_[64, 32]_0.0005_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133257_[64, 32]_0.0005_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133257_[64, 32]_0.0005_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4247 - accuracy: 0.8812 - val_loss: 0.1841 - val_accuracy: 0.9479\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1797 - accuracy: 0.9477 - val_loss: 0.1375 - val_accuracy: 0.9585\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1290 - accuracy: 0.9611 - val_loss: 0.1156 - val_accuracy: 0.9648\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0999 - accuracy: 0.9700 - val_loss: 0.1028 - val_accuracy: 0.9688\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0785 - accuracy: 0.9765 - val_loss: 0.1030 - val_accuracy: 0.9680\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0647 - accuracy: 0.9802 - val_loss: 0.1001 - val_accuracy: 0.9690\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.1041 - val_accuracy: 0.9684\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0441 - accuracy: 0.9867 - val_loss: 0.1103 - val_accuracy: 0.9680\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0373 - accuracy: 0.9886 - val_loss: 0.1151 - val_accuracy: 0.9669\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0323 - accuracy: 0.9903 - val_loss: 0.1072 - val_accuracy: 0.9707\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.1189 - val_accuracy: 0.9663\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.1086 - val_accuracy: 0.9707\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0196 - accuracy: 0.9945 - val_loss: 0.1131 - val_accuracy: 0.9704\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.1167 - val_accuracy: 0.9702\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0151 - accuracy: 0.9958 - val_loss: 0.1257 - val_accuracy: 0.9700\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.1233 - val_accuracy: 0.9714\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.1320 - val_accuracy: 0.9689\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1155 - val_accuracy: 0.9744\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.1413 - val_accuracy: 0.9688\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.1428 - val_accuracy: 0.9700\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.1327 - val_accuracy: 0.9712\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.1439 - val_accuracy: 0.9693\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.1371 - val_accuracy: 0.9718\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.1460 - val_accuracy: 0.9703\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.1382 - val_accuracy: 0.9729\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.1444 - val_accuracy: 0.9724\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.1451 - val_accuracy: 0.9706\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.1463 - val_accuracy: 0.9714\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1440 - val_accuracy: 0.9722\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.1541 - val_accuracy: 0.9709\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.1392 - val_accuracy: 0.9731\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1544 - val_accuracy: 0.9709\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1455 - val_accuracy: 0.9699\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1560 - val_accuracy: 0.9702\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.1623 - val_accuracy: 0.9701\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.1468 - val_accuracy: 0.9726\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.1498 - val_accuracy: 0.9738\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.1566 - val_accuracy: 0.9728\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.1514 - val_accuracy: 0.9731\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1454 - val_accuracy: 0.9732\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1580 - val_accuracy: 0.9722\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1642 - val_accuracy: 0.9723\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.1626 - val_accuracy: 0.9721\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1662 - val_accuracy: 0.9721\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.1597 - val_accuracy: 0.9719\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1971 - val_accuracy: 0.9677\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.1731 - val_accuracy: 0.9732\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.1719 - val_accuracy: 0.9728\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1833 - val_accuracy: 0.9693\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1757 - val_accuracy: 0.9707\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133452_[64, 32]_0.0005_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133452_[64, 32]_0.0005_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133452_[64, 32]_0.0005_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7297 - accuracy: 0.7700 - val_loss: 0.4445 - val_accuracy: 0.8664\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4396 - accuracy: 0.8645 - val_loss: 0.3869 - val_accuracy: 0.8778\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3918 - accuracy: 0.8799 - val_loss: 0.3637 - val_accuracy: 0.8889\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3667 - accuracy: 0.8872 - val_loss: 0.3358 - val_accuracy: 0.9007\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3344 - accuracy: 0.8979 - val_loss: 0.3072 - val_accuracy: 0.9057\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3134 - accuracy: 0.9045 - val_loss: 0.2727 - val_accuracy: 0.9153\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3049 - accuracy: 0.9068 - val_loss: 0.3095 - val_accuracy: 0.9059\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3005 - accuracy: 0.9082 - val_loss: 0.2749 - val_accuracy: 0.9172\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2804 - accuracy: 0.9141 - val_loss: 0.2368 - val_accuracy: 0.9252\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2593 - accuracy: 0.9204 - val_loss: 0.2362 - val_accuracy: 0.9280\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2660 - accuracy: 0.9178 - val_loss: 0.2633 - val_accuracy: 0.9167\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2627 - accuracy: 0.9194 - val_loss: 0.2201 - val_accuracy: 0.9293\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2416 - accuracy: 0.9255 - val_loss: 0.2270 - val_accuracy: 0.9303\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2465 - accuracy: 0.9242 - val_loss: 0.2332 - val_accuracy: 0.9253\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2382 - accuracy: 0.9275 - val_loss: 0.2225 - val_accuracy: 0.9332\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9284 - val_loss: 0.2073 - val_accuracy: 0.9375\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2270 - accuracy: 0.9306 - val_loss: 0.2061 - val_accuracy: 0.9390\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2269 - accuracy: 0.9301 - val_loss: 0.2176 - val_accuracy: 0.9327\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2259 - accuracy: 0.9296 - val_loss: 0.2032 - val_accuracy: 0.9383\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2270 - accuracy: 0.9305 - val_loss: 0.2114 - val_accuracy: 0.9340\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2197 - accuracy: 0.9323 - val_loss: 0.1992 - val_accuracy: 0.9390\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2128 - accuracy: 0.9342 - val_loss: 0.2023 - val_accuracy: 0.9390\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2127 - accuracy: 0.9354 - val_loss: 0.1978 - val_accuracy: 0.9388\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2013 - accuracy: 0.9384 - val_loss: 0.1884 - val_accuracy: 0.9428\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1997 - accuracy: 0.9389 - val_loss: 0.1801 - val_accuracy: 0.9453\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1971 - accuracy: 0.9396 - val_loss: 0.1848 - val_accuracy: 0.9430\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1844 - accuracy: 0.9443 - val_loss: 0.1813 - val_accuracy: 0.9442\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1917 - accuracy: 0.9413 - val_loss: 0.1851 - val_accuracy: 0.9447\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2016 - accuracy: 0.9382 - val_loss: 0.1878 - val_accuracy: 0.9419\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1973 - accuracy: 0.9393 - val_loss: 0.1937 - val_accuracy: 0.9420\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1897 - accuracy: 0.9423 - val_loss: 0.1914 - val_accuracy: 0.9402\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1886 - accuracy: 0.9430 - val_loss: 0.1945 - val_accuracy: 0.9402\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1921 - accuracy: 0.9411 - val_loss: 0.1901 - val_accuracy: 0.9431\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1964 - accuracy: 0.9408 - val_loss: 0.1871 - val_accuracy: 0.9436\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1905 - accuracy: 0.9425 - val_loss: 0.1760 - val_accuracy: 0.9474\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1837 - accuracy: 0.9440 - val_loss: 0.1711 - val_accuracy: 0.9488\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1799 - accuracy: 0.9445 - val_loss: 0.1712 - val_accuracy: 0.9452\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1798 - accuracy: 0.9450 - val_loss: 0.1786 - val_accuracy: 0.9457\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1770 - accuracy: 0.9449 - val_loss: 0.1795 - val_accuracy: 0.9444\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1747 - accuracy: 0.9467 - val_loss: 0.1678 - val_accuracy: 0.9526\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1730 - accuracy: 0.9473 - val_loss: 0.1743 - val_accuracy: 0.9489\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1695 - accuracy: 0.9490 - val_loss: 0.1719 - val_accuracy: 0.9479\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1730 - accuracy: 0.9472 - val_loss: 0.1737 - val_accuracy: 0.9484\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1765 - accuracy: 0.9467 - val_loss: 0.1772 - val_accuracy: 0.9443\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1674 - accuracy: 0.9478 - val_loss: 0.1686 - val_accuracy: 0.9464\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1654 - accuracy: 0.9485 - val_loss: 0.1830 - val_accuracy: 0.9440\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1762 - accuracy: 0.9452 - val_loss: 0.1761 - val_accuracy: 0.9477\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1779 - accuracy: 0.9451 - val_loss: 0.1826 - val_accuracy: 0.9453\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1757 - accuracy: 0.9461 - val_loss: 0.1707 - val_accuracy: 0.9484\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1627 - accuracy: 0.9516 - val_loss: 0.1597 - val_accuracy: 0.9515\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133833_[64, 32]_0.0005_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133833_[64, 32]_0.0005_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_133833_[64, 32]_0.0005_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.9010 - accuracy: 0.7423 - val_loss: 0.4135 - val_accuracy: 0.8983\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3812 - accuracy: 0.8987 - val_loss: 0.2667 - val_accuracy: 0.9266\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2733 - accuracy: 0.9233 - val_loss: 0.2088 - val_accuracy: 0.9400\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2178 - accuracy: 0.9385 - val_loss: 0.1786 - val_accuracy: 0.9488\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1815 - accuracy: 0.9482 - val_loss: 0.1593 - val_accuracy: 0.9534\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1557 - accuracy: 0.9565 - val_loss: 0.1461 - val_accuracy: 0.9563\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1357 - accuracy: 0.9620 - val_loss: 0.1498 - val_accuracy: 0.9603\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1195 - accuracy: 0.9670 - val_loss: 0.1307 - val_accuracy: 0.9607\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1065 - accuracy: 0.9707 - val_loss: 0.1257 - val_accuracy: 0.9617\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0952 - accuracy: 0.9741 - val_loss: 0.1268 - val_accuracy: 0.9643\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134218_[64, 32]_0.0001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134218_[64, 32]_0.0001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134218_[64, 32]_0.0001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.2921 - accuracy: 0.5934 - val_loss: 0.6697 - val_accuracy: 0.8062\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5906 - accuracy: 0.8259 - val_loss: 0.4647 - val_accuracy: 0.8660\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4560 - accuracy: 0.8658 - val_loss: 0.3874 - val_accuracy: 0.8836\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3874 - accuracy: 0.8846 - val_loss: 0.3428 - val_accuracy: 0.8939\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3465 - accuracy: 0.8967 - val_loss: 0.3109 - val_accuracy: 0.9064\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3208 - accuracy: 0.9044 - val_loss: 0.3013 - val_accuracy: 0.9077\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3006 - accuracy: 0.9103 - val_loss: 0.2819 - val_accuracy: 0.9147\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2813 - accuracy: 0.9162 - val_loss: 0.2697 - val_accuracy: 0.9208\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2623 - accuracy: 0.9212 - val_loss: 0.2621 - val_accuracy: 0.9218\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2530 - accuracy: 0.9256 - val_loss: 0.2534 - val_accuracy: 0.9249\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134302_[64, 32]_0.0001_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134302_[64, 32]_0.0001_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134302_[64, 32]_0.0001_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.9021 - accuracy: 0.7358 - val_loss: 0.4198 - val_accuracy: 0.8946\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3849 - accuracy: 0.8981 - val_loss: 0.2716 - val_accuracy: 0.9288\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2778 - accuracy: 0.9243 - val_loss: 0.2130 - val_accuracy: 0.9417\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2229 - accuracy: 0.9384 - val_loss: 0.1827 - val_accuracy: 0.9488\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1872 - accuracy: 0.9474 - val_loss: 0.1670 - val_accuracy: 0.9529\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1608 - accuracy: 0.9547 - val_loss: 0.1486 - val_accuracy: 0.9559\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1403 - accuracy: 0.9612 - val_loss: 0.1373 - val_accuracy: 0.9586\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1236 - accuracy: 0.9665 - val_loss: 0.1277 - val_accuracy: 0.9618\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1098 - accuracy: 0.9701 - val_loss: 0.1241 - val_accuracy: 0.9626\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0980 - accuracy: 0.9733 - val_loss: 0.1180 - val_accuracy: 0.9644\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0870 - accuracy: 0.9768 - val_loss: 0.1149 - val_accuracy: 0.9648\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9799 - val_loss: 0.1154 - val_accuracy: 0.9644\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9818 - val_loss: 0.1123 - val_accuracy: 0.9663\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0628 - accuracy: 0.9843 - val_loss: 0.1103 - val_accuracy: 0.9678\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0562 - accuracy: 0.9862 - val_loss: 0.1112 - val_accuracy: 0.9672\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0499 - accuracy: 0.9883 - val_loss: 0.1076 - val_accuracy: 0.9689\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0452 - accuracy: 0.9898 - val_loss: 0.1103 - val_accuracy: 0.9684\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0400 - accuracy: 0.9916 - val_loss: 0.1094 - val_accuracy: 0.9688\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0355 - accuracy: 0.9931 - val_loss: 0.1125 - val_accuracy: 0.9683\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0315 - accuracy: 0.9941 - val_loss: 0.1144 - val_accuracy: 0.9687\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0279 - accuracy: 0.9948 - val_loss: 0.1145 - val_accuracy: 0.9678\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0243 - accuracy: 0.9958 - val_loss: 0.1153 - val_accuracy: 0.9693\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0212 - accuracy: 0.9968 - val_loss: 0.1197 - val_accuracy: 0.9678\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0190 - accuracy: 0.9970 - val_loss: 0.1183 - val_accuracy: 0.9682\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: 0.1258 - val_accuracy: 0.9679\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134348_[64, 32]_0.0001_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134348_[64, 32]_0.0001_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134348_[64, 32]_0.0001_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.3361 - accuracy: 0.5776 - val_loss: 0.7085 - val_accuracy: 0.7955\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6119 - accuracy: 0.8228 - val_loss: 0.4812 - val_accuracy: 0.8582\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4620 - accuracy: 0.8643 - val_loss: 0.3902 - val_accuracy: 0.8848\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3937 - accuracy: 0.8827 - val_loss: 0.3479 - val_accuracy: 0.8974\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3508 - accuracy: 0.8963 - val_loss: 0.3171 - val_accuracy: 0.9018\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3198 - accuracy: 0.9036 - val_loss: 0.2892 - val_accuracy: 0.9128\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2937 - accuracy: 0.9116 - val_loss: 0.2704 - val_accuracy: 0.9199\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2767 - accuracy: 0.9160 - val_loss: 0.2614 - val_accuracy: 0.9205\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2599 - accuracy: 0.9220 - val_loss: 0.2509 - val_accuracy: 0.9248\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2498 - accuracy: 0.9244 - val_loss: 0.2338 - val_accuracy: 0.9293\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2351 - accuracy: 0.9294 - val_loss: 0.2280 - val_accuracy: 0.9317\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2301 - accuracy: 0.9305 - val_loss: 0.2232 - val_accuracy: 0.9323\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2240 - accuracy: 0.9321 - val_loss: 0.2226 - val_accuracy: 0.9323\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2125 - accuracy: 0.9355 - val_loss: 0.2147 - val_accuracy: 0.9344\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2045 - accuracy: 0.9377 - val_loss: 0.2061 - val_accuracy: 0.9359\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2002 - accuracy: 0.9381 - val_loss: 0.2100 - val_accuracy: 0.9383\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1957 - accuracy: 0.9411 - val_loss: 0.2023 - val_accuracy: 0.9386\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1878 - accuracy: 0.9426 - val_loss: 0.1960 - val_accuracy: 0.9398\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1855 - accuracy: 0.9428 - val_loss: 0.1976 - val_accuracy: 0.9398\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1846 - accuracy: 0.9426 - val_loss: 0.2013 - val_accuracy: 0.9408\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1729 - accuracy: 0.9470 - val_loss: 0.1889 - val_accuracy: 0.9444\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1698 - accuracy: 0.9475 - val_loss: 0.1842 - val_accuracy: 0.9433\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1662 - accuracy: 0.9496 - val_loss: 0.1852 - val_accuracy: 0.9450\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1643 - accuracy: 0.9497 - val_loss: 0.1875 - val_accuracy: 0.9438\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1569 - accuracy: 0.9513 - val_loss: 0.1746 - val_accuracy: 0.9468\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134542_[64, 32]_0.0001_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134542_[64, 32]_0.0001_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134542_[64, 32]_0.0001_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.9109 - accuracy: 0.7380 - val_loss: 0.4369 - val_accuracy: 0.8919\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3944 - accuracy: 0.8960 - val_loss: 0.2884 - val_accuracy: 0.9268\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2856 - accuracy: 0.9225 - val_loss: 0.2255 - val_accuracy: 0.9399\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2302 - accuracy: 0.9362 - val_loss: 0.2094 - val_accuracy: 0.9488\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1936 - accuracy: 0.9463 - val_loss: 0.1720 - val_accuracy: 0.9517\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1671 - accuracy: 0.9530 - val_loss: 0.1537 - val_accuracy: 0.9572\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1462 - accuracy: 0.9581 - val_loss: 0.1820 - val_accuracy: 0.9597\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1295 - accuracy: 0.9638 - val_loss: 0.1422 - val_accuracy: 0.9607\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1161 - accuracy: 0.9673 - val_loss: 0.1296 - val_accuracy: 0.9631\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1040 - accuracy: 0.9715 - val_loss: 0.1418 - val_accuracy: 0.9638\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0938 - accuracy: 0.9739 - val_loss: 0.1248 - val_accuracy: 0.9651\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0853 - accuracy: 0.9767 - val_loss: 0.1243 - val_accuracy: 0.9660\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0773 - accuracy: 0.9801 - val_loss: 0.1264 - val_accuracy: 0.9657\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0692 - accuracy: 0.9819 - val_loss: 0.1326 - val_accuracy: 0.9646\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0631 - accuracy: 0.9839 - val_loss: 0.1446 - val_accuracy: 0.9656\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0569 - accuracy: 0.9856 - val_loss: 0.1391 - val_accuracy: 0.9650\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0514 - accuracy: 0.9876 - val_loss: 0.1614 - val_accuracy: 0.9657\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0464 - accuracy: 0.9896 - val_loss: 0.1357 - val_accuracy: 0.9658\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0418 - accuracy: 0.9906 - val_loss: 0.1661 - val_accuracy: 0.9655\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0372 - accuracy: 0.9924 - val_loss: 0.1268 - val_accuracy: 0.9659\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0338 - accuracy: 0.9934 - val_loss: 0.1935 - val_accuracy: 0.9657\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0299 - accuracy: 0.9943 - val_loss: 0.1442 - val_accuracy: 0.9656\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0268 - accuracy: 0.9953 - val_loss: 0.2415 - val_accuracy: 0.9661\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0243 - accuracy: 0.9958 - val_loss: 0.2362 - val_accuracy: 0.9640\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0216 - accuracy: 0.9965 - val_loss: 0.1470 - val_accuracy: 0.9666\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0185 - accuracy: 0.9971 - val_loss: 0.2498 - val_accuracy: 0.9657\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0166 - accuracy: 0.9975 - val_loss: 0.1847 - val_accuracy: 0.9662\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0148 - accuracy: 0.9983 - val_loss: 0.1939 - val_accuracy: 0.9646\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0128 - accuracy: 0.9986 - val_loss: 0.1893 - val_accuracy: 0.9645\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0112 - accuracy: 0.9989 - val_loss: 0.1897 - val_accuracy: 0.9650\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.1946 - val_accuracy: 0.9637\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 0.1799 - val_accuracy: 0.9634\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0071 - accuracy: 0.9996 - val_loss: 0.1677 - val_accuracy: 0.9644\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 0.1624 - val_accuracy: 0.9656\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.2096 - val_accuracy: 0.9648\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.2176 - val_accuracy: 0.9656\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.1588 - val_accuracy: 0.9661\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.2327 - val_accuracy: 0.9639\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.2153 - val_accuracy: 0.9657\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2405 - val_accuracy: 0.9620\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.2166 - val_accuracy: 0.9654\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.2492 - val_accuracy: 0.9647\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.1804 - val_accuracy: 0.9649\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.2027 - val_accuracy: 0.9654\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2155 - val_accuracy: 0.9617\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.1790 - val_accuracy: 0.9633\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2306 - val_accuracy: 0.9663\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.2371 - val_accuracy: 0.9592\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.2416 - val_accuracy: 0.9654\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 9.2745e-04 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9668\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134733_[64, 32]_0.0001_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134733_[64, 32]_0.0001_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_134733_[64, 32]_0.0001_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.2278 - accuracy: 0.6208 - val_loss: 0.6890 - val_accuracy: 0.7994\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5977 - accuracy: 0.8247 - val_loss: 0.4835 - val_accuracy: 0.8550\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4637 - accuracy: 0.8612 - val_loss: 0.3959 - val_accuracy: 0.8832\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3982 - accuracy: 0.8812 - val_loss: 0.3367 - val_accuracy: 0.9015\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3514 - accuracy: 0.8942 - val_loss: 0.3176 - val_accuracy: 0.9034\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3217 - accuracy: 0.9034 - val_loss: 0.2890 - val_accuracy: 0.9145\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2957 - accuracy: 0.9117 - val_loss: 0.2706 - val_accuracy: 0.9186\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2760 - accuracy: 0.9169 - val_loss: 0.2608 - val_accuracy: 0.9192\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2641 - accuracy: 0.9199 - val_loss: 0.2498 - val_accuracy: 0.9237\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2498 - accuracy: 0.9253 - val_loss: 0.2306 - val_accuracy: 0.9286\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2365 - accuracy: 0.9289 - val_loss: 0.2262 - val_accuracy: 0.9296\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2293 - accuracy: 0.9305 - val_loss: 0.2231 - val_accuracy: 0.9314\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2191 - accuracy: 0.9344 - val_loss: 0.2182 - val_accuracy: 0.9331\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2132 - accuracy: 0.9353 - val_loss: 0.2179 - val_accuracy: 0.9330\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2044 - accuracy: 0.9386 - val_loss: 0.2103 - val_accuracy: 0.9354\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2003 - accuracy: 0.9391 - val_loss: 0.2024 - val_accuracy: 0.9362\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1920 - accuracy: 0.9415 - val_loss: 0.1994 - val_accuracy: 0.9378\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1831 - accuracy: 0.9435 - val_loss: 0.1888 - val_accuracy: 0.9423\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1800 - accuracy: 0.9444 - val_loss: 0.1975 - val_accuracy: 0.9396\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1744 - accuracy: 0.9467 - val_loss: 0.1920 - val_accuracy: 0.9407\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1724 - accuracy: 0.9470 - val_loss: 0.1937 - val_accuracy: 0.9408\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1692 - accuracy: 0.9488 - val_loss: 0.1853 - val_accuracy: 0.9446\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1641 - accuracy: 0.9506 - val_loss: 0.1818 - val_accuracy: 0.9442\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1569 - accuracy: 0.9524 - val_loss: 0.1793 - val_accuracy: 0.9458\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1598 - accuracy: 0.9513 - val_loss: 0.1822 - val_accuracy: 0.9417\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1526 - accuracy: 0.9536 - val_loss: 0.1824 - val_accuracy: 0.9447\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1468 - accuracy: 0.9554 - val_loss: 0.1792 - val_accuracy: 0.9442\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1475 - accuracy: 0.9554 - val_loss: 0.1754 - val_accuracy: 0.9488\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1449 - accuracy: 0.9561 - val_loss: 0.1776 - val_accuracy: 0.9466\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1437 - accuracy: 0.9562 - val_loss: 0.1732 - val_accuracy: 0.9484\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1379 - accuracy: 0.9576 - val_loss: 0.1741 - val_accuracy: 0.9466\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1335 - accuracy: 0.9594 - val_loss: 0.1677 - val_accuracy: 0.9503\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1325 - accuracy: 0.9593 - val_loss: 0.1688 - val_accuracy: 0.9488\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1277 - accuracy: 0.9612 - val_loss: 0.1772 - val_accuracy: 0.9480\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1322 - accuracy: 0.9601 - val_loss: 0.1682 - val_accuracy: 0.9482\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1275 - accuracy: 0.9607 - val_loss: 0.1664 - val_accuracy: 0.9483\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1264 - accuracy: 0.9615 - val_loss: 0.1570 - val_accuracy: 0.9534\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1180 - accuracy: 0.9646 - val_loss: 0.1646 - val_accuracy: 0.9503\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1205 - accuracy: 0.9630 - val_loss: 0.1630 - val_accuracy: 0.9510\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1200 - accuracy: 0.9630 - val_loss: 0.1558 - val_accuracy: 0.9529\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1152 - accuracy: 0.9647 - val_loss: 0.1588 - val_accuracy: 0.9518\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1149 - accuracy: 0.9644 - val_loss: 0.1548 - val_accuracy: 0.9532\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1100 - accuracy: 0.9659 - val_loss: 0.1584 - val_accuracy: 0.9529\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1092 - accuracy: 0.9668 - val_loss: 0.1570 - val_accuracy: 0.9523\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1095 - accuracy: 0.9670 - val_loss: 0.1615 - val_accuracy: 0.9488\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1054 - accuracy: 0.9678 - val_loss: 0.1610 - val_accuracy: 0.9523\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1038 - accuracy: 0.9676 - val_loss: 0.1615 - val_accuracy: 0.9513\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1024 - accuracy: 0.9689 - val_loss: 0.1549 - val_accuracy: 0.9538\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1024 - accuracy: 0.9688 - val_loss: 0.1651 - val_accuracy: 0.9515\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0996 - accuracy: 0.9693 - val_loss: 0.1560 - val_accuracy: 0.9552\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135117_[64, 32]_0.0001_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135117_[64, 32]_0.0001_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135117_[64, 32]_0.0001_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4416 - accuracy: 0.8791 - val_loss: 0.1941 - val_accuracy: 0.9452\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2022 - accuracy: 0.9406 - val_loss: 0.1560 - val_accuracy: 0.9551\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1614 - accuracy: 0.9521 - val_loss: 0.1453 - val_accuracy: 0.9575\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1380 - accuracy: 0.9583 - val_loss: 0.1307 - val_accuracy: 0.9603\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1221 - accuracy: 0.9632 - val_loss: 0.1314 - val_accuracy: 0.9600\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1100 - accuracy: 0.9666 - val_loss: 0.1195 - val_accuracy: 0.9632\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1000 - accuracy: 0.9699 - val_loss: 0.1209 - val_accuracy: 0.9639\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0944 - accuracy: 0.9702 - val_loss: 0.1279 - val_accuracy: 0.9631\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0849 - accuracy: 0.9735 - val_loss: 0.1384 - val_accuracy: 0.9603\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9751 - val_loss: 0.1292 - val_accuracy: 0.9644\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135502_[32, 16]_0.001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135502_[32, 16]_0.001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135502_[32, 16]_0.001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.8633 - accuracy: 0.7243 - val_loss: 0.7175 - val_accuracy: 0.7716\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5795 - accuracy: 0.8148 - val_loss: 0.5567 - val_accuracy: 0.8158\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5034 - accuracy: 0.8443 - val_loss: 0.4509 - val_accuracy: 0.8608\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5041 - accuracy: 0.8410 - val_loss: 0.4697 - val_accuracy: 0.8542\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4644 - accuracy: 0.8587 - val_loss: 0.3828 - val_accuracy: 0.8823\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4225 - accuracy: 0.8714 - val_loss: 0.4034 - val_accuracy: 0.8736\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4416 - accuracy: 0.8644 - val_loss: 0.3881 - val_accuracy: 0.8827\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4163 - accuracy: 0.8728 - val_loss: 0.3452 - val_accuracy: 0.8969\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3799 - accuracy: 0.8855 - val_loss: 0.3562 - val_accuracy: 0.8923\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3951 - accuracy: 0.8797 - val_loss: 0.3498 - val_accuracy: 0.8952\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135550_[32, 16]_0.001_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135550_[32, 16]_0.001_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135550_[32, 16]_0.001_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4515 - accuracy: 0.8779 - val_loss: 0.2011 - val_accuracy: 0.9404\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2069 - accuracy: 0.9398 - val_loss: 0.1721 - val_accuracy: 0.9492\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1669 - accuracy: 0.9494 - val_loss: 0.1407 - val_accuracy: 0.9575\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1413 - accuracy: 0.9574 - val_loss: 0.1348 - val_accuracy: 0.9586\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1254 - accuracy: 0.9612 - val_loss: 0.1264 - val_accuracy: 0.9628\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1128 - accuracy: 0.9648 - val_loss: 0.1248 - val_accuracy: 0.9652\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1016 - accuracy: 0.9678 - val_loss: 0.1255 - val_accuracy: 0.9637\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0913 - accuracy: 0.9716 - val_loss: 0.1268 - val_accuracy: 0.9643\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0862 - accuracy: 0.9734 - val_loss: 0.1361 - val_accuracy: 0.9623\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0802 - accuracy: 0.9744 - val_loss: 0.1199 - val_accuracy: 0.9663\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0729 - accuracy: 0.9767 - val_loss: 0.1251 - val_accuracy: 0.9663\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 0.1273 - val_accuracy: 0.9660\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0639 - accuracy: 0.9799 - val_loss: 0.1271 - val_accuracy: 0.9670\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0579 - accuracy: 0.9818 - val_loss: 0.1416 - val_accuracy: 0.9619\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0555 - accuracy: 0.9818 - val_loss: 0.1435 - val_accuracy: 0.9622\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0516 - accuracy: 0.9838 - val_loss: 0.1493 - val_accuracy: 0.9628\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0483 - accuracy: 0.9845 - val_loss: 0.1401 - val_accuracy: 0.9641\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0453 - accuracy: 0.9858 - val_loss: 0.1498 - val_accuracy: 0.9632\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0421 - accuracy: 0.9868 - val_loss: 0.1593 - val_accuracy: 0.9629\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 996s 665ms/step - loss: 0.0406 - accuracy: 0.9870 - val_loss: 0.1423 - val_accuracy: 0.9652\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.1540 - val_accuracy: 0.9661\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0360 - accuracy: 0.9884 - val_loss: 0.1545 - val_accuracy: 0.9645\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 0.1659 - val_accuracy: 0.9628\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 0.1734 - val_accuracy: 0.9605\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.1748 - val_accuracy: 0.9619\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135637_[32, 16]_0.001_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135637_[32, 16]_0.001_25_relu\\params_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnguyen6\\AppData\\Local\\Temp\\ipykernel_43088\\934920084.py:14: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig = plt.figure(figsize=(half_length * 5,5))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_135637_[32, 16]_0.001_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.8540 - accuracy: 0.7305 - val_loss: 0.5689 - val_accuracy: 0.8242\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5647 - accuracy: 0.8289 - val_loss: 0.5023 - val_accuracy: 0.8459\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5540 - accuracy: 0.8260 - val_loss: 0.4977 - val_accuracy: 0.8432\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5386 - accuracy: 0.8334 - val_loss: 0.4588 - val_accuracy: 0.8622\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5026 - accuracy: 0.8426 - val_loss: 0.4833 - val_accuracy: 0.8448\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4664 - accuracy: 0.8567 - val_loss: 0.4326 - val_accuracy: 0.8683\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4348 - accuracy: 0.8657 - val_loss: 0.3813 - val_accuracy: 0.8852\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3999 - accuracy: 0.8794 - val_loss: 0.3766 - val_accuracy: 0.8848\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4025 - accuracy: 0.8768 - val_loss: 0.3786 - val_accuracy: 0.8831\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3782 - accuracy: 0.8856 - val_loss: 0.3723 - val_accuracy: 0.8829\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3704 - accuracy: 0.8878 - val_loss: 0.3974 - val_accuracy: 0.8800\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3837 - accuracy: 0.8847 - val_loss: 0.3905 - val_accuracy: 0.8823\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3859 - accuracy: 0.8841 - val_loss: 0.3679 - val_accuracy: 0.8877\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3548 - accuracy: 0.8919 - val_loss: 0.3502 - val_accuracy: 0.8970\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3791 - accuracy: 0.8861 - val_loss: 0.3639 - val_accuracy: 0.8881\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3688 - accuracy: 0.8897 - val_loss: 0.3422 - val_accuracy: 0.8977\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3661 - accuracy: 0.8922 - val_loss: 0.3638 - val_accuracy: 0.8925\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3486 - accuracy: 0.8960 - val_loss: 0.3322 - val_accuracy: 0.8998\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3545 - accuracy: 0.8941 - val_loss: 0.3225 - val_accuracy: 0.9035\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3626 - accuracy: 0.8889 - val_loss: 0.3414 - val_accuracy: 0.8988\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3648 - accuracy: 0.8899 - val_loss: 0.3489 - val_accuracy: 0.8986\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3293 - accuracy: 0.9018 - val_loss: 0.3078 - val_accuracy: 0.9109\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3371 - accuracy: 0.8999 - val_loss: 0.3273 - val_accuracy: 0.9031\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3312 - accuracy: 0.9019 - val_loss: 0.3258 - val_accuracy: 0.9041\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3282 - accuracy: 0.9012 - val_loss: 0.3056 - val_accuracy: 0.9074\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_141507_[32, 16]_0.001_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_141507_[32, 16]_0.001_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_141507_[32, 16]_0.001_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4370 - accuracy: 0.8771 - val_loss: 0.2261 - val_accuracy: 0.9314\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2143 - accuracy: 0.9372 - val_loss: 0.1780 - val_accuracy: 0.9432\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1702 - accuracy: 0.9503 - val_loss: 0.1535 - val_accuracy: 0.9525\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1450 - accuracy: 0.9559 - val_loss: 0.1452 - val_accuracy: 0.9559\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1286 - accuracy: 0.9614 - val_loss: 0.1321 - val_accuracy: 0.9588\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1137 - accuracy: 0.9657 - val_loss: 0.1291 - val_accuracy: 0.9612\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1047 - accuracy: 0.9675 - val_loss: 0.1248 - val_accuracy: 0.9630\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0950 - accuracy: 0.9710 - val_loss: 0.1443 - val_accuracy: 0.9561\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0872 - accuracy: 0.9726 - val_loss: 0.1365 - val_accuracy: 0.9588\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9741 - val_loss: 0.1375 - val_accuracy: 0.9610\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0735 - accuracy: 0.9772 - val_loss: 0.1423 - val_accuracy: 0.9578\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0703 - accuracy: 0.9773 - val_loss: 0.1391 - val_accuracy: 0.9603\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0659 - accuracy: 0.9787 - val_loss: 0.1405 - val_accuracy: 0.9607\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0604 - accuracy: 0.9810 - val_loss: 0.1362 - val_accuracy: 0.9613\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0582 - accuracy: 0.9812 - val_loss: 0.1449 - val_accuracy: 0.9606\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.1516 - val_accuracy: 0.9610\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0508 - accuracy: 0.9831 - val_loss: 0.1549 - val_accuracy: 0.9597\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0462 - accuracy: 0.9848 - val_loss: 0.1438 - val_accuracy: 0.9627\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.1561 - val_accuracy: 0.9607\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.1735 - val_accuracy: 0.9587\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0401 - accuracy: 0.9867 - val_loss: 0.1622 - val_accuracy: 0.9617\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0357 - accuracy: 0.9883 - val_loss: 0.1622 - val_accuracy: 0.9615\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 0.1694 - val_accuracy: 0.9611\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 0.1809 - val_accuracy: 0.9592\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0320 - accuracy: 0.9897 - val_loss: 0.1753 - val_accuracy: 0.9598\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 0.1808 - val_accuracy: 0.9597\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0274 - accuracy: 0.9910 - val_loss: 0.1948 - val_accuracy: 0.9581\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.2006 - val_accuracy: 0.9571\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.1902 - val_accuracy: 0.9603\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.2043 - val_accuracy: 0.9598\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.1922 - val_accuracy: 0.9607\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.2086 - val_accuracy: 0.9599\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.2160 - val_accuracy: 0.9580\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.2138 - val_accuracy: 0.9587\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.2134 - val_accuracy: 0.9611\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.2193 - val_accuracy: 0.9583\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.2277 - val_accuracy: 0.9582\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.2334 - val_accuracy: 0.9573\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.2176 - val_accuracy: 0.9604\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0174 - accuracy: 0.9942 - val_loss: 0.2380 - val_accuracy: 0.9572\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0169 - accuracy: 0.9945 - val_loss: 0.2330 - val_accuracy: 0.9596\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.2225 - val_accuracy: 0.9613\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.2344 - val_accuracy: 0.9595\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.2456 - val_accuracy: 0.9597\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.2413 - val_accuracy: 0.9597\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.2382 - val_accuracy: 0.9607\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0125 - accuracy: 0.9959 - val_loss: 0.2653 - val_accuracy: 0.9574\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.2454 - val_accuracy: 0.9603\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.2646 - val_accuracy: 0.9594\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.2534 - val_accuracy: 0.9589\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_141657_[32, 16]_0.001_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_141657_[32, 16]_0.001_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_141657_[32, 16]_0.001_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.8686 - accuracy: 0.7258 - val_loss: 0.6504 - val_accuracy: 0.7995\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5679 - accuracy: 0.8241 - val_loss: 0.4865 - val_accuracy: 0.8506\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5091 - accuracy: 0.8458 - val_loss: 0.4593 - val_accuracy: 0.8588\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4732 - accuracy: 0.8576 - val_loss: 0.4823 - val_accuracy: 0.8518\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5047 - accuracy: 0.8405 - val_loss: 0.4335 - val_accuracy: 0.8659\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4559 - accuracy: 0.8622 - val_loss: 0.4108 - val_accuracy: 0.8751\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4513 - accuracy: 0.8638 - val_loss: 0.4297 - val_accuracy: 0.8638\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4175 - accuracy: 0.8736 - val_loss: 0.3811 - val_accuracy: 0.8850\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4042 - accuracy: 0.8775 - val_loss: 0.3957 - val_accuracy: 0.8844\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3920 - accuracy: 0.8842 - val_loss: 0.3565 - val_accuracy: 0.8898\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3928 - accuracy: 0.8828 - val_loss: 0.3735 - val_accuracy: 0.8900\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3909 - accuracy: 0.8814 - val_loss: 0.4033 - val_accuracy: 0.8730\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3755 - accuracy: 0.8871 - val_loss: 0.3773 - val_accuracy: 0.8830\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3863 - accuracy: 0.8843 - val_loss: 0.3281 - val_accuracy: 0.9013\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3508 - accuracy: 0.8954 - val_loss: 0.3487 - val_accuracy: 0.8948\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3613 - accuracy: 0.8907 - val_loss: 0.3391 - val_accuracy: 0.8992\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3489 - accuracy: 0.8965 - val_loss: 0.4033 - val_accuracy: 0.8846\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3534 - accuracy: 0.8943 - val_loss: 0.3057 - val_accuracy: 0.9060\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3632 - accuracy: 0.8882 - val_loss: 0.3387 - val_accuracy: 0.8966\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3630 - accuracy: 0.8930 - val_loss: 0.3445 - val_accuracy: 0.8966\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3550 - accuracy: 0.8931 - val_loss: 0.3568 - val_accuracy: 0.8909\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3358 - accuracy: 0.8991 - val_loss: 0.3180 - val_accuracy: 0.9046\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3343 - accuracy: 0.8990 - val_loss: 0.3568 - val_accuracy: 0.9065\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3249 - accuracy: 0.9043 - val_loss: 0.3103 - val_accuracy: 0.9099\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3155 - accuracy: 0.9054 - val_loss: 0.3039 - val_accuracy: 0.9091\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3284 - accuracy: 0.9019 - val_loss: 0.3090 - val_accuracy: 0.9081\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3229 - accuracy: 0.9040 - val_loss: 0.2908 - val_accuracy: 0.9147\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3175 - accuracy: 0.9047 - val_loss: 0.3026 - val_accuracy: 0.9082\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3098 - accuracy: 0.9073 - val_loss: 0.2997 - val_accuracy: 0.9092\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3123 - accuracy: 0.9086 - val_loss: 0.3001 - val_accuracy: 0.9100\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3114 - accuracy: 0.9056 - val_loss: 0.2808 - val_accuracy: 0.9157\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3183 - accuracy: 0.9075 - val_loss: 0.3025 - val_accuracy: 0.9100\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3099 - accuracy: 0.9085 - val_loss: 0.2930 - val_accuracy: 0.9126\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3125 - accuracy: 0.9075 - val_loss: 0.3151 - val_accuracy: 0.9000\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3107 - accuracy: 0.9069 - val_loss: 0.2891 - val_accuracy: 0.9164\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3102 - accuracy: 0.9087 - val_loss: 0.2916 - val_accuracy: 0.9134\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3031 - accuracy: 0.9092 - val_loss: 0.2767 - val_accuracy: 0.9181\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3148 - accuracy: 0.9059 - val_loss: 0.2880 - val_accuracy: 0.9143\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3096 - accuracy: 0.9083 - val_loss: 0.2837 - val_accuracy: 0.9158\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3043 - accuracy: 0.9092 - val_loss: 0.2916 - val_accuracy: 0.9110\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2875 - accuracy: 0.9150 - val_loss: 0.2695 - val_accuracy: 0.9193\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2862 - accuracy: 0.9142 - val_loss: 0.2624 - val_accuracy: 0.9237\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2966 - accuracy: 0.9119 - val_loss: 0.2776 - val_accuracy: 0.9165\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2947 - accuracy: 0.9119 - val_loss: 0.2712 - val_accuracy: 0.9212\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2852 - accuracy: 0.9138 - val_loss: 0.2616 - val_accuracy: 0.9207\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2860 - accuracy: 0.9144 - val_loss: 0.2699 - val_accuracy: 0.9181\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3043 - accuracy: 0.9094 - val_loss: 0.2800 - val_accuracy: 0.9178\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2899 - accuracy: 0.9134 - val_loss: 0.2590 - val_accuracy: 0.9248\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2814 - accuracy: 0.9159 - val_loss: 0.2684 - val_accuracy: 0.9218\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2808 - accuracy: 0.9161 - val_loss: 0.2810 - val_accuracy: 0.9166\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142056_[32, 16]_0.001_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142056_[32, 16]_0.001_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142056_[32, 16]_0.001_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.5550 - accuracy: 0.8481 - val_loss: 0.2370 - val_accuracy: 0.9339\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2400 - accuracy: 0.9313 - val_loss: 0.1727 - val_accuracy: 0.9497\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1823 - accuracy: 0.9459 - val_loss: 0.1463 - val_accuracy: 0.9562\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1541 - accuracy: 0.9545 - val_loss: 0.1330 - val_accuracy: 0.9602\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1326 - accuracy: 0.9603 - val_loss: 0.1253 - val_accuracy: 0.9612\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1199 - accuracy: 0.9639 - val_loss: 0.1277 - val_accuracy: 0.9605\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1069 - accuracy: 0.9679 - val_loss: 0.1216 - val_accuracy: 0.9628\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0974 - accuracy: 0.9703 - val_loss: 0.1197 - val_accuracy: 0.9642\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0897 - accuracy: 0.9713 - val_loss: 0.1281 - val_accuracy: 0.9608\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0832 - accuracy: 0.9748 - val_loss: 0.1148 - val_accuracy: 0.9668\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142457_[32, 16]_0.0005_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142457_[32, 16]_0.0005_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142457_[32, 16]_0.0005_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.0160 - accuracy: 0.6900 - val_loss: 0.5759 - val_accuracy: 0.8310\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5477 - accuracy: 0.8388 - val_loss: 0.4302 - val_accuracy: 0.8764\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4679 - accuracy: 0.8588 - val_loss: 0.4006 - val_accuracy: 0.8842\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4331 - accuracy: 0.8722 - val_loss: 0.3860 - val_accuracy: 0.8822\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4048 - accuracy: 0.8802 - val_loss: 0.3577 - val_accuracy: 0.8937\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3745 - accuracy: 0.8894 - val_loss: 0.4065 - val_accuracy: 0.8790\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3613 - accuracy: 0.8938 - val_loss: 0.3248 - val_accuracy: 0.9066\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3467 - accuracy: 0.8955 - val_loss: 0.3123 - val_accuracy: 0.9075\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3376 - accuracy: 0.9000 - val_loss: 0.3245 - val_accuracy: 0.9038\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3174 - accuracy: 0.9071 - val_loss: 0.3273 - val_accuracy: 0.9046\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142545_[32, 16]_0.0005_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142545_[32, 16]_0.0005_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142545_[32, 16]_0.0005_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5512 - accuracy: 0.8505 - val_loss: 0.2485 - val_accuracy: 0.9320\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2441 - accuracy: 0.9300 - val_loss: 0.1773 - val_accuracy: 0.9474\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1876 - accuracy: 0.9450 - val_loss: 0.1549 - val_accuracy: 0.9562\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1586 - accuracy: 0.9526 - val_loss: 0.1447 - val_accuracy: 0.9565\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1393 - accuracy: 0.9585 - val_loss: 0.1425 - val_accuracy: 0.9586\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1243 - accuracy: 0.9624 - val_loss: 0.1373 - val_accuracy: 0.9588\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1140 - accuracy: 0.9650 - val_loss: 0.1295 - val_accuracy: 0.9618\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1035 - accuracy: 0.9686 - val_loss: 0.1327 - val_accuracy: 0.9613\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0957 - accuracy: 0.9707 - val_loss: 0.1434 - val_accuracy: 0.9581\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0887 - accuracy: 0.9729 - val_loss: 0.1313 - val_accuracy: 0.9612\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0817 - accuracy: 0.9744 - val_loss: 0.1386 - val_accuracy: 0.9597\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0762 - accuracy: 0.9764 - val_loss: 0.1450 - val_accuracy: 0.9591\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.1368 - val_accuracy: 0.9602\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0648 - accuracy: 0.9799 - val_loss: 0.1337 - val_accuracy: 0.9630\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0620 - accuracy: 0.9808 - val_loss: 0.1388 - val_accuracy: 0.9613\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0577 - accuracy: 0.9823 - val_loss: 0.1390 - val_accuracy: 0.9637\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0542 - accuracy: 0.9832 - val_loss: 0.1424 - val_accuracy: 0.9621\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0507 - accuracy: 0.9840 - val_loss: 0.1591 - val_accuracy: 0.9592\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0469 - accuracy: 0.9854 - val_loss: 0.1474 - val_accuracy: 0.9631\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0443 - accuracy: 0.9861 - val_loss: 0.1525 - val_accuracy: 0.9609\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.1616 - val_accuracy: 0.9592\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 0.1634 - val_accuracy: 0.9590\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.1756 - val_accuracy: 0.9587\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0336 - accuracy: 0.9900 - val_loss: 0.1647 - val_accuracy: 0.9615\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.1731 - val_accuracy: 0.9610\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142626_[32, 16]_0.0005_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142626_[32, 16]_0.0005_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142626_[32, 16]_0.0005_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.9645 - accuracy: 0.7003 - val_loss: 0.5902 - val_accuracy: 0.8235\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5418 - accuracy: 0.8341 - val_loss: 0.4457 - val_accuracy: 0.8637\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4730 - accuracy: 0.8539 - val_loss: 0.4228 - val_accuracy: 0.8697\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4256 - accuracy: 0.8697 - val_loss: 0.3879 - val_accuracy: 0.8846\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3886 - accuracy: 0.8817 - val_loss: 0.3337 - val_accuracy: 0.8972\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3762 - accuracy: 0.8844 - val_loss: 0.3214 - val_accuracy: 0.9028\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3711 - accuracy: 0.8863 - val_loss: 0.3329 - val_accuracy: 0.8963\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3597 - accuracy: 0.8895 - val_loss: 0.3247 - val_accuracy: 0.9011\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3466 - accuracy: 0.8952 - val_loss: 0.3287 - val_accuracy: 0.8999\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3372 - accuracy: 0.8979 - val_loss: 0.2878 - val_accuracy: 0.9143\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3193 - accuracy: 0.9039 - val_loss: 0.2954 - val_accuracy: 0.9102\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3111 - accuracy: 0.9070 - val_loss: 0.2982 - val_accuracy: 0.9119\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3150 - accuracy: 0.9042 - val_loss: 0.2673 - val_accuracy: 0.9183\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3053 - accuracy: 0.9085 - val_loss: 0.2792 - val_accuracy: 0.9136\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2994 - accuracy: 0.9092 - val_loss: 0.2712 - val_accuracy: 0.9201\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2986 - accuracy: 0.9099 - val_loss: 0.2654 - val_accuracy: 0.9205\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2909 - accuracy: 0.9118 - val_loss: 0.2724 - val_accuracy: 0.9187\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2788 - accuracy: 0.9147 - val_loss: 0.2733 - val_accuracy: 0.9202\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2856 - accuracy: 0.9144 - val_loss: 0.2759 - val_accuracy: 0.9179\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2864 - accuracy: 0.9146 - val_loss: 0.2556 - val_accuracy: 0.9247\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2719 - accuracy: 0.9177 - val_loss: 0.2607 - val_accuracy: 0.9223\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2709 - accuracy: 0.9193 - val_loss: 0.2536 - val_accuracy: 0.9223\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2717 - accuracy: 0.9193 - val_loss: 0.2497 - val_accuracy: 0.9265\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2592 - accuracy: 0.9226 - val_loss: 0.2607 - val_accuracy: 0.9204\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2629 - accuracy: 0.9221 - val_loss: 0.2363 - val_accuracy: 0.9321\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142808_[32, 16]_0.0005_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142808_[32, 16]_0.0005_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142808_[32, 16]_0.0005_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6081 - accuracy: 0.8347 - val_loss: 0.2575 - val_accuracy: 0.9295\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2591 - accuracy: 0.9255 - val_loss: 0.1870 - val_accuracy: 0.9447\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1976 - accuracy: 0.9428 - val_loss: 0.1705 - val_accuracy: 0.9492\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1662 - accuracy: 0.9512 - val_loss: 0.1513 - val_accuracy: 0.9549\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1451 - accuracy: 0.9565 - val_loss: 0.1401 - val_accuracy: 0.9566\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1278 - accuracy: 0.9625 - val_loss: 0.1394 - val_accuracy: 0.9592\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1140 - accuracy: 0.9657 - val_loss: 0.1322 - val_accuracy: 0.9611\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1043 - accuracy: 0.9691 - val_loss: 0.1333 - val_accuracy: 0.9589\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0962 - accuracy: 0.9710 - val_loss: 0.1283 - val_accuracy: 0.9614\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0877 - accuracy: 0.9734 - val_loss: 0.1358 - val_accuracy: 0.9602\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0809 - accuracy: 0.9758 - val_loss: 0.1363 - val_accuracy: 0.9603\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0763 - accuracy: 0.9771 - val_loss: 0.1327 - val_accuracy: 0.9615\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0689 - accuracy: 0.9788 - val_loss: 0.1347 - val_accuracy: 0.9607\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0650 - accuracy: 0.9805 - val_loss: 0.1323 - val_accuracy: 0.9625\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.1336 - val_accuracy: 0.9638\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0561 - accuracy: 0.9829 - val_loss: 0.1338 - val_accuracy: 0.9636\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0531 - accuracy: 0.9845 - val_loss: 0.1359 - val_accuracy: 0.9628\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0491 - accuracy: 0.9853 - val_loss: 0.1484 - val_accuracy: 0.9611\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.1488 - val_accuracy: 0.9617\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0442 - accuracy: 0.9868 - val_loss: 0.1498 - val_accuracy: 0.9602\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.1520 - val_accuracy: 0.9620\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.1562 - val_accuracy: 0.9595\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 0.1549 - val_accuracy: 0.9600\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.1564 - val_accuracy: 0.9612\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0326 - accuracy: 0.9906 - val_loss: 0.1574 - val_accuracy: 0.9622\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.1770 - val_accuracy: 0.9590\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.1699 - val_accuracy: 0.9622\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.1722 - val_accuracy: 0.9616\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.1841 - val_accuracy: 0.9594\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0250 - accuracy: 0.9925 - val_loss: 0.1785 - val_accuracy: 0.9606\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.1899 - val_accuracy: 0.9591\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0219 - accuracy: 0.9936 - val_loss: 0.1783 - val_accuracy: 0.9636\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.1919 - val_accuracy: 0.9595\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0209 - accuracy: 0.9939 - val_loss: 0.1878 - val_accuracy: 0.9612\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.1946 - val_accuracy: 0.9613\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 0.1839 - val_accuracy: 0.9613\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0172 - accuracy: 0.9948 - val_loss: 0.2176 - val_accuracy: 0.9564\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 0.2029 - val_accuracy: 0.9612\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.2156 - val_accuracy: 0.9588\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.2068 - val_accuracy: 0.9600\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.2192 - val_accuracy: 0.9586\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.2334 - val_accuracy: 0.9553\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.2113 - val_accuracy: 0.9605\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.2344 - val_accuracy: 0.9580\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.2129 - val_accuracy: 0.9623\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.2221 - val_accuracy: 0.9610\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.2255 - val_accuracy: 0.9607\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.2456 - val_accuracy: 0.9591\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.2282 - val_accuracy: 0.9617\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.2541 - val_accuracy: 0.9570\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142950_[32, 16]_0.0005_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142950_[32, 16]_0.0005_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_142950_[32, 16]_0.0005_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.9328 - accuracy: 0.7091 - val_loss: 0.5758 - val_accuracy: 0.8263\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5139 - accuracy: 0.8441 - val_loss: 0.4427 - val_accuracy: 0.8676\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4378 - accuracy: 0.8676 - val_loss: 0.3779 - val_accuracy: 0.8872\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4006 - accuracy: 0.8794 - val_loss: 0.3816 - val_accuracy: 0.8841\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3827 - accuracy: 0.8848 - val_loss: 0.3786 - val_accuracy: 0.8836\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3571 - accuracy: 0.8931 - val_loss: 0.3473 - val_accuracy: 0.8944\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3498 - accuracy: 0.8958 - val_loss: 0.3707 - val_accuracy: 0.8836\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3335 - accuracy: 0.9011 - val_loss: 0.2863 - val_accuracy: 0.9129\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3172 - accuracy: 0.9074 - val_loss: 0.3039 - val_accuracy: 0.9096\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3193 - accuracy: 0.9058 - val_loss: 0.2980 - val_accuracy: 0.9111\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.3312 - accuracy: 0.8991 - val_loss: 0.2939 - val_accuracy: 0.9117\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3035 - accuracy: 0.9093 - val_loss: 0.2705 - val_accuracy: 0.9192\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2935 - accuracy: 0.9111 - val_loss: 0.2765 - val_accuracy: 0.9152\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2983 - accuracy: 0.9093 - val_loss: 0.2615 - val_accuracy: 0.9232\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2900 - accuracy: 0.9128 - val_loss: 0.2613 - val_accuracy: 0.9190\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2829 - accuracy: 0.9156 - val_loss: 0.2588 - val_accuracy: 0.9251\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2809 - accuracy: 0.9158 - val_loss: 0.2657 - val_accuracy: 0.9224\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2736 - accuracy: 0.9187 - val_loss: 0.2501 - val_accuracy: 0.9241\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2641 - accuracy: 0.9225 - val_loss: 0.2401 - val_accuracy: 0.9291\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2633 - accuracy: 0.9221 - val_loss: 0.2562 - val_accuracy: 0.9215\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2658 - accuracy: 0.9202 - val_loss: 0.2466 - val_accuracy: 0.9256\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2646 - accuracy: 0.9199 - val_loss: 0.2653 - val_accuracy: 0.9183\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2708 - accuracy: 0.9184 - val_loss: 0.2337 - val_accuracy: 0.9305\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2460 - accuracy: 0.9264 - val_loss: 0.2317 - val_accuracy: 0.9341\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2484 - accuracy: 0.9255 - val_loss: 0.2471 - val_accuracy: 0.9270\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2588 - accuracy: 0.9229 - val_loss: 0.2382 - val_accuracy: 0.9298\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2471 - accuracy: 0.9258 - val_loss: 0.2413 - val_accuracy: 0.9292\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2448 - accuracy: 0.9279 - val_loss: 0.2241 - val_accuracy: 0.9330\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2539 - accuracy: 0.9246 - val_loss: 0.2533 - val_accuracy: 0.9251\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2462 - accuracy: 0.9258 - val_loss: 0.2384 - val_accuracy: 0.9288\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2457 - accuracy: 0.9256 - val_loss: 0.2246 - val_accuracy: 0.9303\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2419 - accuracy: 0.9271 - val_loss: 0.2321 - val_accuracy: 0.9286\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2382 - accuracy: 0.9288 - val_loss: 0.2161 - val_accuracy: 0.9367\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2310 - accuracy: 0.9311 - val_loss: 0.2263 - val_accuracy: 0.9319\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2320 - accuracy: 0.9319 - val_loss: 0.2082 - val_accuracy: 0.9389\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2180 - accuracy: 0.9360 - val_loss: 0.2181 - val_accuracy: 0.9355\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2247 - accuracy: 0.9335 - val_loss: 0.2171 - val_accuracy: 0.9345\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2281 - accuracy: 0.9332 - val_loss: 0.2217 - val_accuracy: 0.9352\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2261 - accuracy: 0.9339 - val_loss: 0.2263 - val_accuracy: 0.9352\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2195 - accuracy: 0.9359 - val_loss: 0.2230 - val_accuracy: 0.9311\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2314 - accuracy: 0.9312 - val_loss: 0.2047 - val_accuracy: 0.9393\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2136 - accuracy: 0.9369 - val_loss: 0.1966 - val_accuracy: 0.9419\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2155 - accuracy: 0.9360 - val_loss: 0.2114 - val_accuracy: 0.9375\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2198 - accuracy: 0.9342 - val_loss: 0.2160 - val_accuracy: 0.9338\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2175 - accuracy: 0.9353 - val_loss: 0.2007 - val_accuracy: 0.9389\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2092 - accuracy: 0.9361 - val_loss: 0.2077 - val_accuracy: 0.9392\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2033 - accuracy: 0.9384 - val_loss: 0.2100 - val_accuracy: 0.9380\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2093 - accuracy: 0.9371 - val_loss: 0.2055 - val_accuracy: 0.9388\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2094 - accuracy: 0.9376 - val_loss: 0.2143 - val_accuracy: 0.9364\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2059 - accuracy: 0.9399 - val_loss: 0.2102 - val_accuracy: 0.9384\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143316_[32, 16]_0.0005_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143316_[32, 16]_0.0005_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143316_[32, 16]_0.0005_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.1637 - accuracy: 0.6830 - val_loss: 0.6457 - val_accuracy: 0.8657\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5746 - accuracy: 0.8665 - val_loss: 0.4000 - val_accuracy: 0.9074\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4008 - accuracy: 0.8978 - val_loss: 0.3037 - val_accuracy: 0.9243\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3219 - accuracy: 0.9143 - val_loss: 0.2495 - val_accuracy: 0.9327\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2761 - accuracy: 0.9245 - val_loss: 0.2261 - val_accuracy: 0.9393\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2467 - accuracy: 0.9322 - val_loss: 0.2041 - val_accuracy: 0.9424\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2244 - accuracy: 0.9374 - val_loss: 0.1914 - val_accuracy: 0.9475\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2075 - accuracy: 0.9408 - val_loss: 0.1825 - val_accuracy: 0.9483\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1940 - accuracy: 0.9448 - val_loss: 0.1812 - val_accuracy: 0.9515\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1813 - accuracy: 0.9485 - val_loss: 0.1714 - val_accuracy: 0.9523\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143636_[32, 16]_0.0001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143636_[32, 16]_0.0001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143636_[32, 16]_0.0001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.6670 - accuracy: 0.4622 - val_loss: 1.1007 - val_accuracy: 0.6826\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.9233 - accuracy: 0.7433 - val_loss: 0.7061 - val_accuracy: 0.8052\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6556 - accuracy: 0.8176 - val_loss: 0.5431 - val_accuracy: 0.8469\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5341 - accuracy: 0.8466 - val_loss: 0.4661 - val_accuracy: 0.8629\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4678 - accuracy: 0.8662 - val_loss: 0.4193 - val_accuracy: 0.8755\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4240 - accuracy: 0.8767 - val_loss: 0.3883 - val_accuracy: 0.8822\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4024 - accuracy: 0.8824 - val_loss: 0.3770 - val_accuracy: 0.8872\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3812 - accuracy: 0.8872 - val_loss: 0.3542 - val_accuracy: 0.8927\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3572 - accuracy: 0.8944 - val_loss: 0.3398 - val_accuracy: 0.8975\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3424 - accuracy: 0.8989 - val_loss: 0.3317 - val_accuracy: 0.8984\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143717_[32, 16]_0.0001_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143717_[32, 16]_0.0001_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143717_[32, 16]_0.0001_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.1619 - accuracy: 0.6765 - val_loss: 0.6525 - val_accuracy: 0.8507\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5776 - accuracy: 0.8589 - val_loss: 0.4127 - val_accuracy: 0.8998\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4138 - accuracy: 0.8928 - val_loss: 0.3148 - val_accuracy: 0.9176\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3336 - accuracy: 0.9093 - val_loss: 0.2639 - val_accuracy: 0.9293\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2855 - accuracy: 0.9214 - val_loss: 0.2310 - val_accuracy: 0.9377\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2527 - accuracy: 0.9295 - val_loss: 0.2109 - val_accuracy: 0.9411\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2289 - accuracy: 0.9353 - val_loss: 0.1982 - val_accuracy: 0.9430\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2102 - accuracy: 0.9413 - val_loss: 0.1853 - val_accuracy: 0.9471\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1942 - accuracy: 0.9457 - val_loss: 0.1776 - val_accuracy: 0.9477\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1823 - accuracy: 0.9490 - val_loss: 0.1738 - val_accuracy: 0.9498\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1710 - accuracy: 0.9516 - val_loss: 0.1661 - val_accuracy: 0.9503\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1611 - accuracy: 0.9546 - val_loss: 0.1625 - val_accuracy: 0.9508\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1525 - accuracy: 0.9576 - val_loss: 0.1605 - val_accuracy: 0.9524\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1445 - accuracy: 0.9594 - val_loss: 0.1584 - val_accuracy: 0.9534\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1378 - accuracy: 0.9615 - val_loss: 0.1550 - val_accuracy: 0.9544\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1313 - accuracy: 0.9626 - val_loss: 0.1533 - val_accuracy: 0.9553\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1252 - accuracy: 0.9649 - val_loss: 0.1563 - val_accuracy: 0.9543\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1203 - accuracy: 0.9667 - val_loss: 0.1535 - val_accuracy: 0.9556\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1147 - accuracy: 0.9687 - val_loss: 0.1518 - val_accuracy: 0.9564\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1100 - accuracy: 0.9693 - val_loss: 0.1525 - val_accuracy: 0.9568\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1053 - accuracy: 0.9711 - val_loss: 0.1517 - val_accuracy: 0.9569\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1011 - accuracy: 0.9721 - val_loss: 0.1511 - val_accuracy: 0.9573\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0975 - accuracy: 0.9730 - val_loss: 0.1527 - val_accuracy: 0.9572\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0934 - accuracy: 0.9747 - val_loss: 0.1526 - val_accuracy: 0.9573\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0898 - accuracy: 0.9751 - val_loss: 0.1548 - val_accuracy: 0.9565\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143757_[32, 16]_0.0001_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143757_[32, 16]_0.0001_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143757_[32, 16]_0.0001_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.6156 - accuracy: 0.4760 - val_loss: 1.0413 - val_accuracy: 0.6977\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.8606 - accuracy: 0.7593 - val_loss: 0.6704 - val_accuracy: 0.8083\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6345 - accuracy: 0.8186 - val_loss: 0.5370 - val_accuracy: 0.8427\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5277 - accuracy: 0.8449 - val_loss: 0.4662 - val_accuracy: 0.8597\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4632 - accuracy: 0.8655 - val_loss: 0.4229 - val_accuracy: 0.8752\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4192 - accuracy: 0.8768 - val_loss: 0.3933 - val_accuracy: 0.8817\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3888 - accuracy: 0.8856 - val_loss: 0.3603 - val_accuracy: 0.8969\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3643 - accuracy: 0.8931 - val_loss: 0.3536 - val_accuracy: 0.8953\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3462 - accuracy: 0.8976 - val_loss: 0.3369 - val_accuracy: 0.9001\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3306 - accuracy: 0.9038 - val_loss: 0.3223 - val_accuracy: 0.9057\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3161 - accuracy: 0.9070 - val_loss: 0.3129 - val_accuracy: 0.9090\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3059 - accuracy: 0.9110 - val_loss: 0.3054 - val_accuracy: 0.9094\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2957 - accuracy: 0.9130 - val_loss: 0.2900 - val_accuracy: 0.9158\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 4s 2ms/step - loss: 0.2890 - accuracy: 0.9148 - val_loss: 0.2956 - val_accuracy: 0.9137\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2788 - accuracy: 0.9169 - val_loss: 0.2896 - val_accuracy: 0.9148\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2800 - accuracy: 0.9161 - val_loss: 0.2793 - val_accuracy: 0.9183\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2656 - accuracy: 0.9220 - val_loss: 0.2737 - val_accuracy: 0.9208\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2644 - accuracy: 0.9212 - val_loss: 0.2627 - val_accuracy: 0.9224\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2583 - accuracy: 0.9237 - val_loss: 0.2706 - val_accuracy: 0.9227\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2529 - accuracy: 0.9254 - val_loss: 0.2660 - val_accuracy: 0.9219\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2481 - accuracy: 0.9268 - val_loss: 0.2602 - val_accuracy: 0.9238\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2453 - accuracy: 0.9275 - val_loss: 0.2586 - val_accuracy: 0.9249\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2404 - accuracy: 0.9290 - val_loss: 0.2520 - val_accuracy: 0.9273\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2311 - accuracy: 0.9320 - val_loss: 0.2561 - val_accuracy: 0.9261\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2295 - accuracy: 0.9319 - val_loss: 0.2562 - val_accuracy: 0.9252\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143940_[32, 16]_0.0001_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143940_[32, 16]_0.0001_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_143940_[32, 16]_0.0001_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.2112 - accuracy: 0.6599 - val_loss: 0.6581 - val_accuracy: 0.8457\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5830 - accuracy: 0.8571 - val_loss: 0.4173 - val_accuracy: 0.8974\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4140 - accuracy: 0.8914 - val_loss: 0.3186 - val_accuracy: 0.9160\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3322 - accuracy: 0.9105 - val_loss: 0.2665 - val_accuracy: 0.9287\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2830 - accuracy: 0.9216 - val_loss: 0.2318 - val_accuracy: 0.9363\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2491 - accuracy: 0.9292 - val_loss: 0.2165 - val_accuracy: 0.9410\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2238 - accuracy: 0.9370 - val_loss: 0.1962 - val_accuracy: 0.9448\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2048 - accuracy: 0.9409 - val_loss: 0.1868 - val_accuracy: 0.9475\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1895 - accuracy: 0.9449 - val_loss: 0.1744 - val_accuracy: 0.9501\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1771 - accuracy: 0.9490 - val_loss: 0.1719 - val_accuracy: 0.9503\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1667 - accuracy: 0.9515 - val_loss: 0.1616 - val_accuracy: 0.9527\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1574 - accuracy: 0.9541 - val_loss: 0.1631 - val_accuracy: 0.9542\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1495 - accuracy: 0.9561 - val_loss: 0.1579 - val_accuracy: 0.9534\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1422 - accuracy: 0.9592 - val_loss: 0.1639 - val_accuracy: 0.9560\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1353 - accuracy: 0.9606 - val_loss: 0.1588 - val_accuracy: 0.9557\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1293 - accuracy: 0.9628 - val_loss: 0.1885 - val_accuracy: 0.9578\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1234 - accuracy: 0.9645 - val_loss: 0.1943 - val_accuracy: 0.9567\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1188 - accuracy: 0.9657 - val_loss: 0.1604 - val_accuracy: 0.9570\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1137 - accuracy: 0.9674 - val_loss: 0.1919 - val_accuracy: 0.9572\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1094 - accuracy: 0.9679 - val_loss: 0.1737 - val_accuracy: 0.9582\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1049 - accuracy: 0.9705 - val_loss: 0.1473 - val_accuracy: 0.9585\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1011 - accuracy: 0.9714 - val_loss: 0.1462 - val_accuracy: 0.9585\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0972 - accuracy: 0.9723 - val_loss: 0.1526 - val_accuracy: 0.9592\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0944 - accuracy: 0.9732 - val_loss: 0.1553 - val_accuracy: 0.9601\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0905 - accuracy: 0.9742 - val_loss: 0.1794 - val_accuracy: 0.9599\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0867 - accuracy: 0.9762 - val_loss: 0.2037 - val_accuracy: 0.9597\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0840 - accuracy: 0.9766 - val_loss: 0.1558 - val_accuracy: 0.9604\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0807 - accuracy: 0.9779 - val_loss: 0.1651 - val_accuracy: 0.9597\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0777 - accuracy: 0.9787 - val_loss: 0.1467 - val_accuracy: 0.9607\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0754 - accuracy: 0.9794 - val_loss: 0.1501 - val_accuracy: 0.9608\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0730 - accuracy: 0.9803 - val_loss: 0.1523 - val_accuracy: 0.9592\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0703 - accuracy: 0.9812 - val_loss: 0.1446 - val_accuracy: 0.9604\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0674 - accuracy: 0.9819 - val_loss: 0.1773 - val_accuracy: 0.9598\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0652 - accuracy: 0.9830 - val_loss: 0.1520 - val_accuracy: 0.9606\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0628 - accuracy: 0.9838 - val_loss: 0.1480 - val_accuracy: 0.9603\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0605 - accuracy: 0.9844 - val_loss: 0.2182 - val_accuracy: 0.9601\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0588 - accuracy: 0.9851 - val_loss: 0.1969 - val_accuracy: 0.9590\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0563 - accuracy: 0.9859 - val_loss: 0.1567 - val_accuracy: 0.9589\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0542 - accuracy: 0.9864 - val_loss: 0.1498 - val_accuracy: 0.9602\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0525 - accuracy: 0.9870 - val_loss: 0.1566 - val_accuracy: 0.9586\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0504 - accuracy: 0.9874 - val_loss: 0.1575 - val_accuracy: 0.9595\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0488 - accuracy: 0.9882 - val_loss: 0.1642 - val_accuracy: 0.9567\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0471 - accuracy: 0.9886 - val_loss: 0.1686 - val_accuracy: 0.9558\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0449 - accuracy: 0.9891 - val_loss: 0.2324 - val_accuracy: 0.9580\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0434 - accuracy: 0.9896 - val_loss: 0.1834 - val_accuracy: 0.9582\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0419 - accuracy: 0.9903 - val_loss: 0.1737 - val_accuracy: 0.9571\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0402 - accuracy: 0.9907 - val_loss: 0.1730 - val_accuracy: 0.9582\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0389 - accuracy: 0.9909 - val_loss: 0.1831 - val_accuracy: 0.9594\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0372 - accuracy: 0.9917 - val_loss: 0.1933 - val_accuracy: 0.9569\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0362 - accuracy: 0.9916 - val_loss: 0.2013 - val_accuracy: 0.9567\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144119_[32, 16]_0.0001_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144119_[32, 16]_0.0001_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144119_[32, 16]_0.0001_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.6706 - accuracy: 0.4698 - val_loss: 1.0541 - val_accuracy: 0.6963\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.9040 - accuracy: 0.7419 - val_loss: 0.7021 - val_accuracy: 0.8004\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6596 - accuracy: 0.8125 - val_loss: 0.5504 - val_accuracy: 0.8406\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.5390 - accuracy: 0.8424 - val_loss: 0.4688 - val_accuracy: 0.8615\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4722 - accuracy: 0.8618 - val_loss: 0.4221 - val_accuracy: 0.8734\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4321 - accuracy: 0.8728 - val_loss: 0.3877 - val_accuracy: 0.8827\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4015 - accuracy: 0.8837 - val_loss: 0.3668 - val_accuracy: 0.8919\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3814 - accuracy: 0.8870 - val_loss: 0.3630 - val_accuracy: 0.8894\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3643 - accuracy: 0.8922 - val_loss: 0.3378 - val_accuracy: 0.8992\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3495 - accuracy: 0.8955 - val_loss: 0.3216 - val_accuracy: 0.9044\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3337 - accuracy: 0.9018 - val_loss: 0.3236 - val_accuracy: 0.9062\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3289 - accuracy: 0.9013 - val_loss: 0.3129 - val_accuracy: 0.9083\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3138 - accuracy: 0.9067 - val_loss: 0.3002 - val_accuracy: 0.9088\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3087 - accuracy: 0.9080 - val_loss: 0.2953 - val_accuracy: 0.9131\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2997 - accuracy: 0.9107 - val_loss: 0.2889 - val_accuracy: 0.9158\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2899 - accuracy: 0.9130 - val_loss: 0.2790 - val_accuracy: 0.9178\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2827 - accuracy: 0.9158 - val_loss: 0.2796 - val_accuracy: 0.9175\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2784 - accuracy: 0.9166 - val_loss: 0.2701 - val_accuracy: 0.9208\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2690 - accuracy: 0.9194 - val_loss: 0.2709 - val_accuracy: 0.9192\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2641 - accuracy: 0.9208 - val_loss: 0.2665 - val_accuracy: 0.9218\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2598 - accuracy: 0.9226 - val_loss: 0.2652 - val_accuracy: 0.9216\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2555 - accuracy: 0.9230 - val_loss: 0.2656 - val_accuracy: 0.9220\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2505 - accuracy: 0.9250 - val_loss: 0.2532 - val_accuracy: 0.9244\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2447 - accuracy: 0.9280 - val_loss: 0.2489 - val_accuracy: 0.9261\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2373 - accuracy: 0.9289 - val_loss: 0.2473 - val_accuracy: 0.9268\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2371 - accuracy: 0.9291 - val_loss: 0.2533 - val_accuracy: 0.9270\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2351 - accuracy: 0.9296 - val_loss: 0.2448 - val_accuracy: 0.9273\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2297 - accuracy: 0.9318 - val_loss: 0.2498 - val_accuracy: 0.9275\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2263 - accuracy: 0.9318 - val_loss: 0.2459 - val_accuracy: 0.9285\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2203 - accuracy: 0.9346 - val_loss: 0.2451 - val_accuracy: 0.9285\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2202 - accuracy: 0.9350 - val_loss: 0.2317 - val_accuracy: 0.9325\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2165 - accuracy: 0.9353 - val_loss: 0.2382 - val_accuracy: 0.9295\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2168 - accuracy: 0.9350 - val_loss: 0.2416 - val_accuracy: 0.9295\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2187 - accuracy: 0.9347 - val_loss: 0.2376 - val_accuracy: 0.9321\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2104 - accuracy: 0.9376 - val_loss: 0.2308 - val_accuracy: 0.9321\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2090 - accuracy: 0.9382 - val_loss: 0.2405 - val_accuracy: 0.9295\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2017 - accuracy: 0.9398 - val_loss: 0.2287 - val_accuracy: 0.9343\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1996 - accuracy: 0.9408 - val_loss: 0.2309 - val_accuracy: 0.9337\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1973 - accuracy: 0.9414 - val_loss: 0.2259 - val_accuracy: 0.9366\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1962 - accuracy: 0.9419 - val_loss: 0.2273 - val_accuracy: 0.9338\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1936 - accuracy: 0.9421 - val_loss: 0.2302 - val_accuracy: 0.9352\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1908 - accuracy: 0.9438 - val_loss: 0.2244 - val_accuracy: 0.9348\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1875 - accuracy: 0.9436 - val_loss: 0.2221 - val_accuracy: 0.9358\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1867 - accuracy: 0.9448 - val_loss: 0.2249 - val_accuracy: 0.9344\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1876 - accuracy: 0.9439 - val_loss: 0.2211 - val_accuracy: 0.9368\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1812 - accuracy: 0.9461 - val_loss: 0.2257 - val_accuracy: 0.9357\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1819 - accuracy: 0.9458 - val_loss: 0.2190 - val_accuracy: 0.9367\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1853 - accuracy: 0.9448 - val_loss: 0.2177 - val_accuracy: 0.9388\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1782 - accuracy: 0.9464 - val_loss: 0.2166 - val_accuracy: 0.9389\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1763 - accuracy: 0.9470 - val_loss: 0.2139 - val_accuracy: 0.9393\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144438_[32, 16]_0.0001_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144438_[32, 16]_0.0001_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144438_[32, 16]_0.0001_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4072 - accuracy: 0.8872 - val_loss: 0.1681 - val_accuracy: 0.9512\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1795 - accuracy: 0.9452 - val_loss: 0.1481 - val_accuracy: 0.9536\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1320 - accuracy: 0.9606 - val_loss: 0.1237 - val_accuracy: 0.9626\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9686 - val_loss: 0.1212 - val_accuracy: 0.9621\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0860 - accuracy: 0.9739 - val_loss: 0.1047 - val_accuracy: 0.9671\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0728 - accuracy: 0.9772 - val_loss: 0.1088 - val_accuracy: 0.9688\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.1092 - val_accuracy: 0.9674\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0537 - accuracy: 0.9838 - val_loss: 0.1131 - val_accuracy: 0.9670\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0472 - accuracy: 0.9852 - val_loss: 0.1217 - val_accuracy: 0.9666\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 0.1133 - val_accuracy: 0.9679\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144805_[64, 32, 16]_0.001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144805_[64, 32, 16]_0.001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144805_[64, 32, 16]_0.001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.7740 - accuracy: 0.7566 - val_loss: 0.5927 - val_accuracy: 0.8178\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5600 - accuracy: 0.8223 - val_loss: 0.5196 - val_accuracy: 0.8351\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4868 - accuracy: 0.8460 - val_loss: 0.4379 - val_accuracy: 0.8683\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4500 - accuracy: 0.8608 - val_loss: 0.4257 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4347 - accuracy: 0.8649 - val_loss: 0.3495 - val_accuracy: 0.8906\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3871 - accuracy: 0.8800 - val_loss: 0.3590 - val_accuracy: 0.8857\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3626 - accuracy: 0.8861 - val_loss: 0.3578 - val_accuracy: 0.8900\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3623 - accuracy: 0.8866 - val_loss: 0.3612 - val_accuracy: 0.8852\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3533 - accuracy: 0.8910 - val_loss: 0.3165 - val_accuracy: 0.9032\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3440 - accuracy: 0.8936 - val_loss: 0.3110 - val_accuracy: 0.9024\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144853_[64, 32, 16]_0.001_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144853_[64, 32, 16]_0.001_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144853_[64, 32, 16]_0.001_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4167 - accuracy: 0.8845 - val_loss: 0.1675 - val_accuracy: 0.9498\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1845 - accuracy: 0.9451 - val_loss: 0.1313 - val_accuracy: 0.9623\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1334 - accuracy: 0.9594 - val_loss: 0.1245 - val_accuracy: 0.9616\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1068 - accuracy: 0.9680 - val_loss: 0.1075 - val_accuracy: 0.9669\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9726 - val_loss: 0.1036 - val_accuracy: 0.9701\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0726 - accuracy: 0.9771 - val_loss: 0.0950 - val_accuracy: 0.9705\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0997 - val_accuracy: 0.9726\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0504 - accuracy: 0.9845 - val_loss: 0.1049 - val_accuracy: 0.9694\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0452 - accuracy: 0.9858 - val_loss: 0.1044 - val_accuracy: 0.9722\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0402 - accuracy: 0.9868 - val_loss: 0.1090 - val_accuracy: 0.9691\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 0.1023 - val_accuracy: 0.9715\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.1120 - val_accuracy: 0.9719\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 0.1167 - val_accuracy: 0.9711\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.1111 - val_accuracy: 0.9728\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 0.1292 - val_accuracy: 0.9708\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.1147 - val_accuracy: 0.9737\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1154 - val_accuracy: 0.9740\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.1236 - val_accuracy: 0.9728\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.1185 - val_accuracy: 0.9758\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.1174 - val_accuracy: 0.9753\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.1198 - val_accuracy: 0.9740\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.1314 - val_accuracy: 0.9729\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.1215 - val_accuracy: 0.9752\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.1425 - val_accuracy: 0.9697\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1248 - val_accuracy: 0.9728\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144942_[64, 32, 16]_0.001_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144942_[64, 32, 16]_0.001_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_144942_[64, 32, 16]_0.001_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7731 - accuracy: 0.7542 - val_loss: 0.6123 - val_accuracy: 0.8008\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5653 - accuracy: 0.8197 - val_loss: 0.5433 - val_accuracy: 0.8274\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5167 - accuracy: 0.8401 - val_loss: 0.4658 - val_accuracy: 0.8472\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.4575 - accuracy: 0.8586 - val_loss: 0.4265 - val_accuracy: 0.8671\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4421 - accuracy: 0.8624 - val_loss: 0.3764 - val_accuracy: 0.8850\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4036 - accuracy: 0.8750 - val_loss: 0.3670 - val_accuracy: 0.8907\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4016 - accuracy: 0.8777 - val_loss: 0.3447 - val_accuracy: 0.8879\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3929 - accuracy: 0.8769 - val_loss: 0.3290 - val_accuracy: 0.8973\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3709 - accuracy: 0.8866 - val_loss: 0.3390 - val_accuracy: 0.8939\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3627 - accuracy: 0.8885 - val_loss: 0.3389 - val_accuracy: 0.8959\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3548 - accuracy: 0.8907 - val_loss: 0.2891 - val_accuracy: 0.9119\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3202 - accuracy: 0.9026 - val_loss: 0.3053 - val_accuracy: 0.9055\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3283 - accuracy: 0.8967 - val_loss: 0.2949 - val_accuracy: 0.9091\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3202 - accuracy: 0.8990 - val_loss: 0.2787 - val_accuracy: 0.9150\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3033 - accuracy: 0.9059 - val_loss: 0.2741 - val_accuracy: 0.9161\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3103 - accuracy: 0.9052 - val_loss: 0.2842 - val_accuracy: 0.9113\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3137 - accuracy: 0.9033 - val_loss: 0.2679 - val_accuracy: 0.9187\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3035 - accuracy: 0.9060 - val_loss: 0.2894 - val_accuracy: 0.9108\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3084 - accuracy: 0.9044 - val_loss: 0.2704 - val_accuracy: 0.9172\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2829 - accuracy: 0.9134 - val_loss: 0.2811 - val_accuracy: 0.9143\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2922 - accuracy: 0.9115 - val_loss: 0.2584 - val_accuracy: 0.9213\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2841 - accuracy: 0.9137 - val_loss: 0.2481 - val_accuracy: 0.9247\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2905 - accuracy: 0.9104 - val_loss: 0.2615 - val_accuracy: 0.9188\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2839 - accuracy: 0.9136 - val_loss: 0.2746 - val_accuracy: 0.9162\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2925 - accuracy: 0.9099 - val_loss: 0.2518 - val_accuracy: 0.9205\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145141_[64, 32, 16]_0.001_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145141_[64, 32, 16]_0.001_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145141_[64, 32, 16]_0.001_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4355 - accuracy: 0.8781 - val_loss: 0.1821 - val_accuracy: 0.9469\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1885 - accuracy: 0.9446 - val_loss: 0.1383 - val_accuracy: 0.9620\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1393 - accuracy: 0.9580 - val_loss: 0.1203 - val_accuracy: 0.9663\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1130 - accuracy: 0.9652 - val_loss: 0.1263 - val_accuracy: 0.9637\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0927 - accuracy: 0.9720 - val_loss: 0.1126 - val_accuracy: 0.9669\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0775 - accuracy: 0.9766 - val_loss: 0.1115 - val_accuracy: 0.9663\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.1095 - val_accuracy: 0.9693\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0560 - accuracy: 0.9827 - val_loss: 0.1089 - val_accuracy: 0.9695\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0498 - accuracy: 0.9840 - val_loss: 0.1071 - val_accuracy: 0.9714\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0420 - accuracy: 0.9865 - val_loss: 0.1133 - val_accuracy: 0.9713\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0373 - accuracy: 0.9886 - val_loss: 0.1345 - val_accuracy: 0.9659\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 0.1243 - val_accuracy: 0.9691\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0310 - accuracy: 0.9900 - val_loss: 0.1181 - val_accuracy: 0.9705\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0252 - accuracy: 0.9917 - val_loss: 0.1199 - val_accuracy: 0.9728\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.1352 - val_accuracy: 0.9692\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.1458 - val_accuracy: 0.9688\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0185 - accuracy: 0.9940 - val_loss: 0.1448 - val_accuracy: 0.9661\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9927 - val_loss: 0.1448 - val_accuracy: 0.9678\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0176 - accuracy: 0.9946 - val_loss: 0.1575 - val_accuracy: 0.9664\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.1525 - val_accuracy: 0.9681\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.1514 - val_accuracy: 0.9699\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1521 - val_accuracy: 0.9685\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.1495 - val_accuracy: 0.9709\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.1504 - val_accuracy: 0.9703\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1756 - val_accuracy: 0.9688\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 0.1579 - val_accuracy: 0.9691\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.1683 - val_accuracy: 0.9691\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.1713 - val_accuracy: 0.9680\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1640 - val_accuracy: 0.9710\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.1656 - val_accuracy: 0.9702\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.1814 - val_accuracy: 0.9691\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.1667 - val_accuracy: 0.9713\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.1658 - val_accuracy: 0.9708\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.1760 - val_accuracy: 0.9704\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.1893 - val_accuracy: 0.9699\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.1639 - val_accuracy: 0.9722\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1885 - val_accuracy: 0.9684\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.1737 - val_accuracy: 0.9711\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.1882 - val_accuracy: 0.9695\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.1832 - val_accuracy: 0.9706\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1896 - val_accuracy: 0.9700\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1886 - val_accuracy: 0.9709\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.1845 - val_accuracy: 0.9716\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.1835 - val_accuracy: 0.9703\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.1777 - val_accuracy: 0.9709\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.1990 - val_accuracy: 0.9692\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1879 - val_accuracy: 0.9709\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1890 - val_accuracy: 0.9710\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.1932 - val_accuracy: 0.9697\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1884 - val_accuracy: 0.9704\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145342_[64, 32, 16]_0.001_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145342_[64, 32, 16]_0.001_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145342_[64, 32, 16]_0.001_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7875 - accuracy: 0.7487 - val_loss: 0.6244 - val_accuracy: 0.7959\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5857 - accuracy: 0.8109 - val_loss: 0.6866 - val_accuracy: 0.7761\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5345 - accuracy: 0.8309 - val_loss: 0.4241 - val_accuracy: 0.8658\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4459 - accuracy: 0.8640 - val_loss: 0.3973 - val_accuracy: 0.8787\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4445 - accuracy: 0.8629 - val_loss: 0.4379 - val_accuracy: 0.8615\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4398 - accuracy: 0.8634 - val_loss: 0.3639 - val_accuracy: 0.8852\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3770 - accuracy: 0.8841 - val_loss: 0.3876 - val_accuracy: 0.8744\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3872 - accuracy: 0.8791 - val_loss: 0.3376 - val_accuracy: 0.8964\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3851 - accuracy: 0.8791 - val_loss: 0.3303 - val_accuracy: 0.8990\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3654 - accuracy: 0.8859 - val_loss: 0.3133 - val_accuracy: 0.9054\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3429 - accuracy: 0.8950 - val_loss: 0.3136 - val_accuracy: 0.9020\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3393 - accuracy: 0.8941 - val_loss: 0.3107 - val_accuracy: 0.9043\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3387 - accuracy: 0.8956 - val_loss: 0.3235 - val_accuracy: 0.8984\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3356 - accuracy: 0.8947 - val_loss: 0.3077 - val_accuracy: 0.9035\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3403 - accuracy: 0.8917 - val_loss: 0.3162 - val_accuracy: 0.9006\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3271 - accuracy: 0.8992 - val_loss: 0.2890 - val_accuracy: 0.9131\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3095 - accuracy: 0.9046 - val_loss: 0.2939 - val_accuracy: 0.9043\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3114 - accuracy: 0.9025 - val_loss: 0.3012 - val_accuracy: 0.9062\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3013 - accuracy: 0.9063 - val_loss: 0.2772 - val_accuracy: 0.9153\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3023 - accuracy: 0.9066 - val_loss: 0.3205 - val_accuracy: 0.8998\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3078 - accuracy: 0.9020 - val_loss: 0.2598 - val_accuracy: 0.9222\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2892 - accuracy: 0.9105 - val_loss: 0.2614 - val_accuracy: 0.9192\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2750 - accuracy: 0.9155 - val_loss: 0.2706 - val_accuracy: 0.9156\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2782 - accuracy: 0.9135 - val_loss: 0.2635 - val_accuracy: 0.9194\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2754 - accuracy: 0.9154 - val_loss: 0.2645 - val_accuracy: 0.9170\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2792 - accuracy: 0.9135 - val_loss: 0.2744 - val_accuracy: 0.9151\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2757 - accuracy: 0.9160 - val_loss: 0.2808 - val_accuracy: 0.9119\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2811 - accuracy: 0.9129 - val_loss: 0.2577 - val_accuracy: 0.9213\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2746 - accuracy: 0.9151 - val_loss: 0.2585 - val_accuracy: 0.9204\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2716 - accuracy: 0.9164 - val_loss: 0.2456 - val_accuracy: 0.9264\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2754 - accuracy: 0.9153 - val_loss: 0.2575 - val_accuracy: 0.9208\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2752 - accuracy: 0.9152 - val_loss: 0.2582 - val_accuracy: 0.9222\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2658 - accuracy: 0.9181 - val_loss: 0.2471 - val_accuracy: 0.9240\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2672 - accuracy: 0.9183 - val_loss: 0.2403 - val_accuracy: 0.9247\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2569 - accuracy: 0.9210 - val_loss: 0.2472 - val_accuracy: 0.9244\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2621 - accuracy: 0.9176 - val_loss: 0.2406 - val_accuracy: 0.9238\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2558 - accuracy: 0.9217 - val_loss: 0.2315 - val_accuracy: 0.9277\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2699 - accuracy: 0.9166 - val_loss: 0.2609 - val_accuracy: 0.9200\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2787 - accuracy: 0.9135 - val_loss: 0.2450 - val_accuracy: 0.9261\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2577 - accuracy: 0.9212 - val_loss: 0.2438 - val_accuracy: 0.9278\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2551 - accuracy: 0.9217 - val_loss: 0.2370 - val_accuracy: 0.9286\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2528 - accuracy: 0.9226 - val_loss: 0.2271 - val_accuracy: 0.9321\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2540 - accuracy: 0.9215 - val_loss: 0.2379 - val_accuracy: 0.9311\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2597 - accuracy: 0.9211 - val_loss: 0.2444 - val_accuracy: 0.9284\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2472 - accuracy: 0.9220 - val_loss: 0.2321 - val_accuracy: 0.9320\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2437 - accuracy: 0.9251 - val_loss: 0.2322 - val_accuracy: 0.9310\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2459 - accuracy: 0.9255 - val_loss: 0.2255 - val_accuracy: 0.9322\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2416 - accuracy: 0.9254 - val_loss: 0.2197 - val_accuracy: 0.9342\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2353 - accuracy: 0.9280 - val_loss: 0.2261 - val_accuracy: 0.9314\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2320 - accuracy: 0.9294 - val_loss: 0.2287 - val_accuracy: 0.9307\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145812_[64, 32, 16]_0.001_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145812_[64, 32, 16]_0.001_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_145812_[64, 32, 16]_0.001_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5382 - accuracy: 0.8568 - val_loss: 0.2066 - val_accuracy: 0.9421\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2160 - accuracy: 0.9392 - val_loss: 0.1512 - val_accuracy: 0.9549\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1530 - accuracy: 0.9555 - val_loss: 0.1295 - val_accuracy: 0.9592\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1204 - accuracy: 0.9648 - val_loss: 0.1319 - val_accuracy: 0.9589\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0964 - accuracy: 0.9719 - val_loss: 0.1133 - val_accuracy: 0.9638\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0825 - accuracy: 0.9754 - val_loss: 0.1105 - val_accuracy: 0.9672\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0685 - accuracy: 0.9796 - val_loss: 0.1165 - val_accuracy: 0.9664\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0581 - accuracy: 0.9827 - val_loss: 0.1082 - val_accuracy: 0.9675\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0505 - accuracy: 0.9846 - val_loss: 0.1174 - val_accuracy: 0.9671\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0414 - accuracy: 0.9876 - val_loss: 0.1221 - val_accuracy: 0.9666\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150232_[64, 32, 16]_0.0005_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150232_[64, 32, 16]_0.0005_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150232_[64, 32, 16]_0.0005_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7551 - accuracy: 0.7729 - val_loss: 0.5069 - val_accuracy: 0.8457\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4489 - accuracy: 0.8626 - val_loss: 0.4358 - val_accuracy: 0.8629\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4197 - accuracy: 0.8701 - val_loss: 0.3491 - val_accuracy: 0.8913\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3777 - accuracy: 0.8838 - val_loss: 0.3227 - val_accuracy: 0.8995\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3521 - accuracy: 0.8922 - val_loss: 0.3201 - val_accuracy: 0.8991\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3311 - accuracy: 0.8989 - val_loss: 0.3107 - val_accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3304 - accuracy: 0.8998 - val_loss: 0.2688 - val_accuracy: 0.9198\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3030 - accuracy: 0.9083 - val_loss: 0.2477 - val_accuracy: 0.9245\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3018 - accuracy: 0.9064 - val_loss: 0.2700 - val_accuracy: 0.9173\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2940 - accuracy: 0.9107 - val_loss: 0.2477 - val_accuracy: 0.9239\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150328_[64, 32, 16]_0.0005_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150328_[64, 32, 16]_0.0005_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150328_[64, 32, 16]_0.0005_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5477 - accuracy: 0.8494 - val_loss: 0.2235 - val_accuracy: 0.9416\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2152 - accuracy: 0.9385 - val_loss: 0.1578 - val_accuracy: 0.9541\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1548 - accuracy: 0.9551 - val_loss: 0.1272 - val_accuracy: 0.9626\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1202 - accuracy: 0.9649 - val_loss: 0.1195 - val_accuracy: 0.9654\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0964 - accuracy: 0.9720 - val_loss: 0.1186 - val_accuracy: 0.9664\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0815 - accuracy: 0.9762 - val_loss: 0.1100 - val_accuracy: 0.9689\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0665 - accuracy: 0.9809 - val_loss: 0.1114 - val_accuracy: 0.9699\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0561 - accuracy: 0.9834 - val_loss: 0.1084 - val_accuracy: 0.9691\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.1087 - val_accuracy: 0.9708\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0413 - accuracy: 0.9876 - val_loss: 0.1103 - val_accuracy: 0.9700\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0356 - accuracy: 0.9892 - val_loss: 0.1202 - val_accuracy: 0.9692\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.1223 - val_accuracy: 0.9696\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0276 - accuracy: 0.9915 - val_loss: 0.1139 - val_accuracy: 0.9716\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 0.1223 - val_accuracy: 0.9712\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0212 - accuracy: 0.9936 - val_loss: 0.1281 - val_accuracy: 0.9712\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.1358 - val_accuracy: 0.9695\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.1318 - val_accuracy: 0.9694\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.1331 - val_accuracy: 0.9703\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0121 - accuracy: 0.9966 - val_loss: 0.1295 - val_accuracy: 0.9719\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.1578 - val_accuracy: 0.9688\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.1479 - val_accuracy: 0.9706\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0110 - accuracy: 0.9970 - val_loss: 0.1492 - val_accuracy: 0.9719\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.1414 - val_accuracy: 0.9729\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0124 - accuracy: 0.9961 - val_loss: 0.1655 - val_accuracy: 0.9691\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.1432 - val_accuracy: 0.9729\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150425_[64, 32, 16]_0.0005_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150425_[64, 32, 16]_0.0005_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150425_[64, 32, 16]_0.0005_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7605 - accuracy: 0.7716 - val_loss: 0.4775 - val_accuracy: 0.8550\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4547 - accuracy: 0.8615 - val_loss: 0.4103 - val_accuracy: 0.8699\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3965 - accuracy: 0.8774 - val_loss: 0.3586 - val_accuracy: 0.8888\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3575 - accuracy: 0.8910 - val_loss: 0.3195 - val_accuracy: 0.9028\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3353 - accuracy: 0.8959 - val_loss: 0.2985 - val_accuracy: 0.9091\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3258 - accuracy: 0.8998 - val_loss: 0.2965 - val_accuracy: 0.9057\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3251 - accuracy: 0.8988 - val_loss: 0.2819 - val_accuracy: 0.9143\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3000 - accuracy: 0.9093 - val_loss: 0.2717 - val_accuracy: 0.9176\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3033 - accuracy: 0.9078 - val_loss: 0.2678 - val_accuracy: 0.9197\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2910 - accuracy: 0.9117 - val_loss: 0.2648 - val_accuracy: 0.9212\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2886 - accuracy: 0.9135 - val_loss: 0.2538 - val_accuracy: 0.9218\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2805 - accuracy: 0.9146 - val_loss: 0.2643 - val_accuracy: 0.9180\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2736 - accuracy: 0.9157 - val_loss: 0.2405 - val_accuracy: 0.9254\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2595 - accuracy: 0.9198 - val_loss: 0.2682 - val_accuracy: 0.9166\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2676 - accuracy: 0.9175 - val_loss: 0.2323 - val_accuracy: 0.9309\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2534 - accuracy: 0.9208 - val_loss: 0.2331 - val_accuracy: 0.9294\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2428 - accuracy: 0.9260 - val_loss: 0.2199 - val_accuracy: 0.9337\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2506 - accuracy: 0.9239 - val_loss: 0.2354 - val_accuracy: 0.9263\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2470 - accuracy: 0.9255 - val_loss: 0.2254 - val_accuracy: 0.9316\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2311 - accuracy: 0.9308 - val_loss: 0.2241 - val_accuracy: 0.9336\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2295 - accuracy: 0.9307 - val_loss: 0.2116 - val_accuracy: 0.9347\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2249 - accuracy: 0.9311 - val_loss: 0.2135 - val_accuracy: 0.9345\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2296 - accuracy: 0.9309 - val_loss: 0.2167 - val_accuracy: 0.9335\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2232 - accuracy: 0.9318 - val_loss: 0.2041 - val_accuracy: 0.9370\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2187 - accuracy: 0.9317 - val_loss: 0.2063 - val_accuracy: 0.9383\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150642_[64, 32, 16]_0.0005_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150642_[64, 32, 16]_0.0005_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150642_[64, 32, 16]_0.0005_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5404 - accuracy: 0.8451 - val_loss: 0.1934 - val_accuracy: 0.9474\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2069 - accuracy: 0.9402 - val_loss: 0.1365 - val_accuracy: 0.9601\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1492 - accuracy: 0.9565 - val_loss: 0.1439 - val_accuracy: 0.9564\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1144 - accuracy: 0.9667 - val_loss: 0.1187 - val_accuracy: 0.9643\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0949 - accuracy: 0.9713 - val_loss: 0.1144 - val_accuracy: 0.9655\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0769 - accuracy: 0.9770 - val_loss: 0.1073 - val_accuracy: 0.9686\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0647 - accuracy: 0.9808 - val_loss: 0.1068 - val_accuracy: 0.9683\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0549 - accuracy: 0.9835 - val_loss: 0.1066 - val_accuracy: 0.9682\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0458 - accuracy: 0.9864 - val_loss: 0.1120 - val_accuracy: 0.9680\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.1130 - val_accuracy: 0.9707\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.1176 - val_accuracy: 0.9706\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.1138 - val_accuracy: 0.9703\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0262 - accuracy: 0.9921 - val_loss: 0.1231 - val_accuracy: 0.9675\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.1304 - val_accuracy: 0.9697\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.1247 - val_accuracy: 0.9688\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.1305 - val_accuracy: 0.9697\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.1372 - val_accuracy: 0.9683\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0175 - accuracy: 0.9945 - val_loss: 0.1295 - val_accuracy: 0.9714\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.1455 - val_accuracy: 0.9671\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.1405 - val_accuracy: 0.9701\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.1465 - val_accuracy: 0.9678\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.1399 - val_accuracy: 0.9719\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.1438 - val_accuracy: 0.9710\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1385 - val_accuracy: 0.9722\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.1522 - val_accuracy: 0.9703\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1632 - val_accuracy: 0.9712\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.1433 - val_accuracy: 0.9732\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1599 - val_accuracy: 0.9697\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0103 - accuracy: 0.9968 - val_loss: 0.1550 - val_accuracy: 0.9699\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.1715 - val_accuracy: 0.9693\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1533 - val_accuracy: 0.9722\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1661 - val_accuracy: 0.9707\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.1712 - val_accuracy: 0.9698\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1773 - val_accuracy: 0.9702\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.1639 - val_accuracy: 0.9709\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1493 - val_accuracy: 0.9733\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.1700 - val_accuracy: 0.9707\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.1603 - val_accuracy: 0.9719\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1710 - val_accuracy: 0.9715\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.1561 - val_accuracy: 0.9728\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.1551 - val_accuracy: 0.9729\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.1610 - val_accuracy: 0.9731\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.1729 - val_accuracy: 0.9701\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1732 - val_accuracy: 0.9722\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1718 - val_accuracy: 0.9727\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1637 - val_accuracy: 0.9739\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1676 - val_accuracy: 0.9732\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.1700 - val_accuracy: 0.9727\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1763 - val_accuracy: 0.9704\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1681 - val_accuracy: 0.9731\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150900_[64, 32, 16]_0.0005_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150900_[64, 32, 16]_0.0005_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_150900_[64, 32, 16]_0.0005_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7554 - accuracy: 0.7778 - val_loss: 0.4517 - val_accuracy: 0.8647\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.4448 - accuracy: 0.8649 - val_loss: 0.3632 - val_accuracy: 0.8911\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4140 - accuracy: 0.8718 - val_loss: 0.4025 - val_accuracy: 0.8771\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3980 - accuracy: 0.8799 - val_loss: 0.3468 - val_accuracy: 0.8948\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3562 - accuracy: 0.8919 - val_loss: 0.3087 - val_accuracy: 0.9085\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3311 - accuracy: 0.8996 - val_loss: 0.2927 - val_accuracy: 0.9069\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3319 - accuracy: 0.8985 - val_loss: 0.2829 - val_accuracy: 0.9116\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3092 - accuracy: 0.9080 - val_loss: 0.2755 - val_accuracy: 0.9170\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2839 - accuracy: 0.9152 - val_loss: 0.2570 - val_accuracy: 0.9198\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2780 - accuracy: 0.9150 - val_loss: 0.2360 - val_accuracy: 0.9284\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2776 - accuracy: 0.9155 - val_loss: 0.2388 - val_accuracy: 0.9283\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2756 - accuracy: 0.9167 - val_loss: 0.2502 - val_accuracy: 0.9212\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2757 - accuracy: 0.9154 - val_loss: 0.2453 - val_accuracy: 0.9241\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2573 - accuracy: 0.9198 - val_loss: 0.2394 - val_accuracy: 0.9253\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2628 - accuracy: 0.9186 - val_loss: 0.2423 - val_accuracy: 0.9258\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2509 - accuracy: 0.9230 - val_loss: 0.2250 - val_accuracy: 0.9340\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2525 - accuracy: 0.9231 - val_loss: 0.2227 - val_accuracy: 0.9317\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2443 - accuracy: 0.9252 - val_loss: 0.2419 - val_accuracy: 0.9275\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2413 - accuracy: 0.9268 - val_loss: 0.2198 - val_accuracy: 0.9315\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2344 - accuracy: 0.9280 - val_loss: 0.2196 - val_accuracy: 0.9342\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2325 - accuracy: 0.9286 - val_loss: 0.2164 - val_accuracy: 0.9354\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2326 - accuracy: 0.9296 - val_loss: 0.2131 - val_accuracy: 0.9342\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2241 - accuracy: 0.9310 - val_loss: 0.2086 - val_accuracy: 0.9342\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2236 - accuracy: 0.9306 - val_loss: 0.2045 - val_accuracy: 0.9398\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2146 - accuracy: 0.9348 - val_loss: 0.1966 - val_accuracy: 0.9380\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2096 - accuracy: 0.9371 - val_loss: 0.1952 - val_accuracy: 0.9408\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2044 - accuracy: 0.9382 - val_loss: 0.1971 - val_accuracy: 0.9405\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2102 - accuracy: 0.9355 - val_loss: 0.1918 - val_accuracy: 0.9408\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2035 - accuracy: 0.9380 - val_loss: 0.1966 - val_accuracy: 0.9411\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2014 - accuracy: 0.9390 - val_loss: 0.1828 - val_accuracy: 0.9433\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1983 - accuracy: 0.9393 - val_loss: 0.1778 - val_accuracy: 0.9459\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2072 - accuracy: 0.9382 - val_loss: 0.1966 - val_accuracy: 0.9416\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2075 - accuracy: 0.9368 - val_loss: 0.1935 - val_accuracy: 0.9438\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1980 - accuracy: 0.9398 - val_loss: 0.1924 - val_accuracy: 0.9427\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2011 - accuracy: 0.9389 - val_loss: 0.1904 - val_accuracy: 0.9425\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1932 - accuracy: 0.9415 - val_loss: 0.1866 - val_accuracy: 0.9442\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1847 - accuracy: 0.9433 - val_loss: 0.1736 - val_accuracy: 0.9482\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1756 - accuracy: 0.9466 - val_loss: 0.1678 - val_accuracy: 0.9497\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1869 - accuracy: 0.9434 - val_loss: 0.1807 - val_accuracy: 0.9462\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1877 - accuracy: 0.9424 - val_loss: 0.1884 - val_accuracy: 0.9427\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1914 - accuracy: 0.9404 - val_loss: 0.1804 - val_accuracy: 0.9457\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1925 - accuracy: 0.9409 - val_loss: 0.1906 - val_accuracy: 0.9409\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1823 - accuracy: 0.9451 - val_loss: 0.1770 - val_accuracy: 0.9467\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1864 - accuracy: 0.9425 - val_loss: 0.1731 - val_accuracy: 0.9484\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1741 - accuracy: 0.9456 - val_loss: 0.1699 - val_accuracy: 0.9509\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1727 - accuracy: 0.9464 - val_loss: 0.1775 - val_accuracy: 0.9465\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1783 - accuracy: 0.9450 - val_loss: 0.1684 - val_accuracy: 0.9459\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1717 - accuracy: 0.9467 - val_loss: 0.1663 - val_accuracy: 0.9493\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1654 - accuracy: 0.9495 - val_loss: 0.1670 - val_accuracy: 0.9512\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1636 - accuracy: 0.9490 - val_loss: 0.1742 - val_accuracy: 0.9472\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151334_[64, 32, 16]_0.0005_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151334_[64, 32, 16]_0.0005_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151334_[64, 32, 16]_0.0005_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.2324 - accuracy: 0.6427 - val_loss: 0.6304 - val_accuracy: 0.8603\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5438 - accuracy: 0.8686 - val_loss: 0.3620 - val_accuracy: 0.9155\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3577 - accuracy: 0.9096 - val_loss: 0.2599 - val_accuracy: 0.9334\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2751 - accuracy: 0.9268 - val_loss: 0.2096 - val_accuracy: 0.9447\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2262 - accuracy: 0.9393 - val_loss: 0.1856 - val_accuracy: 0.9483\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1924 - accuracy: 0.9471 - val_loss: 0.1659 - val_accuracy: 0.9534\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1674 - accuracy: 0.9539 - val_loss: 0.1584 - val_accuracy: 0.9543\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1475 - accuracy: 0.9598 - val_loss: 0.1451 - val_accuracy: 0.9569\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1311 - accuracy: 0.9638 - val_loss: 0.1458 - val_accuracy: 0.9592\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1172 - accuracy: 0.9686 - val_loss: 0.1358 - val_accuracy: 0.9592\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151810_[64, 32, 16]_0.0001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151810_[64, 32, 16]_0.0001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151810_[64, 32, 16]_0.0001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.3816 - accuracy: 0.5726 - val_loss: 0.8454 - val_accuracy: 0.7663\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7289 - accuracy: 0.7977 - val_loss: 0.5629 - val_accuracy: 0.8436\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5322 - accuracy: 0.8492 - val_loss: 0.4441 - val_accuracy: 0.8723\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4446 - accuracy: 0.8705 - val_loss: 0.3836 - val_accuracy: 0.8883\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3878 - accuracy: 0.8855 - val_loss: 0.3525 - val_accuracy: 0.8970\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3535 - accuracy: 0.8949 - val_loss: 0.3173 - val_accuracy: 0.9055\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3262 - accuracy: 0.9019 - val_loss: 0.2958 - val_accuracy: 0.9110\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3073 - accuracy: 0.9076 - val_loss: 0.2885 - val_accuracy: 0.9122\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2908 - accuracy: 0.9133 - val_loss: 0.2716 - val_accuracy: 0.9181\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2678 - accuracy: 0.9197 - val_loss: 0.2578 - val_accuracy: 0.9228\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151906_[64, 32, 16]_0.0001_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151906_[64, 32, 16]_0.0001_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_151906_[64, 32, 16]_0.0001_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.1706 - accuracy: 0.6666 - val_loss: 0.6187 - val_accuracy: 0.8666\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5302 - accuracy: 0.8731 - val_loss: 0.3542 - val_accuracy: 0.9181\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3541 - accuracy: 0.9080 - val_loss: 0.2520 - val_accuracy: 0.9362\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2720 - accuracy: 0.9272 - val_loss: 0.2107 - val_accuracy: 0.9460\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2231 - accuracy: 0.9383 - val_loss: 0.1888 - val_accuracy: 0.9513\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1898 - accuracy: 0.9477 - val_loss: 0.1674 - val_accuracy: 0.9564\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1645 - accuracy: 0.9546 - val_loss: 0.1499 - val_accuracy: 0.9572\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1447 - accuracy: 0.9595 - val_loss: 0.1440 - val_accuracy: 0.9587\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1279 - accuracy: 0.9655 - val_loss: 0.1409 - val_accuracy: 0.9596\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1146 - accuracy: 0.9690 - val_loss: 0.1404 - val_accuracy: 0.9610\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1021 - accuracy: 0.9725 - val_loss: 0.1345 - val_accuracy: 0.9617\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0920 - accuracy: 0.9754 - val_loss: 0.1311 - val_accuracy: 0.9621\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0828 - accuracy: 0.9781 - val_loss: 0.1263 - val_accuracy: 0.9627\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0744 - accuracy: 0.9814 - val_loss: 0.1227 - val_accuracy: 0.9638\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0669 - accuracy: 0.9837 - val_loss: 0.1301 - val_accuracy: 0.9645\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0599 - accuracy: 0.9855 - val_loss: 0.1239 - val_accuracy: 0.9649\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0537 - accuracy: 0.9875 - val_loss: 0.1325 - val_accuracy: 0.9644\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0484 - accuracy: 0.9891 - val_loss: 0.1438 - val_accuracy: 0.9650\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0429 - accuracy: 0.9910 - val_loss: 0.1330 - val_accuracy: 0.9638\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0383 - accuracy: 0.9920 - val_loss: 0.1301 - val_accuracy: 0.9653\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0341 - accuracy: 0.9933 - val_loss: 0.1360 - val_accuracy: 0.9637\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0304 - accuracy: 0.9943 - val_loss: 0.1387 - val_accuracy: 0.9631\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0266 - accuracy: 0.9956 - val_loss: 0.1756 - val_accuracy: 0.9628\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0237 - accuracy: 0.9962 - val_loss: 0.1405 - val_accuracy: 0.9644\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0208 - accuracy: 0.9969 - val_loss: 0.1414 - val_accuracy: 0.9632\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152000_[64, 32, 16]_0.0001_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152000_[64, 32, 16]_0.0001_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152000_[64, 32, 16]_0.0001_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.3595 - accuracy: 0.5856 - val_loss: 0.7994 - val_accuracy: 0.7793\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.6919 - accuracy: 0.8106 - val_loss: 0.5207 - val_accuracy: 0.8543\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5007 - accuracy: 0.8586 - val_loss: 0.4037 - val_accuracy: 0.8846\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.4173 - accuracy: 0.8777 - val_loss: 0.3630 - val_accuracy: 0.8947\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3688 - accuracy: 0.8920 - val_loss: 0.3178 - val_accuracy: 0.9067\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3303 - accuracy: 0.9021 - val_loss: 0.2892 - val_accuracy: 0.9137\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3092 - accuracy: 0.9080 - val_loss: 0.2738 - val_accuracy: 0.9182\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2876 - accuracy: 0.9148 - val_loss: 0.2680 - val_accuracy: 0.9196\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2729 - accuracy: 0.9174 - val_loss: 0.2522 - val_accuracy: 0.9243\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2634 - accuracy: 0.9208 - val_loss: 0.2538 - val_accuracy: 0.9247\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2477 - accuracy: 0.9268 - val_loss: 0.2377 - val_accuracy: 0.9303\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2394 - accuracy: 0.9278 - val_loss: 0.2335 - val_accuracy: 0.9310\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2288 - accuracy: 0.9307 - val_loss: 0.2249 - val_accuracy: 0.9347\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2247 - accuracy: 0.9323 - val_loss: 0.2178 - val_accuracy: 0.9360\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2152 - accuracy: 0.9362 - val_loss: 0.2146 - val_accuracy: 0.9373\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2078 - accuracy: 0.9378 - val_loss: 0.2094 - val_accuracy: 0.9358\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2033 - accuracy: 0.9383 - val_loss: 0.2028 - val_accuracy: 0.9377\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1955 - accuracy: 0.9411 - val_loss: 0.1959 - val_accuracy: 0.9398\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1893 - accuracy: 0.9416 - val_loss: 0.1920 - val_accuracy: 0.9427\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1854 - accuracy: 0.9436 - val_loss: 0.1922 - val_accuracy: 0.9432\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1807 - accuracy: 0.9455 - val_loss: 0.1891 - val_accuracy: 0.9435\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1743 - accuracy: 0.9486 - val_loss: 0.1869 - val_accuracy: 0.9452\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1689 - accuracy: 0.9488 - val_loss: 0.1859 - val_accuracy: 0.9433\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1679 - accuracy: 0.9496 - val_loss: 0.1807 - val_accuracy: 0.9461\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1600 - accuracy: 0.9526 - val_loss: 0.1767 - val_accuracy: 0.9469\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152219_[64, 32, 16]_0.0001_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152219_[64, 32, 16]_0.0001_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152219_[64, 32, 16]_0.0001_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.1186 - accuracy: 0.6863 - val_loss: 0.5676 - val_accuracy: 0.8807\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5055 - accuracy: 0.8810 - val_loss: 0.3313 - val_accuracy: 0.9236\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3424 - accuracy: 0.9127 - val_loss: 0.2435 - val_accuracy: 0.9369\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2645 - accuracy: 0.9292 - val_loss: 0.1986 - val_accuracy: 0.9464\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2172 - accuracy: 0.9405 - val_loss: 0.1775 - val_accuracy: 0.9498\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1846 - accuracy: 0.9491 - val_loss: 0.1608 - val_accuracy: 0.9545\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1601 - accuracy: 0.9565 - val_loss: 0.1493 - val_accuracy: 0.9575\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1411 - accuracy: 0.9617 - val_loss: 0.1436 - val_accuracy: 0.9586\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1257 - accuracy: 0.9659 - val_loss: 0.1373 - val_accuracy: 0.9598\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1119 - accuracy: 0.9701 - val_loss: 0.1320 - val_accuracy: 0.9618\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1005 - accuracy: 0.9734 - val_loss: 0.1310 - val_accuracy: 0.9613\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9766 - val_loss: 0.1289 - val_accuracy: 0.9621\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0810 - accuracy: 0.9795 - val_loss: 0.1298 - val_accuracy: 0.9617\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0731 - accuracy: 0.9821 - val_loss: 0.1268 - val_accuracy: 0.9630\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0657 - accuracy: 0.9847 - val_loss: 0.1314 - val_accuracy: 0.9628\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0590 - accuracy: 0.9863 - val_loss: 0.1295 - val_accuracy: 0.9630\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0531 - accuracy: 0.9883 - val_loss: 0.1322 - val_accuracy: 0.9627\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0478 - accuracy: 0.9899 - val_loss: 0.1329 - val_accuracy: 0.9635\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0427 - accuracy: 0.9914 - val_loss: 0.1328 - val_accuracy: 0.9637\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0380 - accuracy: 0.9927 - val_loss: 0.1385 - val_accuracy: 0.9630\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0341 - accuracy: 0.9936 - val_loss: 0.1392 - val_accuracy: 0.9623\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.1434 - val_accuracy: 0.9619\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0270 - accuracy: 0.9953 - val_loss: 0.1477 - val_accuracy: 0.9615\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0239 - accuracy: 0.9966 - val_loss: 0.1463 - val_accuracy: 0.9632\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0212 - accuracy: 0.9967 - val_loss: 0.1507 - val_accuracy: 0.9623\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0184 - accuracy: 0.9973 - val_loss: 0.1519 - val_accuracy: 0.9627\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0169 - accuracy: 0.9976 - val_loss: 0.1584 - val_accuracy: 0.9620\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.1606 - val_accuracy: 0.9621\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 0.1594 - val_accuracy: 0.9626\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0118 - accuracy: 0.9984 - val_loss: 0.1642 - val_accuracy: 0.9609\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0098 - accuracy: 0.9990 - val_loss: 0.1702 - val_accuracy: 0.9604\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.1740 - val_accuracy: 0.9625\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0088 - accuracy: 0.9989 - val_loss: 0.1756 - val_accuracy: 0.9624\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.1815 - val_accuracy: 0.9603\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0066 - accuracy: 0.9993 - val_loss: 0.1851 - val_accuracy: 0.9609\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 0.1869 - val_accuracy: 0.9602\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.1849 - val_accuracy: 0.9621\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.1956 - val_accuracy: 0.9610\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.1929 - val_accuracy: 0.9614\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.2024 - val_accuracy: 0.9597\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.1969 - val_accuracy: 0.9619\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.2085 - val_accuracy: 0.9615\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.1998 - val_accuracy: 0.9627\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.2019 - val_accuracy: 0.9633\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2082 - val_accuracy: 0.9632\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.2096 - val_accuracy: 0.9618\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2074 - val_accuracy: 0.9623\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9626\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 9.0722e-04 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9618\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.2294 - val_accuracy: 0.9617\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152437_[64, 32, 16]_0.0001_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152437_[64, 32, 16]_0.0001_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152437_[64, 32, 16]_0.0001_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.3519 - accuracy: 0.5745 - val_loss: 0.8040 - val_accuracy: 0.7734\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.6898 - accuracy: 0.8101 - val_loss: 0.5337 - val_accuracy: 0.8509\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5126 - accuracy: 0.8540 - val_loss: 0.4344 - val_accuracy: 0.8747\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4279 - accuracy: 0.8763 - val_loss: 0.3638 - val_accuracy: 0.8923\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3755 - accuracy: 0.8891 - val_loss: 0.3368 - val_accuracy: 0.9003\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3362 - accuracy: 0.9007 - val_loss: 0.3012 - val_accuracy: 0.9087\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3117 - accuracy: 0.9083 - val_loss: 0.2822 - val_accuracy: 0.9123\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2934 - accuracy: 0.9136 - val_loss: 0.2655 - val_accuracy: 0.9223\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2773 - accuracy: 0.9177 - val_loss: 0.2516 - val_accuracy: 0.9250\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2621 - accuracy: 0.9230 - val_loss: 0.2432 - val_accuracy: 0.9251\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2478 - accuracy: 0.9271 - val_loss: 0.2244 - val_accuracy: 0.9307\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2397 - accuracy: 0.9286 - val_loss: 0.2239 - val_accuracy: 0.9336\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2344 - accuracy: 0.9309 - val_loss: 0.2188 - val_accuracy: 0.9358\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2260 - accuracy: 0.9329 - val_loss: 0.2110 - val_accuracy: 0.9367\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2201 - accuracy: 0.9354 - val_loss: 0.2133 - val_accuracy: 0.9362\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2054 - accuracy: 0.9394 - val_loss: 0.2107 - val_accuracy: 0.9378\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1998 - accuracy: 0.9407 - val_loss: 0.1971 - val_accuracy: 0.9411\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1958 - accuracy: 0.9411 - val_loss: 0.1910 - val_accuracy: 0.9425\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1934 - accuracy: 0.9415 - val_loss: 0.1882 - val_accuracy: 0.9454\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1891 - accuracy: 0.9434 - val_loss: 0.1907 - val_accuracy: 0.9463\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1852 - accuracy: 0.9451 - val_loss: 0.1835 - val_accuracy: 0.9467\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1788 - accuracy: 0.9467 - val_loss: 0.1882 - val_accuracy: 0.9440\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1744 - accuracy: 0.9473 - val_loss: 0.1893 - val_accuracy: 0.9451\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1687 - accuracy: 0.9495 - val_loss: 0.1796 - val_accuracy: 0.9467\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1660 - accuracy: 0.9502 - val_loss: 0.1773 - val_accuracy: 0.9498\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1659 - accuracy: 0.9498 - val_loss: 0.1790 - val_accuracy: 0.9460\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1613 - accuracy: 0.9518 - val_loss: 0.1772 - val_accuracy: 0.9463\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1577 - accuracy: 0.9521 - val_loss: 0.1747 - val_accuracy: 0.9488\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1531 - accuracy: 0.9541 - val_loss: 0.1799 - val_accuracy: 0.9484\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1538 - accuracy: 0.9549 - val_loss: 0.1674 - val_accuracy: 0.9509\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1481 - accuracy: 0.9556 - val_loss: 0.1645 - val_accuracy: 0.9531\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1488 - accuracy: 0.9554 - val_loss: 0.1698 - val_accuracy: 0.9506\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1422 - accuracy: 0.9572 - val_loss: 0.1663 - val_accuracy: 0.9515\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1392 - accuracy: 0.9587 - val_loss: 0.1649 - val_accuracy: 0.9514\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1400 - accuracy: 0.9575 - val_loss: 0.1676 - val_accuracy: 0.9498\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1385 - accuracy: 0.9574 - val_loss: 0.1676 - val_accuracy: 0.9511\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1322 - accuracy: 0.9594 - val_loss: 0.1617 - val_accuracy: 0.9512\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1312 - accuracy: 0.9592 - val_loss: 0.1637 - val_accuracy: 0.9524\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1298 - accuracy: 0.9605 - val_loss: 0.1617 - val_accuracy: 0.9509\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1256 - accuracy: 0.9619 - val_loss: 0.1587 - val_accuracy: 0.9518\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1282 - accuracy: 0.9617 - val_loss: 0.1580 - val_accuracy: 0.9522\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1262 - accuracy: 0.9616 - val_loss: 0.1579 - val_accuracy: 0.9537\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1205 - accuracy: 0.9639 - val_loss: 0.1613 - val_accuracy: 0.9539\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1186 - accuracy: 0.9642 - val_loss: 0.1578 - val_accuracy: 0.9521\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1149 - accuracy: 0.9653 - val_loss: 0.1534 - val_accuracy: 0.9536\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1136 - accuracy: 0.9660 - val_loss: 0.1590 - val_accuracy: 0.9531\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1146 - accuracy: 0.9650 - val_loss: 0.1559 - val_accuracy: 0.9541\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1081 - accuracy: 0.9677 - val_loss: 0.1545 - val_accuracy: 0.9534\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1150 - accuracy: 0.9648 - val_loss: 0.1571 - val_accuracy: 0.9523\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1093 - accuracy: 0.9671 - val_loss: 0.1594 - val_accuracy: 0.9538\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152911_[64, 32, 16]_0.0001_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152911_[64, 32, 16]_0.0001_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_152911_[64, 32, 16]_0.0001_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6032 - accuracy: 0.8378 - val_loss: 0.2533 - val_accuracy: 0.9286\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2505 - accuracy: 0.9278 - val_loss: 0.1759 - val_accuracy: 0.9485\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1987 - accuracy: 0.9421 - val_loss: 0.1638 - val_accuracy: 0.9496\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1681 - accuracy: 0.9501 - val_loss: 0.1561 - val_accuracy: 0.9536\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1476 - accuracy: 0.9568 - val_loss: 0.1380 - val_accuracy: 0.9588\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1309 - accuracy: 0.9616 - val_loss: 0.1536 - val_accuracy: 0.9553\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1214 - accuracy: 0.9636 - val_loss: 0.1348 - val_accuracy: 0.9598\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1097 - accuracy: 0.9673 - val_loss: 0.1355 - val_accuracy: 0.9601\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1014 - accuracy: 0.9694 - val_loss: 0.1446 - val_accuracy: 0.9592\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0938 - accuracy: 0.9718 - val_loss: 0.1334 - val_accuracy: 0.9605\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153354_[32, 16, 8]_0.001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153354_[32, 16, 8]_0.001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153354_[32, 16, 8]_0.001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.9747 - accuracy: 0.6913 - val_loss: 0.7313 - val_accuracy: 0.7529\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.6319 - accuracy: 0.8018 - val_loss: 0.5294 - val_accuracy: 0.8367\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5406 - accuracy: 0.8352 - val_loss: 0.5068 - val_accuracy: 0.8402\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5185 - accuracy: 0.8399 - val_loss: 0.4750 - val_accuracy: 0.8533\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4917 - accuracy: 0.8493 - val_loss: 0.4417 - val_accuracy: 0.8676\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4769 - accuracy: 0.8551 - val_loss: 0.4558 - val_accuracy: 0.8620\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4682 - accuracy: 0.8581 - val_loss: 0.4104 - val_accuracy: 0.8689\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4391 - accuracy: 0.8672 - val_loss: 0.3980 - val_accuracy: 0.8814\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4283 - accuracy: 0.8718 - val_loss: 0.3760 - val_accuracy: 0.8834\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4041 - accuracy: 0.8777 - val_loss: 0.3815 - val_accuracy: 0.8808\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153452_[32, 16, 8]_0.001_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153452_[32, 16, 8]_0.001_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153452_[32, 16, 8]_0.001_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6047 - accuracy: 0.8413 - val_loss: 0.2372 - val_accuracy: 0.9337\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2481 - accuracy: 0.9287 - val_loss: 0.1825 - val_accuracy: 0.9473\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1942 - accuracy: 0.9431 - val_loss: 0.1758 - val_accuracy: 0.9508\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1655 - accuracy: 0.9524 - val_loss: 0.1448 - val_accuracy: 0.9560\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1434 - accuracy: 0.9573 - val_loss: 0.1366 - val_accuracy: 0.9587\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1283 - accuracy: 0.9624 - val_loss: 0.1320 - val_accuracy: 0.9589\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1156 - accuracy: 0.9655 - val_loss: 0.1319 - val_accuracy: 0.9603\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1047 - accuracy: 0.9679 - val_loss: 0.1222 - val_accuracy: 0.9632\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0970 - accuracy: 0.9707 - val_loss: 0.1391 - val_accuracy: 0.9604\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0881 - accuracy: 0.9727 - val_loss: 0.1308 - val_accuracy: 0.9626\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0806 - accuracy: 0.9750 - val_loss: 0.1328 - val_accuracy: 0.9626\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0744 - accuracy: 0.9779 - val_loss: 0.1382 - val_accuracy: 0.9613\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0705 - accuracy: 0.9783 - val_loss: 0.1398 - val_accuracy: 0.9621\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0653 - accuracy: 0.9801 - val_loss: 0.1496 - val_accuracy: 0.9592\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0596 - accuracy: 0.9822 - val_loss: 0.1428 - val_accuracy: 0.9618\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 0.1444 - val_accuracy: 0.9653\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0533 - accuracy: 0.9831 - val_loss: 0.1573 - val_accuracy: 0.9582\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0506 - accuracy: 0.9846 - val_loss: 0.1541 - val_accuracy: 0.9625\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0472 - accuracy: 0.9856 - val_loss: 0.1531 - val_accuracy: 0.9613\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 0.1555 - val_accuracy: 0.9602\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0421 - accuracy: 0.9870 - val_loss: 0.1618 - val_accuracy: 0.9612\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0416 - accuracy: 0.9870 - val_loss: 0.1582 - val_accuracy: 0.9621\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0370 - accuracy: 0.9886 - val_loss: 0.1609 - val_accuracy: 0.9615\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.1675 - val_accuracy: 0.9603\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 0.1821 - val_accuracy: 0.9593\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153551_[32, 16, 8]_0.001_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153551_[32, 16, 8]_0.001_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153551_[32, 16, 8]_0.001_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.9705 - accuracy: 0.6971 - val_loss: 0.6442 - val_accuracy: 0.7944\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.6333 - accuracy: 0.8040 - val_loss: 0.5745 - val_accuracy: 0.8205\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5801 - accuracy: 0.8242 - val_loss: 0.5449 - val_accuracy: 0.8258\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5600 - accuracy: 0.8270 - val_loss: 0.4736 - val_accuracy: 0.8597\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4910 - accuracy: 0.8536 - val_loss: 0.4263 - val_accuracy: 0.8716\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4605 - accuracy: 0.8604 - val_loss: 0.4450 - val_accuracy: 0.8652\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4763 - accuracy: 0.8552 - val_loss: 0.4421 - val_accuracy: 0.8567\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4658 - accuracy: 0.8585 - val_loss: 0.4502 - val_accuracy: 0.8599\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4393 - accuracy: 0.8660 - val_loss: 0.4069 - val_accuracy: 0.8773\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4163 - accuracy: 0.8771 - val_loss: 0.3761 - val_accuracy: 0.8848\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4235 - accuracy: 0.8732 - val_loss: 0.3779 - val_accuracy: 0.8867\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4179 - accuracy: 0.8756 - val_loss: 0.3606 - val_accuracy: 0.8903\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4056 - accuracy: 0.8776 - val_loss: 0.3708 - val_accuracy: 0.8848\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3893 - accuracy: 0.8832 - val_loss: 0.3412 - val_accuracy: 0.8963\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3955 - accuracy: 0.8793 - val_loss: 0.3733 - val_accuracy: 0.8866\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3950 - accuracy: 0.8813 - val_loss: 0.3551 - val_accuracy: 0.8898\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3914 - accuracy: 0.8799 - val_loss: 0.3373 - val_accuracy: 0.8984\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3785 - accuracy: 0.8879 - val_loss: 0.3580 - val_accuracy: 0.8867\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3717 - accuracy: 0.8906 - val_loss: 0.3229 - val_accuracy: 0.9067\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3520 - accuracy: 0.8954 - val_loss: 0.3158 - val_accuracy: 0.9068\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3621 - accuracy: 0.8931 - val_loss: 0.3275 - val_accuracy: 0.9030\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3545 - accuracy: 0.8947 - val_loss: 0.3283 - val_accuracy: 0.8993\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3429 - accuracy: 0.8989 - val_loss: 0.3103 - val_accuracy: 0.9086\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3460 - accuracy: 0.8965 - val_loss: 0.3225 - val_accuracy: 0.9043\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3555 - accuracy: 0.8970 - val_loss: 0.3273 - val_accuracy: 0.9022\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153818_[32, 16, 8]_0.001_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153818_[32, 16, 8]_0.001_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_153818_[32, 16, 8]_0.001_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6219 - accuracy: 0.8330 - val_loss: 0.2479 - val_accuracy: 0.9304\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2616 - accuracy: 0.9237 - val_loss: 0.1891 - val_accuracy: 0.9462\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2040 - accuracy: 0.9399 - val_loss: 0.1621 - val_accuracy: 0.9533\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1723 - accuracy: 0.9492 - val_loss: 0.1474 - val_accuracy: 0.9553\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1503 - accuracy: 0.9553 - val_loss: 0.1367 - val_accuracy: 0.9580\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1321 - accuracy: 0.9609 - val_loss: 0.1352 - val_accuracy: 0.9586\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1198 - accuracy: 0.9640 - val_loss: 0.1310 - val_accuracy: 0.9603\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1089 - accuracy: 0.9666 - val_loss: 0.1314 - val_accuracy: 0.9606\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1006 - accuracy: 0.9698 - val_loss: 0.1246 - val_accuracy: 0.9637\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0940 - accuracy: 0.9711 - val_loss: 0.1336 - val_accuracy: 0.9597\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0869 - accuracy: 0.9739 - val_loss: 0.1291 - val_accuracy: 0.9619\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0815 - accuracy: 0.9752 - val_loss: 0.1310 - val_accuracy: 0.9619\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9776 - val_loss: 0.1369 - val_accuracy: 0.9614\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0719 - accuracy: 0.9784 - val_loss: 0.1412 - val_accuracy: 0.9604\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0681 - accuracy: 0.9798 - val_loss: 0.1387 - val_accuracy: 0.9625\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0629 - accuracy: 0.9807 - val_loss: 0.1357 - val_accuracy: 0.9615\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0590 - accuracy: 0.9821 - val_loss: 0.1411 - val_accuracy: 0.9617\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0565 - accuracy: 0.9827 - val_loss: 0.1522 - val_accuracy: 0.9615\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0531 - accuracy: 0.9835 - val_loss: 0.1493 - val_accuracy: 0.9607\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 0.1520 - val_accuracy: 0.9611\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0479 - accuracy: 0.9856 - val_loss: 0.1503 - val_accuracy: 0.9633\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 0.1623 - val_accuracy: 0.9606\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 0.1575 - val_accuracy: 0.9614\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.1688 - val_accuracy: 0.9608\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.1722 - val_accuracy: 0.9602\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0377 - accuracy: 0.9881 - val_loss: 0.1686 - val_accuracy: 0.9618\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0350 - accuracy: 0.9897 - val_loss: 0.1904 - val_accuracy: 0.9574\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 0.1754 - val_accuracy: 0.9598\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.1761 - val_accuracy: 0.9606\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0310 - accuracy: 0.9904 - val_loss: 0.1935 - val_accuracy: 0.9578\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0271 - accuracy: 0.9918 - val_loss: 0.1911 - val_accuracy: 0.9594\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.1801 - val_accuracy: 0.9609\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0275 - accuracy: 0.9914 - val_loss: 0.1898 - val_accuracy: 0.9608\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.1961 - val_accuracy: 0.9609\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0255 - accuracy: 0.9920 - val_loss: 0.1991 - val_accuracy: 0.9586\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.1921 - val_accuracy: 0.9609\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.2072 - val_accuracy: 0.9591\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.2101 - val_accuracy: 0.9600\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.2021 - val_accuracy: 0.9609\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.2058 - val_accuracy: 0.9607\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.2231 - val_accuracy: 0.9577\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.2159 - val_accuracy: 0.9581\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.2163 - val_accuracy: 0.9603\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.2202 - val_accuracy: 0.9605\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0192 - accuracy: 0.9931 - val_loss: 0.2159 - val_accuracy: 0.9606\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0194 - accuracy: 0.9941 - val_loss: 0.2195 - val_accuracy: 0.9590\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.2500 - val_accuracy: 0.9563\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.2325 - val_accuracy: 0.9592\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.2270 - val_accuracy: 0.9601\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.2526 - val_accuracy: 0.9563\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154032_[32, 16, 8]_0.001_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154032_[32, 16, 8]_0.001_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154032_[32, 16, 8]_0.001_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.0008 - accuracy: 0.6870 - val_loss: 0.6303 - val_accuracy: 0.7933\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6567 - accuracy: 0.7916 - val_loss: 0.6230 - val_accuracy: 0.8073\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5604 - accuracy: 0.8279 - val_loss: 0.4946 - val_accuracy: 0.8517\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5167 - accuracy: 0.8434 - val_loss: 0.4421 - val_accuracy: 0.8698\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4875 - accuracy: 0.8552 - val_loss: 0.3972 - val_accuracy: 0.8821\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4755 - accuracy: 0.8557 - val_loss: 0.4199 - val_accuracy: 0.8735\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4548 - accuracy: 0.8650 - val_loss: 0.3882 - val_accuracy: 0.8822\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4485 - accuracy: 0.8669 - val_loss: 0.3643 - val_accuracy: 0.8904\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4216 - accuracy: 0.8768 - val_loss: 0.3869 - val_accuracy: 0.8835\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4022 - accuracy: 0.8819 - val_loss: 0.3673 - val_accuracy: 0.8864\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4032 - accuracy: 0.8801 - val_loss: 0.3517 - val_accuracy: 0.8937\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4277 - accuracy: 0.8726 - val_loss: 0.3592 - val_accuracy: 0.8896\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4011 - accuracy: 0.8836 - val_loss: 0.3561 - val_accuracy: 0.8907\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3871 - accuracy: 0.8853 - val_loss: 0.3442 - val_accuracy: 0.8974\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3898 - accuracy: 0.8832 - val_loss: 0.3578 - val_accuracy: 0.8903\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3810 - accuracy: 0.8892 - val_loss: 0.3538 - val_accuracy: 0.8997\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3748 - accuracy: 0.8896 - val_loss: 0.3450 - val_accuracy: 0.8980\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3816 - accuracy: 0.8855 - val_loss: 0.3429 - val_accuracy: 0.8933\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3794 - accuracy: 0.8874 - val_loss: 0.3309 - val_accuracy: 0.9020\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3792 - accuracy: 0.8876 - val_loss: 0.3147 - val_accuracy: 0.9061\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3500 - accuracy: 0.8992 - val_loss: 0.3333 - val_accuracy: 0.9015\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3541 - accuracy: 0.8999 - val_loss: 0.3134 - val_accuracy: 0.9099\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3494 - accuracy: 0.8973 - val_loss: 0.3190 - val_accuracy: 0.9068\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3577 - accuracy: 0.8974 - val_loss: 0.3101 - val_accuracy: 0.9113\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3379 - accuracy: 0.9021 - val_loss: 0.3543 - val_accuracy: 0.8994\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3410 - accuracy: 0.9020 - val_loss: 0.3347 - val_accuracy: 0.9017\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3471 - accuracy: 0.8997 - val_loss: 0.3248 - val_accuracy: 0.9078\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3322 - accuracy: 0.9032 - val_loss: 0.3186 - val_accuracy: 0.9087\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3383 - accuracy: 0.9026 - val_loss: 0.3028 - val_accuracy: 0.9081\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3248 - accuracy: 0.9029 - val_loss: 0.3042 - val_accuracy: 0.9065\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3175 - accuracy: 0.9045 - val_loss: 0.2951 - val_accuracy: 0.9167\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3274 - accuracy: 0.9058 - val_loss: 0.2950 - val_accuracy: 0.9132\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3302 - accuracy: 0.9055 - val_loss: 0.2986 - val_accuracy: 0.9096\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3140 - accuracy: 0.9083 - val_loss: 0.2968 - val_accuracy: 0.9086\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3132 - accuracy: 0.9056 - val_loss: 0.2812 - val_accuracy: 0.9152\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3094 - accuracy: 0.9071 - val_loss: 0.3138 - val_accuracy: 0.9028\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3401 - accuracy: 0.8991 - val_loss: 0.3136 - val_accuracy: 0.9072\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3265 - accuracy: 0.9025 - val_loss: 0.2831 - val_accuracy: 0.9154\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3085 - accuracy: 0.9101 - val_loss: 0.2875 - val_accuracy: 0.9091\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3046 - accuracy: 0.9095 - val_loss: 0.2668 - val_accuracy: 0.9220\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2946 - accuracy: 0.9127 - val_loss: 0.2944 - val_accuracy: 0.9090\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3160 - accuracy: 0.9059 - val_loss: 0.2762 - val_accuracy: 0.9216\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3141 - accuracy: 0.9079 - val_loss: 0.2818 - val_accuracy: 0.9155\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3006 - accuracy: 0.9112 - val_loss: 0.2980 - val_accuracy: 0.9120\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3136 - accuracy: 0.9082 - val_loss: 0.2847 - val_accuracy: 0.9166\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2928 - accuracy: 0.9156 - val_loss: 0.2752 - val_accuracy: 0.9183\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3112 - accuracy: 0.9096 - val_loss: 0.2788 - val_accuracy: 0.9178\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2967 - accuracy: 0.9145 - val_loss: 0.2714 - val_accuracy: 0.9221\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2985 - accuracy: 0.9127 - val_loss: 0.2691 - val_accuracy: 0.9228\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2891 - accuracy: 0.9150 - val_loss: 0.2627 - val_accuracy: 0.9242\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154434_[32, 16, 8]_0.001_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154434_[32, 16, 8]_0.001_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154434_[32, 16, 8]_0.001_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.8176 - accuracy: 0.7861 - val_loss: 0.3146 - val_accuracy: 0.9210\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3101 - accuracy: 0.9155 - val_loss: 0.2057 - val_accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2318 - accuracy: 0.9336 - val_loss: 0.1723 - val_accuracy: 0.9501\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1902 - accuracy: 0.9448 - val_loss: 0.1668 - val_accuracy: 0.9560\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1658 - accuracy: 0.9524 - val_loss: 0.1635 - val_accuracy: 0.9532\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1477 - accuracy: 0.9577 - val_loss: 0.1464 - val_accuracy: 0.9578\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1339 - accuracy: 0.9606 - val_loss: 0.1390 - val_accuracy: 0.9584\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1218 - accuracy: 0.9646 - val_loss: 0.1604 - val_accuracy: 0.9597\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1113 - accuracy: 0.9671 - val_loss: 0.1471 - val_accuracy: 0.9603\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1048 - accuracy: 0.9684 - val_loss: 0.1396 - val_accuracy: 0.9599\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154838_[32, 16, 8]_0.0005_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154838_[32, 16, 8]_0.0005_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154838_[32, 16, 8]_0.0005_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.0989 - accuracy: 0.6683 - val_loss: 0.6565 - val_accuracy: 0.7982\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5982 - accuracy: 0.8216 - val_loss: 0.5161 - val_accuracy: 0.8424\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5314 - accuracy: 0.8388 - val_loss: 0.4818 - val_accuracy: 0.8520\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4801 - accuracy: 0.8545 - val_loss: 0.4171 - val_accuracy: 0.8777\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4531 - accuracy: 0.8668 - val_loss: 0.4518 - val_accuracy: 0.8514\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4279 - accuracy: 0.8752 - val_loss: 0.3758 - val_accuracy: 0.8888\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4224 - accuracy: 0.8757 - val_loss: 0.3849 - val_accuracy: 0.8863\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4087 - accuracy: 0.8785 - val_loss: 0.4085 - val_accuracy: 0.8709\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3958 - accuracy: 0.8834 - val_loss: 0.3405 - val_accuracy: 0.8981\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3681 - accuracy: 0.8928 - val_loss: 0.3356 - val_accuracy: 0.9007\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154926_[32, 16, 8]_0.0005_10_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154926_[32, 16, 8]_0.0005_10_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_154926_[32, 16, 8]_0.0005_10_sigmoid\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.8403 - accuracy: 0.7721 - val_loss: 0.3201 - val_accuracy: 0.9247\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3020 - accuracy: 0.9190 - val_loss: 0.2558 - val_accuracy: 0.9421\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2190 - accuracy: 0.9384 - val_loss: 0.2437 - val_accuracy: 0.9518\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1824 - accuracy: 0.9477 - val_loss: 0.2686 - val_accuracy: 0.9531\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1616 - accuracy: 0.9537 - val_loss: 0.2147 - val_accuracy: 0.9542\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1415 - accuracy: 0.9592 - val_loss: 0.2217 - val_accuracy: 0.9498\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1294 - accuracy: 0.9620 - val_loss: 0.2617 - val_accuracy: 0.9581\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1170 - accuracy: 0.9650 - val_loss: 0.2198 - val_accuracy: 0.9595\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1077 - accuracy: 0.9680 - val_loss: 0.1768 - val_accuracy: 0.9582\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1002 - accuracy: 0.9699 - val_loss: 0.1602 - val_accuracy: 0.9570\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0937 - accuracy: 0.9716 - val_loss: 0.1454 - val_accuracy: 0.9589\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9740 - val_loss: 0.1463 - val_accuracy: 0.9599\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0815 - accuracy: 0.9755 - val_loss: 0.1576 - val_accuracy: 0.9570\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0770 - accuracy: 0.9768 - val_loss: 0.1581 - val_accuracy: 0.9577\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0754 - accuracy: 0.9768 - val_loss: 0.1495 - val_accuracy: 0.9597\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0673 - accuracy: 0.9796 - val_loss: 0.1586 - val_accuracy: 0.9583\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0660 - accuracy: 0.9803 - val_loss: 0.1577 - val_accuracy: 0.9604\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0616 - accuracy: 0.9817 - val_loss: 0.1606 - val_accuracy: 0.9586\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0580 - accuracy: 0.9825 - val_loss: 0.1624 - val_accuracy: 0.9588\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0561 - accuracy: 0.9829 - val_loss: 0.1606 - val_accuracy: 0.9619\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0516 - accuracy: 0.9845 - val_loss: 0.1734 - val_accuracy: 0.9567\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0516 - accuracy: 0.9840 - val_loss: 0.1780 - val_accuracy: 0.9591\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0487 - accuracy: 0.9852 - val_loss: 0.1763 - val_accuracy: 0.9575\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0464 - accuracy: 0.9860 - val_loss: 0.1800 - val_accuracy: 0.9592\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0435 - accuracy: 0.9870 - val_loss: 0.1864 - val_accuracy: 0.9572\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155015_[32, 16, 8]_0.0005_25_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155015_[32, 16, 8]_0.0005_25_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155015_[32, 16, 8]_0.0005_25_relu\\performance_plot.png\n",
      "Epoch 1/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.0697 - accuracy: 0.6676 - val_loss: 0.5739 - val_accuracy: 0.8355\n",
      "Epoch 2/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5849 - accuracy: 0.8232 - val_loss: 0.5447 - val_accuracy: 0.8290\n",
      "Epoch 3/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4931 - accuracy: 0.8524 - val_loss: 0.4106 - val_accuracy: 0.8767\n",
      "Epoch 4/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4543 - accuracy: 0.8674 - val_loss: 0.3837 - val_accuracy: 0.8871\n",
      "Epoch 5/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4327 - accuracy: 0.8693 - val_loss: 0.3638 - val_accuracy: 0.8933\n",
      "Epoch 6/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4024 - accuracy: 0.8817 - val_loss: 0.3532 - val_accuracy: 0.8955\n",
      "Epoch 7/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3764 - accuracy: 0.8888 - val_loss: 0.3368 - val_accuracy: 0.9047\n",
      "Epoch 8/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3656 - accuracy: 0.8930 - val_loss: 0.3070 - val_accuracy: 0.9114\n",
      "Epoch 9/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3470 - accuracy: 0.8983 - val_loss: 0.3125 - val_accuracy: 0.9094\n",
      "Epoch 10/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3535 - accuracy: 0.8959 - val_loss: 0.3061 - val_accuracy: 0.9115\n",
      "Epoch 11/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3438 - accuracy: 0.9004 - val_loss: 0.3238 - val_accuracy: 0.9021\n",
      "Epoch 12/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3364 - accuracy: 0.9016 - val_loss: 0.3080 - val_accuracy: 0.9073\n",
      "Epoch 13/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3178 - accuracy: 0.9051 - val_loss: 0.2815 - val_accuracy: 0.9137\n",
      "Epoch 14/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3192 - accuracy: 0.9075 - val_loss: 0.2854 - val_accuracy: 0.9163\n",
      "Epoch 15/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3141 - accuracy: 0.9071 - val_loss: 0.2837 - val_accuracy: 0.9197\n",
      "Epoch 16/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3082 - accuracy: 0.9106 - val_loss: 0.2943 - val_accuracy: 0.9163\n",
      "Epoch 17/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3228 - accuracy: 0.9054 - val_loss: 0.2874 - val_accuracy: 0.9145\n",
      "Epoch 18/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3131 - accuracy: 0.9084 - val_loss: 0.2851 - val_accuracy: 0.9171\n",
      "Epoch 19/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3130 - accuracy: 0.9089 - val_loss: 0.2998 - val_accuracy: 0.9112\n",
      "Epoch 20/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3047 - accuracy: 0.9112 - val_loss: 0.2778 - val_accuracy: 0.9193\n",
      "Epoch 21/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2970 - accuracy: 0.9133 - val_loss: 0.2693 - val_accuracy: 0.9230\n",
      "Epoch 22/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2830 - accuracy: 0.9172 - val_loss: 0.2707 - val_accuracy: 0.9201\n",
      "Epoch 23/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2854 - accuracy: 0.9161 - val_loss: 0.2722 - val_accuracy: 0.9192\n",
      "Epoch 24/25\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2953 - accuracy: 0.9136 - val_loss: 0.2845 - val_accuracy: 0.9114\n",
      "Epoch 25/25\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2899 - accuracy: 0.9154 - val_loss: 0.2584 - val_accuracy: 0.9239\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155218_[32, 16, 8]_0.0005_25_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155218_[32, 16, 8]_0.0005_25_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155218_[32, 16, 8]_0.0005_25_sigmoid\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.8324 - accuracy: 0.7864 - val_loss: 0.3347 - val_accuracy: 0.9197\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3403 - accuracy: 0.9119 - val_loss: 0.2320 - val_accuracy: 0.9383\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2556 - accuracy: 0.9320 - val_loss: 0.1923 - val_accuracy: 0.9476\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2128 - accuracy: 0.9410 - val_loss: 0.1785 - val_accuracy: 0.9509\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1836 - accuracy: 0.9489 - val_loss: 0.1670 - val_accuracy: 0.9515\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1637 - accuracy: 0.9533 - val_loss: 0.1550 - val_accuracy: 0.9563\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1463 - accuracy: 0.9577 - val_loss: 0.1520 - val_accuracy: 0.9569\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1344 - accuracy: 0.9607 - val_loss: 0.1465 - val_accuracy: 0.9572\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1230 - accuracy: 0.9641 - val_loss: 0.1434 - val_accuracy: 0.9593\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1127 - accuracy: 0.9666 - val_loss: 0.1491 - val_accuracy: 0.9588\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1063 - accuracy: 0.9686 - val_loss: 0.1476 - val_accuracy: 0.9592\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0968 - accuracy: 0.9720 - val_loss: 0.1468 - val_accuracy: 0.9599\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0907 - accuracy: 0.9733 - val_loss: 0.1469 - val_accuracy: 0.9585\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0854 - accuracy: 0.9745 - val_loss: 0.1502 - val_accuracy: 0.9589\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9764 - val_loss: 0.1588 - val_accuracy: 0.9586\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0738 - accuracy: 0.9778 - val_loss: 0.1547 - val_accuracy: 0.9595\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0692 - accuracy: 0.9797 - val_loss: 0.1623 - val_accuracy: 0.9600\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9798 - val_loss: 0.1529 - val_accuracy: 0.9606\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0620 - accuracy: 0.9815 - val_loss: 0.1682 - val_accuracy: 0.9595\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0590 - accuracy: 0.9827 - val_loss: 0.1532 - val_accuracy: 0.9616\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0559 - accuracy: 0.9835 - val_loss: 0.1567 - val_accuracy: 0.9606\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0520 - accuracy: 0.9850 - val_loss: 0.1709 - val_accuracy: 0.9609\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.1783 - val_accuracy: 0.9581\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0467 - accuracy: 0.9865 - val_loss: 0.1737 - val_accuracy: 0.9592\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0450 - accuracy: 0.9872 - val_loss: 0.1707 - val_accuracy: 0.9609\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0423 - accuracy: 0.9876 - val_loss: 0.1806 - val_accuracy: 0.9594\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0427 - accuracy: 0.9872 - val_loss: 0.1938 - val_accuracy: 0.9582\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.1831 - val_accuracy: 0.9609\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0364 - accuracy: 0.9892 - val_loss: 0.1983 - val_accuracy: 0.9570\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0366 - accuracy: 0.9885 - val_loss: 0.1960 - val_accuracy: 0.9591\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.1955 - val_accuracy: 0.9597\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0313 - accuracy: 0.9910 - val_loss: 0.2053 - val_accuracy: 0.9587\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0319 - accuracy: 0.9903 - val_loss: 0.2061 - val_accuracy: 0.9570\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0308 - accuracy: 0.9908 - val_loss: 0.2139 - val_accuracy: 0.9580\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.2067 - val_accuracy: 0.9588\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0278 - accuracy: 0.9914 - val_loss: 0.2238 - val_accuracy: 0.9568\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.2169 - val_accuracy: 0.9593\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0250 - accuracy: 0.9924 - val_loss: 0.2278 - val_accuracy: 0.9585\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.2319 - val_accuracy: 0.9569\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.2323 - val_accuracy: 0.9583\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0215 - accuracy: 0.9937 - val_loss: 0.2309 - val_accuracy: 0.9571\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.2371 - val_accuracy: 0.9590\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.2506 - val_accuracy: 0.9562\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.2864 - val_accuracy: 0.9511\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.2515 - val_accuracy: 0.9570\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.2463 - val_accuracy: 0.9580\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.2657 - val_accuracy: 0.9564\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.2688 - val_accuracy: 0.9566\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.2578 - val_accuracy: 0.9572\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0160 - accuracy: 0.9950 - val_loss: 0.2714 - val_accuracy: 0.9568\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155418_[32, 16, 8]_0.0005_50_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155418_[32, 16, 8]_0.0005_50_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155418_[32, 16, 8]_0.0005_50_relu\\performance_plot.png\n",
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.0768 - accuracy: 0.6774 - val_loss: 0.6238 - val_accuracy: 0.8162\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5783 - accuracy: 0.8265 - val_loss: 0.5172 - val_accuracy: 0.8437\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4996 - accuracy: 0.8504 - val_loss: 0.4475 - val_accuracy: 0.8596\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4552 - accuracy: 0.8648 - val_loss: 0.4325 - val_accuracy: 0.8686\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4401 - accuracy: 0.8706 - val_loss: 0.3826 - val_accuracy: 0.8884\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4129 - accuracy: 0.8768 - val_loss: 0.3413 - val_accuracy: 0.9001\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3803 - accuracy: 0.8890 - val_loss: 0.3509 - val_accuracy: 0.8967\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3832 - accuracy: 0.8860 - val_loss: 0.3444 - val_accuracy: 0.8972\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3651 - accuracy: 0.8923 - val_loss: 0.3069 - val_accuracy: 0.9111\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3489 - accuracy: 0.8971 - val_loss: 0.3179 - val_accuracy: 0.9060\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3540 - accuracy: 0.8938 - val_loss: 0.3174 - val_accuracy: 0.9067\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3303 - accuracy: 0.9019 - val_loss: 0.3028 - val_accuracy: 0.9103\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3297 - accuracy: 0.9015 - val_loss: 0.3044 - val_accuracy: 0.9107\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3240 - accuracy: 0.9041 - val_loss: 0.2893 - val_accuracy: 0.9154\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3082 - accuracy: 0.9084 - val_loss: 0.2885 - val_accuracy: 0.9145\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3094 - accuracy: 0.9078 - val_loss: 0.3128 - val_accuracy: 0.9007\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3088 - accuracy: 0.9081 - val_loss: 0.2834 - val_accuracy: 0.9127\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2970 - accuracy: 0.9122 - val_loss: 0.2679 - val_accuracy: 0.9236\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2902 - accuracy: 0.9143 - val_loss: 0.2688 - val_accuracy: 0.9179\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2904 - accuracy: 0.9130 - val_loss: 0.2696 - val_accuracy: 0.9212\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2951 - accuracy: 0.9114 - val_loss: 0.2764 - val_accuracy: 0.9173\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2893 - accuracy: 0.9135 - val_loss: 0.2657 - val_accuracy: 0.9196\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2671 - accuracy: 0.9209 - val_loss: 0.2534 - val_accuracy: 0.9273\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2699 - accuracy: 0.9211 - val_loss: 0.2558 - val_accuracy: 0.9284\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2907 - accuracy: 0.9126 - val_loss: 0.2704 - val_accuracy: 0.9203\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2859 - accuracy: 0.9153 - val_loss: 0.2742 - val_accuracy: 0.9165\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2746 - accuracy: 0.9175 - val_loss: 0.2454 - val_accuracy: 0.9277\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2674 - accuracy: 0.9209 - val_loss: 0.2382 - val_accuracy: 0.9270\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2666 - accuracy: 0.9212 - val_loss: 0.2459 - val_accuracy: 0.9275\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2659 - accuracy: 0.9219 - val_loss: 0.2414 - val_accuracy: 0.9278\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2699 - accuracy: 0.9193 - val_loss: 0.2401 - val_accuracy: 0.9262\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2588 - accuracy: 0.9231 - val_loss: 0.2547 - val_accuracy: 0.9225\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2518 - accuracy: 0.9249 - val_loss: 0.2413 - val_accuracy: 0.9283\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2536 - accuracy: 0.9254 - val_loss: 0.2486 - val_accuracy: 0.9258\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2580 - accuracy: 0.9246 - val_loss: 0.2551 - val_accuracy: 0.9276\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2588 - accuracy: 0.9227 - val_loss: 0.2421 - val_accuracy: 0.9298\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2444 - accuracy: 0.9289 - val_loss: 0.2325 - val_accuracy: 0.9325\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2412 - accuracy: 0.9286 - val_loss: 0.2284 - val_accuracy: 0.9324\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2443 - accuracy: 0.9276 - val_loss: 0.2451 - val_accuracy: 0.9270\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2528 - accuracy: 0.9227 - val_loss: 0.2224 - val_accuracy: 0.9346\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2302 - accuracy: 0.9308 - val_loss: 0.2159 - val_accuracy: 0.9360\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9306 - val_loss: 0.2202 - val_accuracy: 0.9347\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2438 - accuracy: 0.9278 - val_loss: 0.2472 - val_accuracy: 0.9271\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2376 - accuracy: 0.9297 - val_loss: 0.2182 - val_accuracy: 0.9367\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2310 - accuracy: 0.9326 - val_loss: 0.2317 - val_accuracy: 0.9320\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2284 - accuracy: 0.9324 - val_loss: 0.2228 - val_accuracy: 0.9351\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2214 - accuracy: 0.9342 - val_loss: 0.2138 - val_accuracy: 0.9390\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2311 - accuracy: 0.9310 - val_loss: 0.2261 - val_accuracy: 0.9327\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2257 - accuracy: 0.9326 - val_loss: 0.2070 - val_accuracy: 0.9392\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2254 - accuracy: 0.9329 - val_loss: 0.2127 - val_accuracy: 0.9369\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155823_[32, 16, 8]_0.0005_50_sigmoid\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155823_[32, 16, 8]_0.0005_50_sigmoid\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_155823_[32, 16, 8]_0.0005_50_sigmoid\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.4637 - accuracy: 0.5893 - val_loss: 0.9580 - val_accuracy: 0.8072\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.8350 - accuracy: 0.8200 - val_loss: 0.6023 - val_accuracy: 0.8770\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5733 - accuracy: 0.8694 - val_loss: 0.4283 - val_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4448 - accuracy: 0.8920 - val_loss: 0.3602 - val_accuracy: 0.9146\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3739 - accuracy: 0.9040 - val_loss: 0.2967 - val_accuracy: 0.9224\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3289 - accuracy: 0.9133 - val_loss: 0.2688 - val_accuracy: 0.9294\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2980 - accuracy: 0.9195 - val_loss: 0.2463 - val_accuracy: 0.9328\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2738 - accuracy: 0.9252 - val_loss: 0.2318 - val_accuracy: 0.9362\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2542 - accuracy: 0.9301 - val_loss: 0.2238 - val_accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2386 - accuracy: 0.9341 - val_loss: 0.2142 - val_accuracy: 0.9402\n",
      "Model saved as c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_160231_[32, 16, 8]_0.0001_10_relu\\model.h5\n",
      "Training parameters and results saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_160231_[32, 16, 8]_0.0001_10_relu\\params_results.json\n",
      "Performance plot saved at c:\\mnguyen\\programming-project\\mnist\\ann_model_results/241129_160231_[32, 16, 8]_0.0001_10_relu\\performance_plot.png\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.7596 - accuracy: 0.4189 - val_loss: 1.2905 - val_accuracy: 0.6139\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.1103 - accuracy: 0.6944 - val_loss: 0.8715 - val_accuracy: 0.7686\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.7996 - accuracy: 0.7914 - val_loss: 0.6382 - val_accuracy: 0.8299\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6311 - accuracy: 0.8285 - val_loss: 0.5320 - val_accuracy: 0.8511\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5381 - accuracy: 0.8492 - val_loss: 0.4626 - val_accuracy: 0.8683\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4779 - accuracy: 0.8662 - val_loss: 0.4261 - val_accuracy: 0.8745\n",
      "Epoch 7/10\n",
      " 119/1500 [=>............................] - ETA: 4s - loss: 0.4478 - accuracy: 0.8697"
     ]
    }
   ],
   "source": [
    "for layer_width in LAYER_WIDTHS:\n",
    "    for lr in LEARNING_RATE:\n",
    "        for epoch in EPOCH:\n",
    "            for activation in ACTIVATION:\n",
    "\n",
    "                # Create the directory for this \n",
    "                timestamp = datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
    "                BASE_DIR = os.getcwd()\n",
    "                OUTPUT_DIR = os.path.join(BASE_DIR,f\"ann_model_results/{timestamp}_{str(layer_width)}_{lr}_{epoch}_{activation}\")\n",
    "                os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "                # Build the model\n",
    "                tf.keras.backend.clear_session()\n",
    "                model = build_ann_model(layer_widths=layer_width,\n",
    "                                        input_shape=INPUT_SHAPE+(1,),\n",
    "                                        activation=activation,\n",
    "                                        loss=LOSS,\n",
    "                                        metrics=METRICS,\n",
    "                                        learning_rate=lr)\n",
    "                \n",
    "                # Save the training parameters\n",
    "                training_params = {\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"batch_size\": BATCH_SIZE,\n",
    "                    \"epochs\": epoch,\n",
    "                    \"structure\": str(layer_width),\n",
    "                    \"loss\": LOSS,\n",
    "                    \"metrics\": METRICS,\n",
    "                    \"activation\": activation\n",
    "                }\n",
    "\n",
    "                # Save the model structure/summary\n",
    "                MODEL_SUMMARY_PATH = os.path.join(OUTPUT_DIR, \"model_summary.json\")\n",
    "                with open(MODEL_SUMMARY_PATH, 'w') as f:\n",
    "                    with redirect_stdout(f):\n",
    "                        model.summary()\n",
    "\n",
    "                # Train the model and record the training time\n",
    "                train_start = time()\n",
    "                history = model.fit(train_gen,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    validation_data=val_gen,\n",
    "                                    epochs = epoch)\n",
    "                train_end = time()\n",
    "                TRAIN_TIME = train_end - train_start\n",
    "\n",
    "                # Save the model in H5DF format\n",
    "                MODEL_PATH = os.path.join(OUTPUT_DIR,\"model.h5\")\n",
    "                model.save(MODEL_PATH)\n",
    "                print(f\"Model saved as {MODEL_PATH}\")\n",
    "\n",
    "                # Store the final training results\n",
    "                training_results = {}\n",
    "                for i in history.history.keys():\n",
    "                    training_results[i] = history.history[i][-1]\n",
    "                training_results['train_time'] = TRAIN_TIME\n",
    "                \n",
    "                # Save the training parameters and training results in the directory\n",
    "                params_path = os.path.join(OUTPUT_DIR, \"params_results.json\")\n",
    "                with open(params_path, \"w\") as f:\n",
    "                    json.dump({\"parameters\": training_params, \"results\": training_results}, f, indent=4)\n",
    "                print(f\"Training parameters and results saved at {params_path}\")\n",
    "\n",
    "                # Plot and save the training performance of the model\n",
    "                plot_performance(history,training_params=training_params,save_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loaded a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_DIRECTORY = os.path.join(BASE_DIR,'241129_122303_2_0.0001_50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some random training and test images \n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "for i in range(0, 10):\n",
    "    r = random.randint(1, 60000)\n",
    "    images_2_show.append(x_trainval[r])\n",
    "    titles_2_show.append('training image [' + str(r) + '] = ' + str(y_trainval[r]))    \n",
    "\n",
    "for i in range(0, 5):\n",
    "    r = random.randint(1, 10000)\n",
    "    images_2_show.append(x_test[r])        \n",
    "    titles_2_show.append('test image [' + str(r) + '] = ' + str(y_test[r]))    \n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Construction Function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
