{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "\n",
    "# Fetch the dataset\n",
    "car_dataset = fetch_ucirepo(id=19)\n",
    "\n",
    "# Data unpacking\n",
    "X = car_dataset.data.features\n",
    "y = car_dataset.data.targets\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2,random_state=12)\n",
    "\n",
    "# variable information \n",
    "print(car_dataset.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_dataset.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{X.describe()} \\n\")\n",
    "\n",
    "print(X.sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>high</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>med</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>med</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety  class\n",
       "1514    low    med      2       2    small   high  unacc\n",
       "1501    low   high  5more       4      big    med    acc\n",
       "1696    low    low      4    more      med    med   good\n",
       "203   vhigh   high  5more       4      med   high  unacc\n",
       "991     med   high      2    more    small    med  unacc\n",
       "522    high  vhigh  5more       4    small    low  unacc\n",
       "961     med  vhigh  5more       4      big    med    acc\n",
       "971     med  vhigh  5more    more      big   high    acc\n",
       "1165    med    med  5more       2      med    med  unacc\n",
       "1510    low   high  5more    more      big    med    acc"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([X,y],axis=1)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['unacc', 'acc', 'vgood', 'good'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1382, 7)\n",
      "(346, 7)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.concat([X_train,y_train],axis=1)\n",
    "print(df_train.shape)\n",
    "\n",
    "df_test = pd.concat([X_test,y_test],axis=1)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes algorithm - Yappington Academy\n",
    "\n",
    "In a Naives Bayes classifier, one can learn the probability that an outcome happens given the conditions of the feature. Taken the tennis example, when given that the day is sunny (S), temperature is cool (C), humidity is high (H), and wind is strong (St), the desired output is the probability that players come to the court. Using Naive Bayes assumption, one can calculate this probability as \n",
    "\n",
    "$$p(Play\\_Tennis = Y|Sunny,Cool,High,Strong) = p(Y)\\times p(S|Y)\\times p(C|Y)\\times p(H|Y)\\times p(St|Y)$$\n",
    "\n",
    "The prior probability of Play_Tennis = Y is calculated as the number of yes occurences over the total number of samples. The conditional probabilities (such as $p(S|Y)$) is determined from the given dataset as the number of occurences where Play_Tennis is Yes and Outlook is Sunny over the total number of occurences where Play_Tennis is Yes. \n",
    "$$p(Outlook = Sunny|Play\\_Tennis=Yes) = \\frac{\\text{\\# S and Y}}{\\text{\\# Y}}$$\n",
    "\n",
    "\n",
    "In the car evaluation example, there are three outcomes - unacceptable, acceptable, good, and vgood. The categories of the features were explored in the previous step and reported here\n",
    "* buying: The buying price has 4 categories - low, med, high, and vhigh\n",
    "* maint: The maintenance price has the similar 4 categories\n",
    "* doors: The number of doors has 4 categories - 2, 3, 4, and 5more\n",
    "* person: The number of passenger capacity has 3 categories - 2, 4, and more\n",
    "* lug_boot: The size of luggage boot has 3 categories - small, med, and big\n",
    "* safety: The estimated car safety has 3 categories - low, med, and high\n",
    "\n",
    "In this example, the relative probability of an instance belong to a class is found as\n",
    "$$p(class | \\text{feature 1, feature 2, ... feature n}) = p(class)\\prod_{i=1}^n p(\\text{feature i}|class)$$\n",
    "\n",
    "The class with the highest probability is the class that the instance belongs to. To implement the Naive Bayes classifier, I will then need to be able to:\n",
    "* Find the prior probabilities of each class happening. This is simple since I just need to find the number of instances that belongs to a class and the size of the training dataset\n",
    "* Find the conditional probability of p(feature i | class). This is a bit more involved since I will need to consider each feature value given that the instance belongs to a class -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional implementation of Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for determining prior and conditional probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences where: \n",
      "- Buying price is VHIGH: 432\n",
      "- Class is VGOOD: 65\n",
      "- Buying price is VHIGH and class is GOOD: 0 \n",
      "- Buying price is HIGH and class is UNACC: 360 \n",
      "- Safety is HIGH and class is UNACC: 0 \n",
      "- Doors is 5MORE and class is GOOD: 18 \n",
      "- Maintenance price is HIGH and class is GOOD: 0\n"
     ]
    }
   ],
   "source": [
    "def count_occurrences(df, conditions):\n",
    "    \n",
    "    \"\"\"\n",
    "    Counts the number of occurrences in a DataFrame that match given conditions.\n",
    "\n",
    "    Parameters\n",
    "    - df: DataFrame to count occurrences from.\n",
    "    - conditions: Dictionary specifying conditions (e.g., {'column_name': 'value'}).\n",
    "\n",
    "    Returns:\n",
    "    - int: The count of occurrences matching the conditions.\n",
    "    \"\"\"\n",
    "    # Start with the entire DataFrame and filter down based on conditions\n",
    "    filtered_df = df\n",
    "    for column, value in conditions.items():\n",
    "        filtered_df = filtered_df[filtered_df[column] == value]\n",
    "    return len(filtered_df)\n",
    "\n",
    "print(f\"Number of occurences where: \\n\"\n",
    "      f\"- Buying price is VHIGH: {count_occurrences(df,{'buying':'vhigh'})}\\n\"\n",
    "      f\"- Class is VGOOD: {count_occurrences(df,{'class':'vgood'})}\\n\"\n",
    "      f\"- Buying price is VHIGH and class is GOOD: {count_occurrences(df, {'buying': 'vhigh','class':'good'})} \\n\"\n",
    "      f\"- Buying price is HIGH and class is UNACC: {count_occurrences(df, {'buying': 'vhigh','class':'unacc'})} \\n\"\n",
    "      f\"- Safety is HIGH and class is UNACC: {count_occurrences(df, {'safety': 'vhigh','class':'unacc'})} \\n\"\n",
    "      f\"- Doors is 5MORE and class is GOOD: {count_occurrences(df, {'doors': '5more','class':'good'})} \\n\"\n",
    "      f\"- Maintenance price is HIGH and class is GOOD: {count_occurrences(df, {'maint': 'high','class':'good'})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prior_prob(df, condition):\n",
    "    ''' \n",
    "    This function finds the prior probability P(a=A) by determining the number of samples in the entire dataset and the number of occurences of A\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to count occurrences from.\n",
    "    - conditions: Dictionary specifying the condition or the value of event A (e.g. {'buying'}:{'high'})\n",
    "\n",
    "    Returns:\n",
    "    - float: The prior probability that even A happens \n",
    "    '''\n",
    "    num_instances = len(df)\n",
    "    num_cond = count_occurrences(df, condition)\n",
    "    \n",
    "    prior_prob = num_cond / num_instances\n",
    "\n",
    "    return prior_prob\n",
    "\n",
    "def find_prior_probs(df, label_column):\n",
    "    '''\n",
    "    This function finds the prior probability of each class in the dataframe and report them in a dictionary\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd dataframe): DataFrame from which the probability is determined\n",
    "    - label_colum (str): name of the class/label column\n",
    "\n",
    "    Returns:\n",
    "    - class_prior (dict): the dictionary containing class (key) and their corresponding prior probabilities (value)\n",
    "    '''\n",
    "    classes = df[label_column].unique()                 # List of the classes\n",
    "    num_instances = len(df)\n",
    "    class_prior_probs = {}\n",
    "\n",
    "    for class_value in classes:\n",
    "        class_count = df[df[label_column]==class_value].shape[0]\n",
    "        class_prior_probs[str(class_value)] = class_count / num_instances\n",
    "\n",
    "    return class_prior_probs\n",
    "\n",
    "def find_cond_prob(df, prior_condition, condition):\n",
    "    ''' \n",
    "    This function finds the conditional probability P(a=A|b=B) by first finding the number of B occurences in the data, then find the occurences of A given that B occured\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame to count occurrences from.\n",
    "    - prior_condition: Dictionary specifying the condition or the value of event B (e.g. {'class'}:{'good'})\n",
    "    - conditions: Dictionary specifying the condition or the value of event A (e.g. {'buying'}:{'high'})\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    - float: The conditional probability P(A|B)\n",
    "    '''\n",
    "    # Filter down the dataframe to only include the occurences that satisfy the prior condition\n",
    "    for column, value in prior_condition.items():\n",
    "        filtered_df = df[df[column] ==  value]\n",
    "    num_instances = len(filtered_df)\n",
    "\n",
    "    # Count the number of occurences that satify the condition, given that the prior condition is already satisfied\n",
    "    # (In other words, count the occurences that satisfy the condition from the filtered dataframe)\n",
    "    num_cond = count_occurrences(filtered_df,condition)\n",
    "    \n",
    "    cond_prob = num_cond/num_instances\n",
    "\n",
    "    return cond_prob \n",
    "\n",
    "def find_cond_probs(df, label_column):\n",
    "    classes = df[label_column].unique()\n",
    "\n",
    "    feature_cond_probs = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "    '''This is a nested dictionary of the following structure\n",
    "        - Level 1 - Class Values: This level has the class values and the next dictionary level as the key-value pair\n",
    "            - Level 2 - Feature Names: This level of dictionary has the feature name and the next dictionary level as the key-value pair\n",
    "                - Level 3 - Feature Values: This level of dictionary has the feature value and the conditional probabilities P(feature == feature value | class == class value) as the key-value pair \n",
    "    '''\n",
    "\n",
    "    # Considering the conditional probability feature by feature\n",
    "    for feature in df.columns:\n",
    "        # Skip this step if the feature is the label column of the dataframe\n",
    "        if feature == label_column:\n",
    "            pass\n",
    "        \n",
    "        # Iterate over each class c of the dataframe to find the conditional probabilities of each feature P(feature = value | class)\n",
    "        for c in classes: \n",
    "            df_subset = df[df[label_column]==c]                         # Subset of the dataframe where class has the value c\n",
    "            feature_count = df_subset[feature].value_counts()           # Get a series with the number of instances of each feature value in the subset\n",
    "\n",
    "            # Iterate over all the feature values and calculate the conditional probabilities of each value \n",
    "            for value, count in feature_count.items():                  \n",
    "                feature_cond_probs[c][feature][value] = count / len(df_subset)\n",
    "\n",
    "    return feature_cond_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating specific conditional probabilities\n",
    "This section is to test the find_prior_prob() and find_cond_prob() functions, which determine the prior and condition probabilities given a single specific condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prior probability of the class LOW: 0.6982633863965267\n",
      "The probability that buying price is LOW, given that the class is VGOOD is: 0.6071428571428571 \n",
      "The probability that the class is VGOOD, given that buying price is LOW is: 0.09742120343839542\n",
      " => From this finding, one can conclude that if the car is VGOOD, the buying price of the car is most likely LOW.\n",
      "    However, having a low price does not guarantee that the car is classified as VGOOD since there are other deterrent criteria such as high maintenance price or low safety\n",
      "\n",
      "The conditional probability that buying price is LOW, given that the class is VGOOD is: 0.6071428571428571 \n",
      "The conditional probability that buying price is MED, given that the class is VGOOD is: 0.39285714285714285 \n",
      "The conditional probability that buying price is HIGH, given that the class is VGOOD is: 0.0 \n",
      "The conditional probability that buying price is VHIGH, given that the class is VGOOD is: 0.0\n",
      " => From this finding, one can conclude that if the car is VGOOD, the buying price of the car can only be LOW or MED and never HIGH or VHIGH \n",
      "\n",
      "The conditional probability that buying price is LOW, given that the class is UNACC is: 0.21761658031088082 \n",
      "The conditional probability that buying price is MED, given that the class is UNACC is: 0.21658031088082902 \n",
      "The conditional probability that buying price is HIGH, given that the class is UNACC is: 0.26632124352331604 \n",
      "The conditional probability that buying price is VHIGH, given that the class is UNACC is: 0.2994818652849741\n",
      " => From this finding, one can conclude that if the car is UNACC, the buying price can be of any value but more likely HIGH or VHIGH.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The prior probability of the class LOW: {find_prior_prob(df_train, {'class':'unacc'})}\")\n",
    "\n",
    "print(f\"The probability that buying price is LOW, given that the class is VGOOD is: {find_cond_prob(df_train, {'class':'vgood'}, {'buying':'low'})} \\n\"\n",
    "      f\"The probability that the class is VGOOD, given that buying price is LOW is: {find_cond_prob(df_train, {'buying':'low'}, {'class':'vgood'})}\")\n",
    "\n",
    "print(f\" => From this finding, one can conclude that if the car is VGOOD, the buying price of the car is most likely LOW.\\n\" \n",
    "      f\"    However, having a low price does not guarantee that the car is classified as VGOOD since there are other deterrent criteria such as high maintenance price or low safety\\n\")\n",
    "\n",
    "print(f\"The conditional probability that buying price is LOW, given that the class is VGOOD is: {find_cond_prob(df_train, {'class':'vgood'}, {'buying':'low'})} \\n\"\n",
    "      f\"The conditional probability that buying price is MED, given that the class is VGOOD is: {find_cond_prob(df_train, {'class':'vgood'}, {'buying':'med'})} \\n\"\n",
    "      f\"The conditional probability that buying price is HIGH, given that the class is VGOOD is: {find_cond_prob(df_train, {'class':'vgood'}, {'buying':'high'})} \\n\"\n",
    "      f\"The conditional probability that buying price is VHIGH, given that the class is VGOOD is: {find_cond_prob(df_train, {'class':'vgood'}, {'buying':'vhigh'})}\")\n",
    "\n",
    "print(\" => From this finding, one can conclude that if the car is VGOOD, the buying price of the car can only be LOW or MED and never HIGH or VHIGH \\n\")\n",
    "\n",
    "print(f\"The conditional probability that buying price is LOW, given that the class is UNACC is: {find_cond_prob(df_train, {'class':'unacc'}, {'buying':'low'})} \\n\"\n",
    "      f\"The conditional probability that buying price is MED, given that the class is UNACC is: {find_cond_prob(df_train, {'class':'unacc'}, {'buying':'med'})} \\n\"\n",
    "      f\"The conditional probability that buying price is HIGH, given that the class is UNACC is: {find_cond_prob(df_train, {'class':'unacc'}, {'buying':'high'})} \\n\"\n",
    "      f\"The conditional probability that buying price is VHIGH, given that the class is UNACC is: {find_cond_prob(df_train, {'class':'unacc'}, {'buying':'vhigh'})}\")\n",
    "\n",
    "print(\" => From this finding, one can conclude that if the car is UNACC, the buying price can be of any value but more likely HIGH or VHIGH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the conditional probabilities of all cases\n",
    "This section shows the result of the functions find_prior_probs() and find_cond_probs(), which determine the prior and conditional probabilities for all classes and all probability \n",
    "$$P(\\text{feature values}|\\text{class values})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prior probability of class = unacc is 69.826%\n",
      "The prior probability of class = acc is 22.431%\n",
      "The prior probability of class = vgood is 4.052%\n",
      "The prior probability of class = good is 3.690%\n"
     ]
    }
   ],
   "source": [
    "prior_probs = find_prior_probs(df_train,'class')\n",
    "\n",
    "for key, value in prior_probs.items():\n",
    "    print(f\"The prior probability of class = {key} is {value*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.find_cond_probs.<locals>.<lambda>()>,\n",
       "            {'unacc': defaultdict(<function __main__.find_cond_probs.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'buying': defaultdict(float,\n",
       "                                      {'vhigh': 0.2994818652849741,\n",
       "                                       'high': 0.26632124352331604,\n",
       "                                       'low': 0.21761658031088082,\n",
       "                                       'med': 0.21658031088082902}),\n",
       "                          'maint': defaultdict(float,\n",
       "                                      {'vhigh': 0.3067357512953368,\n",
       "                                       'high': 0.26528497409326424,\n",
       "                                       'med': 0.21865284974093263,\n",
       "                                       'low': 0.20932642487046632}),\n",
       "                          'doors': defaultdict(float,\n",
       "                                      {'2': 0.2549222797927461,\n",
       "                                       '5more': 0.25181347150259065,\n",
       "                                       '3': 0.25077720207253884,\n",
       "                                       '4': 0.24248704663212436}),\n",
       "                          'persons': defaultdict(float,\n",
       "                                      {'2': 0.47046632124352333,\n",
       "                                       'more': 0.27357512953367874,\n",
       "                                       '4': 0.2559585492227979}),\n",
       "                          'lug_boot': defaultdict(float,\n",
       "                                      {'small': 0.3699481865284974,\n",
       "                                       'med': 0.31813471502590673,\n",
       "                                       'big': 0.31191709844559584}),\n",
       "                          'safety': defaultdict(float,\n",
       "                                      {'low': 0.49119170984455957,\n",
       "                                       'med': 0.28911917098445594,\n",
       "                                       'high': 0.21968911917098446}),\n",
       "                          'class': defaultdict(float, {'unacc': 1.0})}),\n",
       "             'acc': defaultdict(<function __main__.find_cond_probs.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'buying': defaultdict(float,\n",
       "                                      {'med': 0.3225806451612903,\n",
       "                                       'high': 0.27741935483870966,\n",
       "                                       'low': 0.22580645161290322,\n",
       "                                       'vhigh': 0.17419354838709677}),\n",
       "                          'maint': defaultdict(float,\n",
       "                                      {'med': 0.3,\n",
       "                                       'high': 0.27741935483870966,\n",
       "                                       'low': 0.23225806451612904,\n",
       "                                       'vhigh': 0.19032258064516128}),\n",
       "                          'doors': defaultdict(float,\n",
       "                                      {'4': 0.27419354838709675,\n",
       "                                       '3': 0.2645161290322581,\n",
       "                                       '5more': 0.25806451612903225,\n",
       "                                       '2': 0.2032258064516129}),\n",
       "                          'persons': defaultdict(float,\n",
       "                                      {'4': 0.5064516129032258,\n",
       "                                       'more': 0.4935483870967742}),\n",
       "                          'lug_boot': defaultdict(float,\n",
       "                                      {'big': 0.3709677419354839,\n",
       "                                       'med': 0.3419354838709677,\n",
       "                                       'small': 0.2870967741935484}),\n",
       "                          'safety': defaultdict(float,\n",
       "                                      {'high': 0.5419354838709678,\n",
       "                                       'med': 0.45806451612903226}),\n",
       "                          'class': defaultdict(float, {'acc': 1.0})}),\n",
       "             'vgood': defaultdict(<function __main__.find_cond_probs.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'buying': defaultdict(float,\n",
       "                                      {'low': 0.6071428571428571,\n",
       "                                       'med': 0.39285714285714285}),\n",
       "                          'maint': defaultdict(float,\n",
       "                                      {'low': 0.4107142857142857,\n",
       "                                       'med': 0.375,\n",
       "                                       'high': 0.21428571428571427}),\n",
       "                          'doors': defaultdict(float,\n",
       "                                      {'5more': 0.30357142857142855,\n",
       "                                       '3': 0.26785714285714285,\n",
       "                                       '4': 0.26785714285714285,\n",
       "                                       '2': 0.16071428571428573}),\n",
       "                          'persons': defaultdict(float,\n",
       "                                      {'more': 0.5357142857142857,\n",
       "                                       '4': 0.4642857142857143}),\n",
       "                          'lug_boot': defaultdict(float,\n",
       "                                      {'big': 0.6071428571428571,\n",
       "                                       'med': 0.39285714285714285}),\n",
       "                          'safety': defaultdict(float, {'high': 1.0}),\n",
       "                          'class': defaultdict(float, {'vgood': 1.0})}),\n",
       "             'good': defaultdict(<function __main__.find_cond_probs.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                         {'buying': defaultdict(float,\n",
       "                                      {'low': 0.6862745098039216,\n",
       "                                       'med': 0.3137254901960784}),\n",
       "                          'maint': defaultdict(float,\n",
       "                                      {'low': 0.6862745098039216,\n",
       "                                       'med': 0.3137254901960784}),\n",
       "                          'doors': defaultdict(float,\n",
       "                                      {'5more': 0.3137254901960784,\n",
       "                                       '2': 0.23529411764705882,\n",
       "                                       '4': 0.23529411764705882,\n",
       "                                       '3': 0.21568627450980393}),\n",
       "                          'persons': defaultdict(float,\n",
       "                                      {'4': 0.5098039215686274,\n",
       "                                       'more': 0.49019607843137253}),\n",
       "                          'lug_boot': defaultdict(float,\n",
       "                                      {'big': 0.4117647058823529,\n",
       "                                       'med': 0.3137254901960784,\n",
       "                                       'small': 0.27450980392156865}),\n",
       "                          'safety': defaultdict(float,\n",
       "                                      {'med': 0.6078431372549019,\n",
       "                                       'high': 0.39215686274509803}),\n",
       "                          'class': defaultdict(float, {'good': 1.0})})})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_probs = find_cond_probs(df_train,label_column='class')\n",
    "cond_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(prior_probs, cond_probs, instances):\n",
    "    '''\n",
    "    This function is used for classifying an instance\n",
    "\n",
    "    Parameters\n",
    "    - cond_probs: the 3-tier dictionary structure returned by the find_cond_probs() function. This structure represents the conditional probabilities P(features | classes) and has the structure of [class value][feature][feature value]\n",
    "    - instance: a dictionary representing a data point ()\n",
    "    '''\n",
    "\n",
    "    # Get the list of classes (from the cond_probs structures)\n",
    "    classes = []\n",
    "    for item in cond_probs.items():\n",
    "        classes.append(item[0])\n",
    "\n",
    "    # List of empty dictionaries to store the probabilities of the instance belong to each class\n",
    "    class_probs = [{}] * len(instances)                                        \n",
    "    \n",
    "    for index, instance in enumerate(instances):\n",
    "        # Iterate over each class to find the prior probability \n",
    "        for c in classes:\n",
    "            class_probs[index][c] = prior_probs[c]                     # p(class==c)\n",
    "\n",
    "            # Iterate over each feature in the instance to find the accumulative of conditional probabilties\n",
    "            for feature,value in instance.items():\n",
    "                class_probs[index][c] *= max(cond_probs[c][feature][value],1e-6)       # In case of zero probability, use a small number\n",
    "        \n",
    "        class_probs[index] = max(class_probs[index], key=class_probs[index].get)\n",
    "\n",
    "    return class_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   buying  maint  doors persons lug_boot safety  class Predicted_Class\n",
      "0   vhigh   high      3    more      med    med  unacc           unacc\n",
      "1     med   high      3    more      med    med    acc             acc\n",
      "2     low    low  5more       2      med    med  unacc           unacc\n",
      "3   vhigh  vhigh      3       2      big    low  unacc           unacc\n",
      "4   vhigh    low      2       2    small   high  unacc           unacc\n",
      "5     med   high      3       4      big    low  unacc           unacc\n",
      "6     low  vhigh  5more       2      big    low  unacc           unacc\n",
      "7     low   high      2       2    small    low  unacc           unacc\n",
      "8    high    med      4       4    small    med  unacc             acc\n",
      "9     low  vhigh      3       4      big    med    acc           unacc\n",
      "10   high    low      2    more      big    low  unacc           unacc\n",
      "11  vhigh    low  5more       2    small    low  unacc           unacc\n",
      "12    low    med      2       2      big    med  unacc           unacc\n",
      "13   high    med      3       2      big   high  unacc           unacc\n",
      "14    med   high      3       2      med    low  unacc           unacc\n",
      "15   high    low      2       4    small    med  unacc           unacc\n",
      "16  vhigh    med      2       4      med   high    acc             acc\n",
      "17    med  vhigh      2    more      med    low  unacc           unacc\n",
      "18    med    med      2       4      big    low  unacc           unacc\n",
      "19    med  vhigh      4       2      med   high  unacc           unacc\n",
      "20  vhigh   high      4       2      med    med  unacc           unacc\n",
      "21    med    low      2       2    small    low  unacc           unacc\n",
      "22    med  vhigh      2       4    small    med  unacc           unacc\n",
      "23  vhigh    low      2       2      med   high  unacc           unacc\n",
      "24    med   high  5more    more    small    low  unacc           unacc\n"
     ]
    }
   ],
   "source": [
    "# Sample some random test_instances and drop the index to later concatenate with the predicted label\n",
    "test_instances = df_test.sample(25).reset_index(drop=True)\n",
    "test_instance_features = test_instances.drop('class',axis =1).to_dict(orient='records')\n",
    "test_instance_labels = test_instances['class'].values\n",
    "\n",
    "\n",
    "prediction = naive_bayes_classifier(prior_probs=prior_probs,\n",
    "                                    cond_probs=cond_probs,\n",
    "                                    instances=test_instance_features)\n",
    "\n",
    "prediction_df = pd.DataFrame(prediction, columns=[\"Predicted_Class\"])\n",
    "prediction_result = pd.concat([test_instances,prediction_df],axis=1)\n",
    "\n",
    "print(prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying vhigh\n",
      "maint med\n",
      "doors 2\n",
      "persons more\n",
      "lug_boot big\n",
      "safety high\n"
     ]
    }
   ],
   "source": [
    "for key,value in test_instance_features[1].items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naives Bayes Classifier - OOP approach\n",
    "\n",
    "As can be seen in the functional implementation of the Naives Bayes, one need to run the find_prior_probs() and find_cond_probs() functions first before passing them into the final naive_baye_classifier() to predict an instance. This approach can be deemed as unwieldy for downstream application. \n",
    "\n",
    "Inspired by the approach that machine learning libraries such as Tensorflow adopted, the following section shows the OOP implementation of Naive Bayes. In this approach, I will define a blueprint for a NaiveBayesClassifier() object, which stores attributes such as the classes, prior probabilities, and conditional probabilities learned from running a fit() method. Afterward, a predict() method can be run on a list of testing instances to provide prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
